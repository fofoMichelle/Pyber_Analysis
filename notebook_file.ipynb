 2/1:
x=[1,2,3]
x
 2/2:
x=[1,2,3]
x
 2/3:
z=100
z
 2/4:
z=100
z
 2/5: z=100
 2/6: z=100
 2/7: z
 1/1:
# The following programm consists of two lines of codes
x= 5+3
print(x)
 1/2:
# The following programm consists of two lines of codes
x= 5+3
print(x)
 1/3:
# The following programm consists of two lines of codes
x= 5+3
print(x)
 1/4:
# The following programm consists of two lines of codes
x= 5+3
print(x)
 1/5: print (y)
 1/6: print (x)
 1/7: prit (y)
 1/8: print (x)
 3/1: print (x-1)
 3/2:
# The following programm consists of two lines of codes
x= 5+3
print(x)
 3/3: print (x-1)
 3/4: print (x+1)
 4/1:
# The following programm consists of two lines of codes
x= 5+3
print(x)
 4/2: print (x-1)
 4/3: print (x+1)
 4/4:

x= 5+3
print(x)
 4/5: x=5
 4/6: x=5
 2/8: x=5
 5/1: x=5
 5/2: x
 5/3: y=8
 5/4: print (y)
 5/5: x,y=(1,2)
 5/6: x,y
 2/9: type (x1)
2/10: type (x1)
2/11: type(x1)
 6/1: x1=5
 6/2: type(x1)
 6/3: type(-6)
 6/4: x2=4.75
 6/5: type (x2)
 6/6: int(x2)
 6/7: float(2)
 6/8: float(5)
 6/9: x3=true
6/10: x3=True
 7/1: 'George'
 7/2: "George"
 7/3: 'George'
 7/4: "George"
 7/5: print("George")
 7/6: print("George")
 7/7: x4="George"
 7/8: print(x4)
 7/9:
y=10
print(str(y)+'Geogre')
7/10: "I'm fine"
7/11: "Red' 'car"
7/12: print('red','car')
7/13: 1+2
7/14: 3-5
7/15: 15/3
7/16: 16/3
7/17: int 16/3
7/18: flot16/3
7/19: float 16/3
7/20: float(16)/3
7/21: 16 % 3
7/22: 5*3
7/23: 5**3
7/24: y= 5** 3
7/25: y
7/26: y== 125
7/27: y== 126
 8/1: import pandas as pd
 8/2:
x=5
print(x)
 9/1:
print("hello world")

counties = ["Arapahoe","Denver","Jefferson"]
if counties[1] == 'Denver':
    print(counties[1])
10/1: print(x1)
10/2: x1 = 5
10/3: print(x1)
14/1: import pandas as pd
14/2:
data_series = pd.Series(["UCLA","UC Berkley"])
print(data_series)
16/1:
# Use Pandas to read data
data_file_pd = pd.read_csv(data_file)
data_file_pd.head(10)
16/2:
# Use Pandas to read data
data_file_pd = pd.read_csv(data_file)
data_file_pd.head(2)
16/3:
# Use Pandas to read data
data_file_pd = pd.read_csv(data_file)
data_file_pd.head()
17/1:
# The sum method adds every entry in the series
total = pd.DataFrame["Amount"].sum()
total
17/2:
# The sum method adds every entry in the series
total =training_df.head["Amount"].sum()
total
17/3:
# A gigantic DataFrame of individuals' names, their trainers, their weight, and their days as gym members
training_df = pd.DataFrame({
    "Name":["Gino Walker","Hiedi Wasser","Kerrie Wetzel","Elizabeth Sackett","Jack Mitten","Madalene Wayman","Jamee Horvath","Arlena Reddin","Tula Levan","Teisha Dreier","Leslie Carrier","Arlette Hartson","Romana Merkle","Heath Viviani","Andres Zimmer","Allyson Osman","Yadira Caggiano","Jeanmarie Friedrichs","Leann Ussery","Bee Mom","Pandora Charland","Karena Wooten","Elizabet Albanese","Augusta Borjas","Erma Yadon","Belia Lenser","Karmen Sancho","Edison Mannion","Sonja Hornsby","Morgan Frei","Florencio Murphy","Christoper Hertel","Thalia Stepney","Tarah Argento","Nicol Canfield","Pok Moretti","Barbera Stallings","Muoi Kelso","Cicely Ritz","Sid Demelo","Eura Langan","Vanita An","Frieda Fuhr","Ernest Fitzhenry","Ashlyn Tash","Melodi Mclendon","Rochell Leblanc","Jacqui Reasons","Freeda Mccroy","Vanna Runk","Florinda Milot","Cierra Lecompte","Nancey Kysar","Latasha Dalton","Charlyn Rinaldi","Erline Averett","Mariko Hillary","Rosalyn Trigg","Sherwood Brauer","Hortencia Olesen","Delana Kohut","Geoffrey Mcdade","Iona Delancey","Donnie Read","Cesar Bhatia","Evia Slate","Kaye Hugo","Denise Vento","Lang Kittle","Sherry Whittenberg","Jodi Bracero","Tamera Linneman","Katheryn Koelling","Tonia Shorty","Misha Baxley","Lisbeth Goering","Merle Ladwig","Tammie Omar","Jesusa Avilla","Alda Zabala","Junita Dogan","Jessia Anglin","Peggie Scranton","Dania Clodfelter","Janis Mccarthy","Edmund Galusha","Tonisha Posey","Arvilla Medley","Briana Barbour","Delfina Kiger","Nia Lenig","Ricarda Bulow","Odell Carson","Nydia Clonts","Andree Resendez","Daniela Puma","Sherill Paavola","Gilbert Bloomquist","Shanon Mach","Justin Bangert","Arden Hokanson","Evelyne Bridge","Hee Simek","Ward Deangelis","Jodie Childs","Janis Boehme","Beaulah Glowacki","Denver Stoneham","Tarra Vinton","Deborah Hummell","Ulysses Neil","Kathryn Marques","Rosanna Dake","Gavin Wheat","Tameka Stoke","Janella Clear","Kaye Ciriaco","Suk Bloxham","Gracia Whaley","Philomena Hemingway","Claudette Vaillancourt","Olevia Piche","Trey Chiles","Idalia Scardina","Jenine Tremble","Herbert Krider","Alycia Schrock","Miss Weibel","Pearlene Neidert","Kina Callender","Charlotte Skelley","Theodora Harrigan","Sydney Shreffler","Annamae Trinidad","Tobi Mumme","Rosia Elliot","Debbra Putt","Rena Delosantos","Genna Grennan","Nieves Huf","Berry Lugo","Ayana Verdugo","Joaquin Mazzei","Doris Harmon","Patience Poss","Magaret Zabel","Marylynn Hinojos","Earlene Marcantel","Yuki Evensen","Rema Gay","Delana Haak","Patricia Fetters","Vinnie Elrod","Octavia Bellew","Burma Revard","Lakenya Kato","Vinita Buchner","Sierra Margulies","Shae Funderburg","Jenae Groleau","Louetta Howie","Astrid Duffer","Caron Altizer","Kymberly Amavisca","Mohammad Diedrich","Thora Wrinkle","Bethel Wiemann","Patria Millet","Eldridge Burbach","Alyson Eddie","Zula Hanna","Devin Goodwin","Felipa Kirkwood","Kurtis Kempf","Kasey Lenart","Deena Blankenship","Kandra Wargo","Sherrie Cieslak","Ron Atha","Reggie Barreiro","Daria Saulter","Tandra Eastman","Donnell Lucious","Talisha Rosner","Emiko Bergh","Terresa Launius","Margy Hoobler","Marylou Stelling","Lavonne Justice","Kala Langstaff","China Truett","Louanne Dussault","Thomasena Samaniego","Charlesetta Tarbell","Fatimah Lade","Malisa Cantero","Florencia Litten","Francina Fraise","Patsy London","Deloris Mclaughlin"],
    "Trainer":['Bettyann Savory','Mariah Barberio','Gordon Perrine','Pa Dargan','Blanch Victoria','Aldo Byler','Aldo Byler','Williams Camire','Junie Ritenour','Gordon Perrine','Bettyann Savory','Mariah Barberio','Aldo Byler','Barton Stecklein','Bettyann Savory','Barton Stecklein','Gordon Perrine','Pa Dargan','Aldo Byler','Brittani Brin','Bettyann Savory','Phyliss Houk','Bettyann Savory','Junie Ritenour','Aldo Byler','Calvin North','Brittani Brin','Junie Ritenour','Blanch Victoria','Brittani Brin','Bettyann Savory','Blanch Victoria','Mariah Barberio','Bettyann Savory','Blanch Victoria','Brittani Brin','Junie Ritenour','Pa Dargan','Gordon Perrine','Phyliss Houk','Pa Dargan','Mariah Barberio','Phyliss Houk','Phyliss Houk','Calvin North','Williams Camire','Brittani Brin','Gordon Perrine','Bettyann Savory','Bettyann Savory','Pa Dargan','Phyliss Houk','Barton Stecklein','Blanch Victoria','Coleman Dunmire','Phyliss Houk','Blanch Victoria','Pa Dargan','Harland Coolidge','Calvin North','Bettyann Savory','Phyliss Houk','Bettyann Savory','Harland Coolidge','Gordon Perrine','Junie Ritenour','Harland Coolidge','Blanch Victoria','Mariah Barberio','Coleman Dunmire','Aldo Byler','Bettyann Savory','Gordon Perrine','Bettyann Savory','Barton Stecklein','Harland Coolidge','Aldo Byler','Aldo Byler','Pa Dargan','Junie Ritenour','Brittani Brin','Junie Ritenour','Gordon Perrine','Mariah Barberio','Mariah Barberio','Mariah Barberio','Bettyann Savory','Brittani Brin','Aldo Byler','Phyliss Houk','Blanch Victoria','Pa Dargan','Phyliss Houk','Brittani Brin','Barton Stecklein','Coleman Dunmire','Bettyann Savory','Bettyann Savory','Gordon Perrine','Blanch Victoria','Junie Ritenour','Phyliss Houk','Coleman Dunmire','Williams Camire','Harland Coolidge','Williams Camire','Aldo Byler','Harland Coolidge','Gordon Perrine','Brittani Brin','Coleman Dunmire','Calvin North','Phyliss Houk','Brittani Brin','Aldo Byler','Bettyann Savory','Brittani Brin','Gordon Perrine','Calvin North','Harland Coolidge','Coleman Dunmire','Harland Coolidge','Aldo Byler','Junie Ritenour','Blanch Victoria','Harland Coolidge','Blanch Victoria','Junie Ritenour','Harland Coolidge','Junie Ritenour','Gordon Perrine','Brittani Brin','Coleman Dunmire','Williams Camire','Junie Ritenour','Brittani Brin','Calvin North','Barton Stecklein','Barton Stecklein','Mariah Barberio','Coleman Dunmire','Bettyann Savory','Mariah Barberio','Pa Dargan','Barton Stecklein','Coleman Dunmire','Brittani Brin','Barton Stecklein','Pa Dargan','Barton Stecklein','Junie Ritenour','Bettyann Savory','Williams Camire','Pa Dargan','Calvin North','Williams Camire','Coleman Dunmire','Aldo Byler','Barton Stecklein','Coleman Dunmire','Blanch Victoria','Mariah Barberio','Mariah Barberio','Harland Coolidge','Barton Stecklein','Phyliss Houk','Pa Dargan','Bettyann Savory','Barton Stecklein','Harland Coolidge','Junie Ritenour','Pa Dargan','Mariah Barberio','Blanch Victoria','Williams Camire','Phyliss Houk','Phyliss Houk','Coleman Dunmire','Mariah Barberio','Gordon Perrine','Coleman Dunmire','Brittani Brin','Pa Dargan','Coleman Dunmire','Brittani Brin','Blanch Victoria','Coleman Dunmire','Gordon Perrine','Coleman Dunmire','Aldo Byler','Aldo Byler','Mariah Barberio','Williams Camire','Phyliss Houk','Aldo Byler','Williams Camire','Aldo Byler','Williams Camire','Coleman Dunmire','Phyliss Houk'],
    "Weight":[128,180,193,177,237,166,224,208,177,241,114,161,162,151,220,142,193,193,124,130,132,141,190,239,213,131,172,127,184,157,215,122,181,240,218,205,239,217,234,158,180,131,194,171,177,110,117,114,217,123,248,189,198,127,182,121,224,111,151,170,188,150,137,231,222,186,139,175,178,246,150,154,129,216,144,198,228,183,173,129,157,199,186,232,172,157,246,239,214,161,132,208,187,224,164,177,175,224,219,235,112,241,243,179,208,196,131,207,182,233,191,162,173,197,190,182,231,196,196,143,250,174,138,135,164,204,235,192,114,179,215,127,185,213,250,213,153,217,176,190,119,167,118,208,113,206,200,236,159,218,168,159,156,183,121,203,215,209,179,219,174,220,129,188,217,250,166,157,112,236,182,144,189,243,238,147,165,115,160,134,245,174,238,157,150,184,174,134,134,248,199,165,117,119,162,112,170,224,247,217],
    "Membership(Days)":[52,70,148,124,186,157,127,155,37,185,158,129,93,69,124,13,76,153,164,161,48,121,167,69,39,163,7,34,176,169,108,162,195,86,155,77,197,200,80,142,179,67,58,145,188,147,125,15,13,173,125,4,61,29,132,110,62,137,197,135,162,174,32,151,149,65,18,42,63,62,104,200,189,40,38,199,1,12,8,2,195,30,7,72,130,144,2,34,200,143,43,196,22,115,171,54,143,59,14,52,109,115,187,185,26,19,178,18,120,169,45,52,130,69,168,178,96,22,78,152,39,51,118,130,60,156,108,69,103,158,165,142,86,91,117,77,57,169,86,188,97,111,22,83,81,177,163,35,12,164,21,181,171,138,22,107,58,51,38,128,19,193,157,13,104,89,13,10,26,190,179,101,7,159,100,49,120,109,56,199,51,108,47,171,69,162,74,119,148,88,32,159,65,146,140,171,88,18,59,13]
})
training_df.head(10)
17/4:
# The sum method adds every entry in the series
total =training_df.head["Amount"].sum()
total
17/5: # Finding the names of the trainers
17/6:
# The sum method adds every entry in the series
total =training_df.(describe)
total
17/7:
# Finding the average weight of all students
training_df["weight"] .mean
18/1:
# Collecting a list of all columns within the DataFrame
file_one_df.columns
18/2:
# Using .rename(columns={}) in order to rename columns
renamed_df = file_one_df.rename(columns={"id":"Student ID",
                                         "first_name":"First Name",
                                        "last_name": "Last Name",
                                        "email": "Email",
                                        "date_enrolled": "Date Enrolled"})
renamed_df.head()
18/3:
# Using .rename(columns={}) in order to rename columns
renamed_df = file_one_df.rename(columns={"id":"Student ID",
                                         "first_name":"First Name",
                                        "last_name": "Last Name",
                                        "email": "Email",
                                        "date_enrolled": "Date Enrolled"})
renamed_df.head()
18/4:
# Create a copy of DataFrame with specific columns. 
students_df = renamed_df[["Student ID", "First Name", "Last Name", "Email" ]].copy()
students_df.head()
20/1:
#  Get the data types of each column.
book_csv_df.head()
20/2:
#  Get the data types of each column.
book_csv_df.head()
book_csv_df["Best_book"].head
20/3:
# Make a reference to the books.csv file path
books.csv = "Resources/books.csv"
# Import the books.csv file as a DataFrame with utf-8 encoding.
books_csv_df = pd.read_csv(book_csv, encoding="ISO-8859-1")
20/4:
#  Get the data types of each column.
books_csv_df.dtypes
books_csv_df["Best_book"].head
20/5:
#  Get the data types of each column.
books_csv_df.dtypes
books_csv_df["Best_book"].head
18/5:
# Show just the header
file_one_df.head()
21/1:
# Dependencies
import pandas as pd
21/2:
# Read in the following data into a DataFrame.
raw_data_info = {
    "customer_id": [112, 403, 999, 543, 123],
    "name": ["John", "Kelly", "Sam", "April", "Bobbo"],
    "email": ["jman@gmail", "kelly@aol.com", "sports@school.edu", "April@yahoo.com", "HeyImBobbo@msn.com"]}
21/3:
# Read in the following data into a DataFrame.
raw_data_items = {
    "customer_id": [403, 112, 543, 999, 654],
    "item": ["soda", "chips", "TV", "Laptop", "Cooler"],
    "cost": [3.00, 4.50, 600, 900, 150]}
21/4: # Merge the two dataframes using an inner join (default)
21/5: # Merge two dataframes using an outer join
21/6: # Merge two dataframes using a left join
21/7: # Merge two dataframes using a right join
21/8:
#  Import the csv files and create DataFrames.
bitcoin_csv = "Resources/bitcoin_cash_price.csv"
dash_csv = "Resources/dash_price.csv"
25/1:
#List of high schools
high_schools = ["Hernandez High School", ["Figueroa High School","Wilson High School","Wright High School"]]

fpr school in high_schools:
    print(school)
25/2:
#List of high schools
high_schools = ["Hernandez High School", ["Figueroa High School","Wilson High School","Wright High School"]]

for school in high_schools:
    print(school)
25/3:
high_school_types = [{"High School": "Griffin", "Type":"District"},
                    {"High School": "Figueroa", "Type": "District"},
                    {"High School": "Wilson", "Type": "Charter"},
                    {"High School": "Wright", "Type": "Charter"}]
25/4:
high_school_types = [{"High School": "Griffin", "Type":"District"},
                    {"High School": "Figueroa", "Type": "District"},
                    {"High School": "Wilson", "Type": "Charter"},
                    {"High School": "Wright", "Type": "Charter"}]
for school in high_school_types:
    print(school)
25/5:
# List of high schools
high_schools = ["Huang High School",  "Figueroa High School", "Shelton High School", "Hernandez High School","Griffin High School","Wilson High School", "Cabrera High School", "Bailey High School", "Holden High School", "Pena High School", "Wright High School","Rodriguez High School", "Johnson High School", "Ford High School", "Thomas High School"]
for school in high_schools:
    print(school)
25/6:
# Add the Pandas dependency.
import pandas as pd
25/7:
# Create a Pandas Series from a list.
school_series = pd.Series(high_schools)
school_series
25/8:
school_df = pd.DataFrame(high_school_docys)
school_df
25/9:
school_df = pd.DataFrame(high_school_docys)
school_df
print(school_df)
25/10:
#Add the list to a new DataFrame.
school_df = pd.DataFrame(high_school_docys)
#Print the DataFrame

school_df
25/11:
#Add the list to a new DataFrame.
school_df = pd.DataFrame(high_school_dicts)
#Print the DataFrame
school_df
25/12:

high_school_dicts = [{"School ID": 0, "school_name": "Huang High    School", "type": "District"},
                   {"School ID": 1, "school_name": "Figueroa High School", "type": "District"},
                    {"School ID": 2, "school_name":"Shelton High School", "type": "Charter"},
                    {"School ID": 3, "school_name":"Hernandez High School", "type": "District"},
                    {"School ID": 4, "school_name":"Griffin High School", "type": "Charter"}]
#Add the list to a new DataFrame.
school_df = pd.DataFrame(high_school_dicts)
#Print the DataFrame
school_df
25/13:

high_school_dicts = [{"School ID": 0, "school_name": "Huang High    School", "type": "District"},
                   {"School ID": 1, "school_name": "Figueroa High School", "type": "District"},
                    {"School ID": 2, "school_name":"Shelton High School", "type": "Charter"},
                    {"School ID": 3, "school_name":"Hernandez High School", "type": "District"},
                    {"School ID": 4, "school_name":"Griffin High School", "type": "Charter"}]
high_school_dicts
25/14:
#Add the list to a new DataFrame.
school_df = pd.DataFrame(high_school_dicts)
#Print the DataFrame
school_df
25/15:
# Three separate lists of information on high schools
school_id = [0, 1, 2, 3, 4]

school_name = ["Huang High School", "Figueroa High School",
"Shelton High School", "Hernandez High School","Griffin High School"]

type_of_school = ["District", "District", "Charter", "District","Charter"]
25/16:
#Initialize a new DataFrame
schools_df = pd.DataFrame()
# Add the list to a new DataFrame.
schools_df["School ID"] = school_id

# Print the DataFrame.
schools_df
25/17:
schools_df["School Name"] = school_name
school_name
25/18:
#Initialize a new DataFrame
schools_df = pd.DataFrame()
# Add the list to a new DataFrame.
schools_df["School ID"] = school_id

# Print the DataFrame.
schools_df
schools_df["School Name"] = school_name
school_name

school_df["Type"]= type_of_school
type_of_school
25/19:
#Initialize a new DataFrame
schools_df = pd.DataFrame()
# Add the list to a new DataFrame.
schools_df["School ID"] = school_id

# Print the DataFrame.
schools_df
schools_df["School Name"] = school_name
school_name

school_df["Type"]= type_of_school
type_of_school
25/20:
#Initialize a new DataFrame
schools_df = pd.DataFrame()
# Add the list to a new DataFrame.
schools_df["School ID"] = school_id

# Print the DataFrame.
schools_df
schools_df["School Name"] = school_name
school_name

schools_df
schools_df["Type"]= type_of_school
type_of_school
25/21:
#Initialize a new DataFrame
schools_df = pd.DataFrame()
# Add the list to a new DataFrame.
schools_df["School ID"] = school_id

# Print the DataFrame.
schools_df
schools_df["School Name"] = school_name
school_name

schools_df
schools_df["Type"]= type_of_school
type_of_school
25/22:
#Initialize a new DataFrame
schools_df = pd.DataFrame()
# Add the list to a new DataFrame.
schools_df["School ID"] = school_id

# Print the DataFrame.
schools_df
schools_df["School Name"] = school_name
school_name
25/23:
schools_df
schools_df["Type"]= type_of_school
type_of_school
25/24:
#Initialize a new DataFrame
schools_df = pd.DataFrame()
# Add the list to a new DataFrame.
schools_df["School ID"] = school_id
25/25:
#Initialize a new DataFrame
schools_df = pd.DataFrame()
# Add the list to a new DataFrame.
schools_df["School ID"] = school_id
26/1:
#Initialize a new DataFrame
schools_df = pd.DataFrame()
# Add the list to a new DataFrame.
schools_df["School ID"] = school_id
26/2:
#Initialize a new DataFrame
schools_df = pd.DataFrame()
# Add the list to a new DataFrame.
schools_df["School ID"] = school_id
school_df
26/3:
#Initialize a new DataFrame
schools_df = pd.DataFrame()

# Add the list to a new DataFrame.
schools_df["School ID"] = school_id
#Print the DataFrame.
schools_df
26/4:
# Three separate lists of information on high schools
school_id = [0, 1, 2, 3, 4]

school_name = ["Huang High School", "Figueroa High School",
"Shelton High School", "Hernandez High School","Griffin High School"]

type_of_school = ["District", "District", "Charter", "District","Charter"]
26/5:
# Three separate lists of information on high schools
school_id = [0, 1, 2, 3, 4]

school_name = ["Huang High School", "Figueroa High School",
"Shelton High School", "Hernandez High School","Griffin High School"]

type_of_school = ["District", "District", "Charter", "District","Charter"]
26/6:
#Initialize a new DataFrame
schools_df = pd.DataFrame()

# Add the list to a new DataFrame.
schools_df["School ID"] = school_id

#Print the DataFrame.
ffschools_df
26/7:
#Initialize a new DataFrame
schools_df = pd.DataFrame()

# Add the list to a new DataFrame.
schools_df["School ID"]= school_id

#Print the DataFrame.
schools_df
26/8:
#Initialize a new DataFrame
schools_df = pd.DataFrame()

# Add the list to a new DataFrame.
schools_df["School ID"]= school_id

#Print the DataFrame.
schools_df
26/9:
#Initialize a new DataFrame
schools_df = pd.DataFrame()
# Add the list to a new DataFrame.
schools_df["School ID"]= school_id
#Print the DataFrame.
schools_df
26/10:
# Three separate lists of information on high schools
school_id = [0, 1, 2, 3, 4]

school_name = ["Huang High School", "Figueroa High School",
"Shelton High School", "Hernandez High School","Griffin High School"]

type_of_school = ["District", "District", "Charter", "District","Charter"]
26/11:
#Initialize a new DataFrame
schools_df = pd.DataFrame(high_school_dicts)
# Add the list to a new DataFrame.
schools_df["School ID"]= school_id
#Print the DataFrame.
schools_df
26/12:
# List of high schools
high_schools = ["Huang High School",  "Figueroa High School", "Shelton High School", "Hernandez High School","Griffin High School","Wilson High School", "Cabrera High School", "Bailey High School", "Holden High School", "Pena High School", "Wright High School","Rodriguez High School", "Johnson High School", "Ford High School", "Thomas High School"]
for school in high_schools:
    print(school)
26/13:
# Add the Pandas dependency.
import pandas as pd
26/14:
# Create a Pandas Series from a list.
school_series = pd.Series(high_schools)
school_series
26/15:

high_school_dicts = [{"School ID": 0, "school_name": "Huang High    School", "type": "District"},
                   {"School ID": 1, "school_name": "Figueroa High School", "type": "District"},
                    {"School ID": 2, "school_name":"Shelton High School", "type": "Charter"},
                    {"School ID": 3, "school_name":"Hernandez High School", "type": "District"},
                    {"School ID": 4, "school_name":"Griffin High School", "type": "Charter"}]
high_school_dicts
26/16:
#Add the list to a new DataFrame.
school_df = pd.DataFrame(high_school_dicts)
#Print the DataFrame
school_df
26/17:
# Three separate lists of information on high schools
school_id = [0, 1, 2, 3, 4]

school_name = ["Huang High School", "Figueroa High School",
"Shelton High School", "Hernandez High School","Griffin High School"]

type_of_school = ["District", "District", "Charter", "District","Charter"]
26/18:
#Initialize a new DataFrame
schools_df = pd.DataFrame(high_school_dicts)
# Add the list to a new DataFrame.
schools_df["School ID"]= school_id
#Print the DataFrame.
schools_df
26/19:
#Initialize a new DataFrame
schools_df = pd.DataFrame()
# Add the list to a new DataFrame.
schools_df["School ID"]= school_id
#Print the DataFrame.
schools_df
26/20:
# Add the list to a new DataFrame.
schools_df["School Name"]= school_name
#Print the DataFrame.
schools_df
26/21:
# Add the list to a new DataFrame.
schools_df["Type"]= type_of_school
#Print the DataFrame.
schools_df
26/22:
# Create a dictionary of information on high schools.
high_schools_dict = {'School ID': school_id, 'school_name':school_name, 'type':type_of_school}
26/23:
# Create a dictionary of information on high schools.
high_schools_dict = {'School ID': school_id, 'school_name':school_name, 'type':type_of_school}
high_schools_dict
26/24:
# Three separate lists of information on high schools
school_id = [0, 1, 2, 3, 4]

school_name = ["Huang High School", "Figueroa High School",
"Shelton High School", "Hernandez High School","Griffin High School"]

type_of_school = ["District", "District", "Charter", "District","Charter"]
26/25:
#Add the list to a new DataFrame.
school_df = pd.DataFrame(high_school_dicts)
#Print the DataFrame
school_df
26/26: school_df.columns
26/27: school_df.index
26/28: school_df.values
27/1:
# Add the Pandas dependency.
import pandas as pd
27/2:
school_data_to_load = "Resources/schools_complete.csv"
student_data_to_load = "Resources/students_complete.csv"
27/3:
# Read the school data file and store it in a Pandas DataFrame.
school_data_df = pd.read_csv(school_data_to_load)
school_data_df
27/4:
# Read the school data file and store it in a Pandas DataFrame.
school_data_df.head() = pd.read_csv(school_data_to_load)
school_data_df.head()
27/5:
# Read the school data file and store it in a Pandas DataFrame.
school_data_df= pd.read_csv(school_data_to_load)
school_data_df
27/6:
# Read the school data file and store it in a Pandas DataFrame.
school_data_df= pd.read_csv(school_data_to_load)
school_data_df.head()
27/7:
# Read the school data file and store it in a Pandas DataFrame.
school_data_df= pd.read_csv(school_data_to_load)
school_data_df
27/8:
# Read the student data file and store it in a Pandas DataFrame.
student_data_df = pd.read_csv(student_data_to_load)
student_data_df.head()
27/9:
# Determine if there are any missing values in the school data.
school_data_df.count()
27/10:
# Determine if there are any missing values in the student data.
student_data_df.count()
27/11: school_data_df.isnull()
27/12: student_data_df.isnull().sum()
27/13: student_data_df.notnull().sum()
28/1:
#Add the Pandas dependency
import pandas as pd
28/2:
#Files to load
file_to_load = "Resources/missing_grades.csv"

#Read the CSV into a DataFrame
missing_grade_df = pd.read_csv(file_to_load)
missing_grade_df
28/3:
#Drop the NaNS.
missing_grade_df.dropna()
28/4:
# Fill in the empty rows with "85"
missing_grade_df.fillna(85)
27/14: school_data_df.dtypes
27/15: school_data_df.budget.dtype
27/16:
# Determine data types for the student DataFrame.
student_data_df.dtypes
29/1:
#Import dependencies
import pandas as pd
29/2:
student_data_to_load = "Resources/students_complete.csv"
student_data_df = pd.read_csv(student_data_to_load)
student_data_df.head()
29/3:
# Put the student names in a list.
student_names = student_data_df["student_name"].tolist()
student_names
27/17:
# Read the student data file and store it in a Pandas DataFrame.
student_data_df = pd.read_csv(student_data_to_load)
student_data_df.head()
27/18:
# Read the school data file and store it in a Pandas DataFrame.
school_data_df= pd.read_csv(school_data_to_load)
school_data_df
27/19:
# Read the student data file and store it in a Pandas DataFrame.
student_data_df = pd.read_csv(student_data_to_load)
student_data_df.head()
27/20:
# Read the school data file and store it in a Pandas DataFrame.
school_data_df= pd.read_csv(school_data_to_load)
school_data_df
27/21:
# Add the Pandas dependency.
import pandas as pd
29/4: name = "Mrs. Linda Santiago"
29/5:
# Split the student name and determine the length of the split name.
for name in student_names:
    print(name.split(), len(name.split()))
29/6:
# Create a new list and use it for the for loop to iterate through the list.
students_to_fix = []

# Use an if statement to check the length of the name.
# If the name is greater than or equal to "3", add the name to the list.

for name in student_names:
    if len(name.split()) >= 3:
        students_to_fix.append(name)

# Get the length of the students whose names are greater than or equal to "3".
len(students_to_fix)
29/7:
# Create a new list and use it for the for loop to iterate through the list.
students_to_fix = []

# Use an if statement to check the length of the name.
# If the name is greater than or equal to "3", add the name to the list.

for name in student_names:
    if len(name.split()) >= 3:
        students_to_fix.append(name)

# Get the length of the students whose names are greater than or equal to "3".
len(students_to_fix)
29/8:
#Import dependencies
import pandas as pd
29/9:
student_data_to_load = "Resources/students_complete.csv"
student_data_df = pd.read_csv(student_data_to_load)
student_data_df.head()
29/10:
# Put the student names in a list.
student_names = student_data_df["student_name"].tolist()
student_names
29/11:
# Split the student name and determine the length of the split name.
for name in student_names:
    print(name.split(), len(name.split()))
29/12:
# Create a new list and use it for the for loop to iterate through the list.
students_to_fix = []

# Use an if statement to check the length of the name.
# If the name is greater than or equal to "3", add the name to the list.

for name in student_names:
    if len(name.split()) >= 3:
        students_to_fix.append(name)

# Get the length of the students whose names are greater than or equal to "3".
len(students_to_fix)
29/13:
# Create a new list and use it for the for loop to iterate through the list.
students_to_fix = []

# Use an if statement to check the length of the name.
# If the name is greater than or equal to "3", add the name to the list.

for name in student_names:
    if len(name.split()) >= 3:
        students_to_fix.append(name)

# Get the length of the students whose names are greater than or equal to "3".
len(students_to_fix)
print(student_fix)
29/14:
# Create a new list and use it for the for loop to iterate through the list.
students_to_fix = []

# Use an if statement to check the length of the name.
# If the name is greater than or equal to "3", add the name to the list.

for name in student_names:
    if len(name.split()) >= 3:
        students_to_fix.append(name)

# Get the length of the students whose names are greater than or equal to "3".
len(students_to_fix)
print(student_to_fix)
29/15:
# Create a new list and use it for the for loop to iterate through the list.
students_to_fix = []

# Use an if statement to check the length of the name.
# If the name is greater than or equal to "3", add the name to the list.

for name in student_names:
    if len(name.split()) >= 3:
        students_to_fix.append(name)

# Get the length of the students whose names are greater than or equal to "3".
len(students_to_fix)
print(students_to_fix)
29/16:
# Add the prefixes less than or equal to 4 to a new list.
prefixes = []
for name in students_to_fix:
    if len(name.split()[0]) <= 4:
        prefixes.append(name.split()[0])

print(prefixes)
29/17:
# Add the prefixes less than or equal to 4 to a new list.
prefixes = []
for name in students_to_fix:
    if len(name.split()[0]) <= 5:
        prefixes.append(name.split()[0])

print(prefixes)
29/18:
# Add the prefixes less than or equal to 4 to a new list.
prefixes = []
for name in students_to_fix:
    if len(name.split()[0]) <= 4:
        prefixes.append(name.split()[0])

print(prefixes)
29/19:
# Add the suffixes less than or equal to 3 to a new list.
suffixes = []
for name in students_to_fix:
    if len(name.split()[-1]) <= 3:
        suffixes.append(name.split()[-1])

print(suffixes
29/20:
# Add the suffixes less than or equal to 3 to a new list.
suffixes = []
for name in students_to_fix:
    if len(name.split()[-1]) <= 3:
        suffixes.append(name.split()[-1])

print(suffixes)
29/21: set(prefixes)
29/22:
# Get the unique items in the "suffixes" list.
set(suffixes)
29/23:
# Strip "Mrs." from the student names
for name in students_to_fix:
    print(name.strip("Mrs."))
29/24:
# Replace "Dr." with an empty string.
name = "Dr. Linda Santiago"
name.replace("Dr.", "")
29/25: prefixes_suffixes = ["Dr. ", "Mr. ","Ms. ", "Mrs. ", "Miss ", " MD", " DDS", " DVM", " PhD"]
29/26:
# Replace "Dr." with an empty string.
name = "Dr. Linda Santiago"
name.replace("Dr.","")
29/27:
# Replace "Dr." with an empty string.
name = "Dr. Linda Santiago"
name.replace("Dr. ","")
29/28:
# Replace "Dr." with an empty string.
name = "Dr. Linda Santiago"
name.replace("Dr.","")
29/29:
# Replace "Dr." with an empty string.
name = "Dr. Linda Santiago"
name.replace("Dr. ","")
29/30:
prefixes_suffixes = ["Dr. ", "Mr. ","Ms. ", "Mrs. ", "Miss ", " MD", " DDS", " DVM", " PhD"]
print(prefixes_suffixes)
29/31: prefixes_suffixes = ["Dr. ", "Mr. ","Ms. ", "Mrs. ", "Miss ", " MD", " DDS", " DVM", " PhD"]
29/32:
student_data_df["student_name"].str.replace()
# Iterate through the "prefixes_suffixes" list and replace them with an empty space, "" when it appears in the student's name.
for word in prefixes_suffixes:
    student_data_df["student_name"] = student_data_df["student_name"].str.replace(word,"")
29/33:
student_data_df["student_name"].str.replace()
# Iterate through the "prefixes_suffixes" list and replace them with an empty space, "" when it appears in the student's name.
29/34: student_data_df["student_name"].str.replace()
29/35:
prefixes_suffixes = ["Dr. ", "Mr. ","Ms. ", "Mrs. ", "Miss ", " MD", " DDS", " DVM", " PhD"]

student_data_df["student_name"].str.replace()

for word in prefixes_suffixes:
    student_data_df["student_name"] = student_data_df["student_name"].str.replace(word,"")
29/36:
prefixes_suffixes = ["Dr. ", "Mr. ","Ms. ", "Mrs. ", "Miss ", " MD", " DDS", " DVM", " PhD"]

student_data_df["student_name"].str.replace()

for word in prefixes_suffixes:
    student_data_df["student_name"] = student_data_df["student_name"].str.replace(word,"")
    student_data_df
29/37:
prefixes_suffixes = ["Dr. ", "Mr. ","Ms. ", "Mrs. ", "Miss ", " MD", " DDS", " DVM", " PhD"]

#student_data_df["student_name"].str.replace()

#for word in prefixes_suffixes:
    #student_data_df["student_name"] = student_data_df["student_name"].str.replace(word,"")
    #student_data_df
29/38: student_data_df["student_name"].str.replace()
29/39:
prefixes_suffixes = ["Dr. ", "Mr. ","Ms. ", "Mrs. ", "Miss ", " MD", " DDS", " DVM", " PhD"]

student_data_df["student_name"].str.replace()

#for word in prefixes_suffixes:
    #student_data_df["student_name"] = student_data_df["student_name"].str.replace(word,"")
    #student_data_df
29/40:
student_data_df["student_name"].str.replace()
for word in prefixes_suffixes:
    #student_data_df["student_name"] = student_data_df["student_name"].str.replace(word,"")
    #student_data_df
29/41:
student_data_df["student_name"].str.replace()
for word in prefixes_suffixes:
    student_data_df["student_name"] = student_data_df["student_name"].str.replace(word,"")
    #tudent_data_df
29/42:
student_data_df["student_name"].str.replace()
for word in prefixes_suffixes:
    student_data_df["student_name"] = student_data_df["student_name"].str.replace(word,"")
    student_data_df
29/43:
student_data_df["student_name"].str.replace()
for word in prefixes_suffixes:
    student_data_df["student_name"] = student_data_df["student_name"].str.replace(word,"")
    student_data_df["student_name"]
29/44:
student_data_df["student_name"].str.replace()
for word in prefixes_suffixes:
    student_data_df["student_name"] = student_data_df["student_name"].str.replace(word,"")
29/45: prefixes_suffixes = ["Dr. ", "Mr. ","Ms. ", "Mrs. ", "Miss ", " MD", " DDS", " DVM", " PhD"]
29/46:
for word in prefixes_suffixes:
    student_data_df["student_name"] = student_data_df["student_name"].str.replace(word,"")
29/47:
for word in prefixes_suffixes:
    student_data_df["student_name"] = student_data_df["student_name"].str.replace(word,"")
29/48: student_data_df["student_name"].str.replace()
29/49:
for word in prefixes_suffixes:
    student_data_df["student_name"] = student_data_df["student_name"].str.replace(word,"")
    print(student_data_df.head(10))
29/50:
for word in prefixes_suffixes:
    student_data_df["student_name"] = student_data_df["student_name"].str.replace(word,"")
    print(student_data_df.head())
29/51:
for word in prefixes_suffixes:
    student_data_df["student_name"] = student_data_df["student_name"].str.replace(word,"")
    print(student_data_df.head(10))
29/52:
for word in prefixes_suffixes:
    student_data_df["student_name"] = student_data_df["student_name"].str.replace(word,"")
    print(student_data_df.head(10))
27/22:
# Read the student data file and store it in a Pandas DataFrame.
student_data_df = pd.read_csv(student_data_to_load)
student_data_df.head()
29/53:
for word in prefixes_suffixes:
    student_data_df["student_name"] = student_data_df["student_name"].str.replace(word,"")
    print(student_data_df.head)
29/54:
for word in prefixes_suffixes:
    student_data_df["student_name"] = student_data_df["student_name"].str.replace(word,"")
    print(student_data_df)
29/55:
student_names = student_data_df["student_name"].tolist()
student_names
29/56:
# Create a new list and use it for the for loop to iterate through the list.
students_fixed = []

# Use an if statement to check the length of the name.

# If the name is greater than or equal to 3, add the name to the list.

for name in student_names:
    if len(name.split()) >= 3:
        students_fixed.append(name)

# Get the length of the students' names that are greater than or equal to 3.
len(students_fixed)
29/57:
for word in prefixes_suffixes:
    student_data_df["student_name"] = student_data_df["student_name"].str.replace(word,"")
    print(student_data_df.head(10))
29/58: set(prefixes)
29/59:
student_data_to_load = "Resources/students_complete.csv"
student_data_df = pd.read_csv(student_data_to_load)
student_data_df.head()
29/60:
# Put the student names in a list.
student_names = student_data_df["student_name"].tolist()
student_names
29/61:
# Split the student name and determine the length of the split name.
for name in student_names:
    print(name.split(), len(name.split()))
29/62:
# Create a new list and use it for the for loop to iterate through the list.
students_to_fix = []

# Use an if statement to check the length of the name.
# If the name is greater than or equal to "3", add the name to the list.

for name in student_names:
    if len(name.split()) >= 3:
        students_to_fix.append(name)

# Get the length of the students whose names are greater than or equal to "3".
len(students_to_fix)
print(students_to_fix)
28/5:
#Files to load
file_to_load = "Resources/missing_grades.csv"

#Read the CSV into a DataFrame
missing_grade_df = pd.read_csv(file_to_load)
missing_grade_df
28/6:
#Files to load
file_to_load = "Resources/missing_grades.csv"

#Read the CSV into a DataFrame
missing_grade_df = pd.read_csv(file_to_load)
missing_grade_df
28/7:
#Drop the NaNS.
missing_grade_df.dropna()
28/8:
# Fill in the empty rows with "85"
missing_grade_df.fillna(85)
29/63:
# Split the student name and determine the length of the split name.
for name in student_names:
    print(name.split(), len(name.split()))
29/64:
# Create a new list and use it for the for loop to iterate through the list.
students_to_fix = []

# Use an if statement to check the length of the name.
# If the name is greater than or equal to "3", add the name to the list.

for name in student_names:
    if len(name.split()) >= 3:
        students_to_fix.append(name)

# Get the length of the students whose names are greater than or equal to "3".
len(students_to_fix)
print(students_to_fix)
29/65:
# Add the suffixes less than or equal to 3 to a new list.
suffixes = []
for name in students_to_fix:
    if len(name.split()[-1]) <= 3:
        suffixes.append(name.split()[-1])

print(suffixes)
29/66: set(prefixes)
29/67:
# Strip "Mrs." from the student names
for name in students_to_fix:
    print(name.strip("Mrs."))
29/68:
# Replace "Dr." with an empty string.
name = "Dr. Linda Santiago"
name.replace("Dr. ","")
29/69: prefixes_suffixes = ["Dr. ", "Mr. ","Ms. ", "Mrs. ", "Miss ", " MD", " DDS", " DVM", " PhD"]
29/70:
for word in prefixes_suffixes:
    student_data_df["student_name"] = student_data_df["student_name"].str.replace(word,"")
    print(student_data_df.head(10))
27/23:
# Add the Pandas dependency.
import pandas as pd
27/24:
school_data_to_load = "Resources/schools_complete.csv"
student_data_to_load = "Resources/students_complete.csv"
27/25:
# Determine if there are any missing values in the school data.
school_data_df.count()
27/26:
# Determine if there are any missing values in the student data.
student_data_df.count()
27/27: school_data_df.isnull()
27/28: student_data_df.isnull().sum()
27/29: student_data_df.notnull().sum()
27/30:
#Determin data types for the student DataFrame
school_data_df.dtypes
27/31:
# Determine data types for the student DataFrame.
student_data_df.dtypes
27/32:
# Read the school data file and store it in a Pandas DataFrame.
school_data_df= pd.read_csv(school_data_to_load)
school_data_df
27/33:
# Read the student data file and store it in a Pandas DataFrame.
student_data_df = pd.read_csv(student_data_to_load)
student_data_df.head()
27/34:
# Add each prefix and suffix to remove to a list.
prefixes_suffixes = ["Dr. ", "Mr. ","Ms. ", "Mrs. ", "Miss ", " MD", " DDS", " DVM", " PhD"]
27/35:
# Iterate through the words in the "prefixes_suffixes" list and replace them with an empty space, "".
for word in prefixes_suffixes:
    student_data_df["student_name"] = student_data_df["student_name"].str.replace(word,"")
27/36:
# Iterate through the words in the "prefixes_suffixes" list and replace them with an empty space, "".
for word in prefixes_suffixes:
    student_data_df["student_name"] = student_data_df["student_name"].str.replace(word,"")
    print(student_data_df)
27/37:
# Iterate through the words in the "prefixes_suffixes" list and replace them with an empty space, "".
for word in prefixes_suffixes:
    student_data_df["student_name"] = student_data_df["student_name"].str.replace(word,"")
    print(student_data_df.head(10))
29/71:
for word in prefixes_suffixes:
    student_data_df["student_name"] = student_data_df["student_name"].str.replace(word,"")
    print(student_data_df.head(10))
    regex="False"
29/72:
for word in prefixes_suffixes:
    student_data_df["student_name"] = student_data_df["student_name"].str.replace(word,"")
    print(student_data_df.head(10))
    regex=False
29/73:
for word in prefixes_suffixes:
    student_data_df["student_name"] = student_data_df["student_name"].str.replace(word,"",regex=True)
    print(student_data_df.head(10))
    regex=False
29/74:
for word in prefixes_suffixes:
    student_data_df["student_name"] = student_data_df["student_name"].str.replace(word,"",regex=True)
    print(student_data_df.head(10))
29/75:
for word in prefixes_suffixes:
    student_data_df["student_name"] = student_data_df["student_name"].str.replace(word,"",regex=False)
    print(student_data_df.head(10))
27/38:
# Iterate through the words in the "prefixes_suffixes" list and replace them with an empty space, "".
for word in prefixes_suffixes:
    student_data_df["student_name"] = student_data_df["student_name"].str.replace(word,"",regex=True)
    print(student_data_df.head(10))
30/1:
# Dependencies
import pandas as pd
import numpy as np
30/2:
# Name of the CSV file
file = 'Resources/donors2008.csv'
30/3:
# Dependencies
import pandas as pd
import numpy as np
30/4:
# Drop all rows with missing information
df = df.dropna(how='all')
30/5:
# Drop all rows with missing information
df = df.dropna(how='any')
30/6:
# Identify incomplete rows
df.count()
30/7:
# Delete extraneous column
del df['FIELD8']
df.head()
30/8:
# Drop all rows with missing information
df = df.dropna(how='any')
30/9:
# Dependencies
import pandas as pd
import numpy as np
30/10:
# Name of the CSV file
file = 'Resources/donors2008.csv'
30/11:
# The correct encoding must be used to read the CSV in pandas
df = pd.read_csv(file, encoding="ISO-8859-1")
30/12:
# Preview of the DataFrame
# Note that FIELD8 is likely a meaningless column
df.head()
30/13:
# Delete extraneous column
del df['FIELD8']
df.head()
30/14:
# Identify incomplete rows
df.count()
30/15:
# Drop all rows with missing information
df = df.dropna(how='any')
30/16:
# Verify dropped rows
df.count()
30/17:
# Identify incomplete rows
df.count()
30/18:
# Drop all rows with missing information
df = df.dropna(how='all')
30/19:
# Verify dropped rows
df.count()
32/1:
# Multiple conditions can be set to narrow down or widen the filter
only_billy_and_peter = df.loc[(df["first_name"] == "Billy") | (
    df["first_name"] == "Peter"), ]

only_billy_and_peter
32/2: import pandas as pd
32/3: file = "Resources/sampleData.csv"
32/4:
original_df = pd.read_csv(file)
original_df.head()
32/5:
# Set new index to last_name
df = original_df.set_index("last_name")
df.head()
32/6:
# Grab the data contained within the "Berry" row and the "Phone Number" column
berry_phone = df.loc["Berry", "Phone Number"]
print("Using Loc: " + berry_phone)

also_berry_phone = df.iloc[1, 2]
print("Using Iloc: " + also_berry_phone)
32/7:
# Grab the first five rows of data and the columns from "id" to "Phone Number"
# The problem with using "last_name" as the index is that the values are not unique so duplicates are returned
# If there are duplicates and loc[] is being used, Pandas will return an error
richardson_to_morales = df.loc[["Richardson", "Berry", "Hudson",
                                "Mcdonald", "Morales"], ["id", "first_name", "Phone Number"]]
richardson_to_morales
32/8:
# Using iloc[] will not find duplicates since a numeric index is always unique
also_richardson_to_morales = df.iloc[0:4, 0:3]
also_richardson_to_morales
32/9:
# The following will select all rows for columns `first_name` and `Phone Number`
df.loc[:, ["first_name", "Phone Number"]].head()
32/10:
# the following logic test/conditional statement returns a series of boolean values
named_billy = df["first_name"] == "Billy"
named_billy.head()
32/11:
# Loc and Iloc also allow for conditional statments to filter rows of data
# using Loc on the logic test above only returns rows where the result is True
only_billys = df.loc[df["first_name"] == "Billy", :]
only_billys
32/12:
# Loc and Iloc also allow for conditional statments to filter rows of data
# using Loc on the logic test above only returns rows where the result is True
only_billys = df.loc[df["first_name"] == "Billy":]
only_billys
32/13:
# Loc and Iloc also allow for conditional statments to filter rows of data
# using Loc on the logic test above only returns rows where the result is True
only_billys = df.loc[df["first_name"] == "Billy", :]
only_billys
33/1:
# Read and display the CSV with Pandas
original_df = pd.read_csv(movie_file)
original_df.head()
33/2:
# Read and display the CSV with Pandas
movie_file_df = pd.read_csv(file)
movie_file_df.head()
33/3:
# Read and display the CSV with Pandas
movie_file_df = pd.read_csv(movie_file)
movie_file_df.head()
33/4:
# Dependencie
import pandas as pd
33/5:
# Load in file
movie_file = "Resources/movie_scores.csv"
33/6:
# Read and display the CSV with Pandas
movie_file_df = pd.read_csv(movie_file)
movie_file_df.head()
33/7:
# List all the columns in the table
movie_file_df.columns
34/1:
# Count how many sightings have occured within each state
state_counts = usa_ufo_df["state"].value_counts()
state_counts.head()
34/2:
# Import Dependencies
import pandas as pd
34/3:
# Create a reference the CSV file desired
csv_path = "Resources/ufoSightings.csv"

# Read the CSV into a Pandas DataFrame
ufo_df = pd.read_csv(csv_path, low_memory = False)

# Print the first five rows of data to the screen
ufo_df.head()
34/4:
# Remove the rows with missing data
clean_ufo_df = ufo_df.dropna(how="any")
clean_ufo_df.count()
34/5: clean_ufo_df.head()
34/6: clean_ufo_df.dtypes
34/7:
# Converting the "duration (seconds)" column's values to numeric
converted_ufo = clean_ufo_df.copy()
converted_ufo["duration (seconds)"] = converted_ufo.loc[:, "duration (seconds)"].astype(float)
34/8: converted_ufo.dtypes
34/9: converted_ufo.head()
34/10:
# Filter the data so that only those sightings in the US are in a DataFrame
usa_ufo_df = converted_ufo.loc[converted_ufo["country"] == "us", :]
usa_ufo_df.head()
34/11:
# Count how many sightings have occured within each state
state_counts = usa_ufo_df["state"].value_counts()
state_counts.head()
34/12:
# Using GroupBy in order to separate the data into fields according to "state" values
grouped_usa_df = usa_ufo_df.groupby(['state'])

# The object returned is a "GroupBy" object and cannot be viewed normally...
print(grouped_usa_df)

# In order to be visualized, a data function must be used...
grouped_usa_df.count().head(10)
34/13:
# Since "duration (seconds)" was converted to a numeric time, it can now be summed up per state
state_duration = grouped_usa_df["duration (seconds)"].sum()
state_duration.head()
35/1:
# Import Dependencies
import pandas as pd
35/2:
# A seriously gigantic DataFrame of individuals' names, their trainers, their weight, and their days as gym members
training_data = pd.DataFrame({
    "Name":["Gino Walker","Hiedi Wasser","Kerrie Wetzel","Elizabeth Sackett","Jack Mitten","Madalene Wayman","Jamee Horvath","Arlena Reddin","Tula Levan","Teisha Dreier","Leslie Carrier","Arlette Hartson","Romana Merkle","Heath Viviani","Andres Zimmer","Allyson Osman","Yadira Caggiano","Jeanmarie Friedrichs","Leann Ussery","Bee Mom","Pandora Charland","Karena Wooten","Elizabet Albanese","Augusta Borjas","Erma Yadon","Belia Lenser","Karmen Sancho","Edison Mannion","Sonja Hornsby","Morgan Frei","Florencio Murphy","Christoper Hertel","Thalia Stepney","Tarah Argento","Nicol Canfield","Pok Moretti","Barbera Stallings","Muoi Kelso","Cicely Ritz","Sid Demelo","Eura Langan","Vanita An","Frieda Fuhr","Ernest Fitzhenry","Ashlyn Tash","Melodi Mclendon","Rochell Leblanc","Jacqui Reasons","Freeda Mccroy","Vanna Runk","Florinda Milot","Cierra Lecompte","Nancey Kysar","Latasha Dalton","Charlyn Rinaldi","Erline Averett","Mariko Hillary","Rosalyn Trigg","Sherwood Brauer","Hortencia Olesen","Delana Kohut","Geoffrey Mcdade","Iona Delancey","Donnie Read","Cesar Bhatia","Evia Slate","Kaye Hugo","Denise Vento","Lang Kittle","Sherry Whittenberg","Jodi Bracero","Tamera Linneman","Katheryn Koelling","Tonia Shorty","Misha Baxley","Lisbeth Goering","Merle Ladwig","Tammie Omar","Jesusa Avilla","Alda Zabala","Junita Dogan","Jessia Anglin","Peggie Scranton","Dania Clodfelter","Janis Mccarthy","Edmund Galusha","Tonisha Posey","Arvilla Medley","Briana Barbour","Delfina Kiger","Nia Lenig","Ricarda Bulow","Odell Carson","Nydia Clonts","Andree Resendez","Daniela Puma","Sherill Paavola","Gilbert Bloomquist","Shanon Mach","Justin Bangert","Arden Hokanson","Evelyne Bridge","Hee Simek","Ward Deangelis","Jodie Childs","Janis Boehme","Beaulah Glowacki","Denver Stoneham","Tarra Vinton","Deborah Hummell","Ulysses Neil","Kathryn Marques","Rosanna Dake","Gavin Wheat","Tameka Stoke","Janella Clear","Kaye Ciriaco","Suk Bloxham","Gracia Whaley","Philomena Hemingway","Claudette Vaillancourt","Olevia Piche","Trey Chiles","Idalia Scardina","Jenine Tremble","Herbert Krider","Alycia Schrock","Miss Weibel","Pearlene Neidert","Kina Callender","Charlotte Skelley","Theodora Harrigan","Sydney Shreffler","Annamae Trinidad","Tobi Mumme","Rosia Elliot","Debbra Putt","Rena Delosantos","Genna Grennan","Nieves Huf","Berry Lugo","Ayana Verdugo","Joaquin Mazzei","Doris Harmon","Patience Poss","Magaret Zabel","Marylynn Hinojos","Earlene Marcantel","Yuki Evensen","Rema Gay","Delana Haak","Patricia Fetters","Vinnie Elrod","Octavia Bellew","Burma Revard","Lakenya Kato","Vinita Buchner","Sierra Margulies","Shae Funderburg","Jenae Groleau","Louetta Howie","Astrid Duffer","Caron Altizer","Kymberly Amavisca","Mohammad Diedrich","Thora Wrinkle","Bethel Wiemann","Patria Millet","Eldridge Burbach","Alyson Eddie","Zula Hanna","Devin Goodwin","Felipa Kirkwood","Kurtis Kempf","Kasey Lenart","Deena Blankenship","Kandra Wargo","Sherrie Cieslak","Ron Atha","Reggie Barreiro","Daria Saulter","Tandra Eastman","Donnell Lucious","Talisha Rosner","Emiko Bergh","Terresa Launius","Margy Hoobler","Marylou Stelling","Lavonne Justice","Kala Langstaff","China Truett","Louanne Dussault","Thomasena Samaniego","Charlesetta Tarbell","Fatimah Lade","Malisa Cantero","Florencia Litten","Francina Fraise","Patsy London","Deloris Mclaughlin"],
    "Trainer":['Bettyann Savory','Mariah Barberio','Gordon Perrine','Pa Dargan','Blanch Victoria','Aldo Byler','Aldo Byler','Williams Camire','Junie Ritenour','Gordon Perrine','Bettyann Savory','Mariah Barberio','Aldo Byler','Barton Stecklein','Bettyann Savory','Barton Stecklein','Gordon Perrine','Pa Dargan','Aldo Byler','Brittani Brin','Bettyann Savory','Phyliss Houk','Bettyann Savory','Junie Ritenour','Aldo Byler','Calvin North','Brittani Brin','Junie Ritenour','Blanch Victoria','Brittani Brin','Bettyann Savory','Blanch Victoria','Mariah Barberio','Bettyann Savory','Blanch Victoria','Brittani Brin','Junie Ritenour','Pa Dargan','Gordon Perrine','Phyliss Houk','Pa Dargan','Mariah Barberio','Phyliss Houk','Phyliss Houk','Calvin North','Williams Camire','Brittani Brin','Gordon Perrine','Bettyann Savory','Bettyann Savory','Pa Dargan','Phyliss Houk','Barton Stecklein','Blanch Victoria','Coleman Dunmire','Phyliss Houk','Blanch Victoria','Pa Dargan','Harland Coolidge','Calvin North','Bettyann Savory','Phyliss Houk','Bettyann Savory','Harland Coolidge','Gordon Perrine','Junie Ritenour','Harland Coolidge','Blanch Victoria','Mariah Barberio','Coleman Dunmire','Aldo Byler','Bettyann Savory','Gordon Perrine','Bettyann Savory','Barton Stecklein','Harland Coolidge','Aldo Byler','Aldo Byler','Pa Dargan','Junie Ritenour','Brittani Brin','Junie Ritenour','Gordon Perrine','Mariah Barberio','Mariah Barberio','Mariah Barberio','Bettyann Savory','Brittani Brin','Aldo Byler','Phyliss Houk','Blanch Victoria','Pa Dargan','Phyliss Houk','Brittani Brin','Barton Stecklein','Coleman Dunmire','Bettyann Savory','Bettyann Savory','Gordon Perrine','Blanch Victoria','Junie Ritenour','Phyliss Houk','Coleman Dunmire','Williams Camire','Harland Coolidge','Williams Camire','Aldo Byler','Harland Coolidge','Gordon Perrine','Brittani Brin','Coleman Dunmire','Calvin North','Phyliss Houk','Brittani Brin','Aldo Byler','Bettyann Savory','Brittani Brin','Gordon Perrine','Calvin North','Harland Coolidge','Coleman Dunmire','Harland Coolidge','Aldo Byler','Junie Ritenour','Blanch Victoria','Harland Coolidge','Blanch Victoria','Junie Ritenour','Harland Coolidge','Junie Ritenour','Gordon Perrine','Brittani Brin','Coleman Dunmire','Williams Camire','Junie Ritenour','Brittani Brin','Calvin North','Barton Stecklein','Barton Stecklein','Mariah Barberio','Coleman Dunmire','Bettyann Savory','Mariah Barberio','Pa Dargan','Barton Stecklein','Coleman Dunmire','Brittani Brin','Barton Stecklein','Pa Dargan','Barton Stecklein','Junie Ritenour','Bettyann Savory','Williams Camire','Pa Dargan','Calvin North','Williams Camire','Coleman Dunmire','Aldo Byler','Barton Stecklein','Coleman Dunmire','Blanch Victoria','Mariah Barberio','Mariah Barberio','Harland Coolidge','Barton Stecklein','Phyliss Houk','Pa Dargan','Bettyann Savory','Barton Stecklein','Harland Coolidge','Junie Ritenour','Pa Dargan','Mariah Barberio','Blanch Victoria','Williams Camire','Phyliss Houk','Phyliss Houk','Coleman Dunmire','Mariah Barberio','Gordon Perrine','Coleman Dunmire','Brittani Brin','Pa Dargan','Coleman Dunmire','Brittani Brin','Blanch Victoria','Coleman Dunmire','Gordon Perrine','Coleman Dunmire','Aldo Byler','Aldo Byler','Mariah Barberio','Williams Camire','Phyliss Houk','Aldo Byler','Williams Camire','Aldo Byler','Williams Camire','Coleman Dunmire','Phyliss Houk'],
    "Weight":[128,180,193,177,237,166,224,208,177,241,114,161,162,151,220,142,193,193,124,130,132,141,190,239,213,131,172,127,184,157,215,122,181,240,218,205,239,217,234,158,180,131,194,171,177,110,117,114,217,123,248,189,198,127,182,121,224,111,151,170,188,150,137,231,222,186,139,175,178,246,150,154,129,216,144,198,228,183,173,129,157,199,186,232,172,157,246,239,214,161,132,208,187,224,164,177,175,224,219,235,112,241,243,179,208,196,131,207,182,233,191,162,173,197,190,182,231,196,196,143,250,174,138,135,164,204,235,192,114,179,215,127,185,213,250,213,153,217,176,190,119,167,118,208,113,206,200,236,159,218,168,159,156,183,121,203,215,209,179,219,174,220,129,188,217,250,166,157,112,236,182,144,189,243,238,147,165,115,160,134,245,174,238,157,150,184,174,134,134,248,199,165,117,119,162,112,170,224,247,217],
    "Membership (Days)":[52,70,148,124,186,157,127,155,37,185,158,129,93,69,124,13,76,153,164,161,48,121,167,69,39,163,7,34,176,169,108,162,195,86,155,77,197,200,80,142,179,67,58,145,188,147,125,15,13,173,125,4,61,29,132,110,62,137,197,135,162,174,32,151,149,65,18,42,63,62,104,200,189,40,38,199,1,12,8,2,195,30,7,72,130,144,2,34,200,143,43,196,22,115,171,54,143,59,14,52,109,115,187,185,26,19,178,18,120,169,45,52,130,69,168,178,96,22,78,152,39,51,118,130,60,156,108,69,103,158,165,142,86,91,117,77,57,169,86,188,97,111,22,83,81,177,163,35,12,164,21,181,171,138,22,107,58,51,38,128,19,193,157,13,104,89,13,10,26,190,179,101,7,159,100,49,120,109,56,199,51,108,47,171,69,162,74,119,148,88,32,159,65,146,140,171,88,18,59,13]
})
training_data.head()
37/1:
# Create a path to the csv and read it into a Pandas DataFrame
csv_path = "Resources/ted_talks.csv"
ted_df = pd.read_csv(csv_path)

ted_df.head()
37/2:
# Import Dependencies
import pandas as pd
37/3:
# Create a path to the csv and read it into a Pandas DataFrame
csv_path = "Resources/ted_talks.csv"
ted_df = pd.read_csv(csv_path)

ted_df.head()
37/4:
# Figure out the minimum and maximum views for a TED Talk
df=df("views")
df.describe
37/5:
# Create a path to the csv and read it into a Pandas DataFrame
csv_path = "Resources/ted_talks.csv"
ted_df = pd.read_csv(csv_path)

ted_df.head()
37/6:
# Figure out the minimum and maximum views for a TED Talk
df=df("views")
df.describe
37/7:
# Figure out the minimum and maximum views for a TED Talk
df=df("views")
df.describe()
37/8:
# Figure out the minimum and maximum views for a TED Talk
df=df.groupby("views")
df.describe()
37/9:
# Create a path to the csv and read it into a Pandas DataFrame
csv_path = "Resources/ted_talks.csv"
ted_df = pd.read_csv(csv_path)

ted_df.head()
39/1:
# A gigantic DataFrame of individuals' names, their trainers, their weight, and their days as gym members
training_df = pd.DataFrame({
    "Name":["Gino Walker","Hiedi Wasser","Kerrie Wetzel","Elizabeth Sackett","Jack Mitten","Madalene Wayman","Jamee Horvath","Arlena Reddin","Tula Levan","Teisha Dreier","Leslie Carrier","Arlette Hartson","Romana Merkle","Heath Viviani","Andres Zimmer","Allyson Osman","Yadira Caggiano","Jeanmarie Friedrichs","Leann Ussery","Bee Mom","Pandora Charland","Karena Wooten","Elizabet Albanese","Augusta Borjas","Erma Yadon","Belia Lenser","Karmen Sancho","Edison Mannion","Sonja Hornsby","Morgan Frei","Florencio Murphy","Christoper Hertel","Thalia Stepney","Tarah Argento","Nicol Canfield","Pok Moretti","Barbera Stallings","Muoi Kelso","Cicely Ritz","Sid Demelo","Eura Langan","Vanita An","Frieda Fuhr","Ernest Fitzhenry","Ashlyn Tash","Melodi Mclendon","Rochell Leblanc","Jacqui Reasons","Freeda Mccroy","Vanna Runk","Florinda Milot","Cierra Lecompte","Nancey Kysar","Latasha Dalton","Charlyn Rinaldi","Erline Averett","Mariko Hillary","Rosalyn Trigg","Sherwood Brauer","Hortencia Olesen","Delana Kohut","Geoffrey Mcdade","Iona Delancey","Donnie Read","Cesar Bhatia","Evia Slate","Kaye Hugo","Denise Vento","Lang Kittle","Sherry Whittenberg","Jodi Bracero","Tamera Linneman","Katheryn Koelling","Tonia Shorty","Misha Baxley","Lisbeth Goering","Merle Ladwig","Tammie Omar","Jesusa Avilla","Alda Zabala","Junita Dogan","Jessia Anglin","Peggie Scranton","Dania Clodfelter","Janis Mccarthy","Edmund Galusha","Tonisha Posey","Arvilla Medley","Briana Barbour","Delfina Kiger","Nia Lenig","Ricarda Bulow","Odell Carson","Nydia Clonts","Andree Resendez","Daniela Puma","Sherill Paavola","Gilbert Bloomquist","Shanon Mach","Justin Bangert","Arden Hokanson","Evelyne Bridge","Hee Simek","Ward Deangelis","Jodie Childs","Janis Boehme","Beaulah Glowacki","Denver Stoneham","Tarra Vinton","Deborah Hummell","Ulysses Neil","Kathryn Marques","Rosanna Dake","Gavin Wheat","Tameka Stoke","Janella Clear","Kaye Ciriaco","Suk Bloxham","Gracia Whaley","Philomena Hemingway","Claudette Vaillancourt","Olevia Piche","Trey Chiles","Idalia Scardina","Jenine Tremble","Herbert Krider","Alycia Schrock","Miss Weibel","Pearlene Neidert","Kina Callender","Charlotte Skelley","Theodora Harrigan","Sydney Shreffler","Annamae Trinidad","Tobi Mumme","Rosia Elliot","Debbra Putt","Rena Delosantos","Genna Grennan","Nieves Huf","Berry Lugo","Ayana Verdugo","Joaquin Mazzei","Doris Harmon","Patience Poss","Magaret Zabel","Marylynn Hinojos","Earlene Marcantel","Yuki Evensen","Rema Gay","Delana Haak","Patricia Fetters","Vinnie Elrod","Octavia Bellew","Burma Revard","Lakenya Kato","Vinita Buchner","Sierra Margulies","Shae Funderburg","Jenae Groleau","Louetta Howie","Astrid Duffer","Caron Altizer","Kymberly Amavisca","Mohammad Diedrich","Thora Wrinkle","Bethel Wiemann","Patria Millet","Eldridge Burbach","Alyson Eddie","Zula Hanna","Devin Goodwin","Felipa Kirkwood","Kurtis Kempf","Kasey Lenart","Deena Blankenship","Kandra Wargo","Sherrie Cieslak","Ron Atha","Reggie Barreiro","Daria Saulter","Tandra Eastman","Donnell Lucious","Talisha Rosner","Emiko Bergh","Terresa Launius","Margy Hoobler","Marylou Stelling","Lavonne Justice","Kala Langstaff","China Truett","Louanne Dussault","Thomasena Samaniego","Charlesetta Tarbell","Fatimah Lade","Malisa Cantero","Florencia Litten","Francina Fraise","Patsy London","Deloris Mclaughlin"],
    "Trainer":['Bettyann Savory','Mariah Barberio','Gordon Perrine','Pa Dargan','Blanch Victoria','Aldo Byler','Aldo Byler','Williams Camire','Junie Ritenour','Gordon Perrine','Bettyann Savory','Mariah Barberio','Aldo Byler','Barton Stecklein','Bettyann Savory','Barton Stecklein','Gordon Perrine','Pa Dargan','Aldo Byler','Brittani Brin','Bettyann Savory','Phyliss Houk','Bettyann Savory','Junie Ritenour','Aldo Byler','Calvin North','Brittani Brin','Junie Ritenour','Blanch Victoria','Brittani Brin','Bettyann Savory','Blanch Victoria','Mariah Barberio','Bettyann Savory','Blanch Victoria','Brittani Brin','Junie Ritenour','Pa Dargan','Gordon Perrine','Phyliss Houk','Pa Dargan','Mariah Barberio','Phyliss Houk','Phyliss Houk','Calvin North','Williams Camire','Brittani Brin','Gordon Perrine','Bettyann Savory','Bettyann Savory','Pa Dargan','Phyliss Houk','Barton Stecklein','Blanch Victoria','Coleman Dunmire','Phyliss Houk','Blanch Victoria','Pa Dargan','Harland Coolidge','Calvin North','Bettyann Savory','Phyliss Houk','Bettyann Savory','Harland Coolidge','Gordon Perrine','Junie Ritenour','Harland Coolidge','Blanch Victoria','Mariah Barberio','Coleman Dunmire','Aldo Byler','Bettyann Savory','Gordon Perrine','Bettyann Savory','Barton Stecklein','Harland Coolidge','Aldo Byler','Aldo Byler','Pa Dargan','Junie Ritenour','Brittani Brin','Junie Ritenour','Gordon Perrine','Mariah Barberio','Mariah Barberio','Mariah Barberio','Bettyann Savory','Brittani Brin','Aldo Byler','Phyliss Houk','Blanch Victoria','Pa Dargan','Phyliss Houk','Brittani Brin','Barton Stecklein','Coleman Dunmire','Bettyann Savory','Bettyann Savory','Gordon Perrine','Blanch Victoria','Junie Ritenour','Phyliss Houk','Coleman Dunmire','Williams Camire','Harland Coolidge','Williams Camire','Aldo Byler','Harland Coolidge','Gordon Perrine','Brittani Brin','Coleman Dunmire','Calvin North','Phyliss Houk','Brittani Brin','Aldo Byler','Bettyann Savory','Brittani Brin','Gordon Perrine','Calvin North','Harland Coolidge','Coleman Dunmire','Harland Coolidge','Aldo Byler','Junie Ritenour','Blanch Victoria','Harland Coolidge','Blanch Victoria','Junie Ritenour','Harland Coolidge','Junie Ritenour','Gordon Perrine','Brittani Brin','Coleman Dunmire','Williams Camire','Junie Ritenour','Brittani Brin','Calvin North','Barton Stecklein','Barton Stecklein','Mariah Barberio','Coleman Dunmire','Bettyann Savory','Mariah Barberio','Pa Dargan','Barton Stecklein','Coleman Dunmire','Brittani Brin','Barton Stecklein','Pa Dargan','Barton Stecklein','Junie Ritenour','Bettyann Savory','Williams Camire','Pa Dargan','Calvin North','Williams Camire','Coleman Dunmire','Aldo Byler','Barton Stecklein','Coleman Dunmire','Blanch Victoria','Mariah Barberio','Mariah Barberio','Harland Coolidge','Barton Stecklein','Phyliss Houk','Pa Dargan','Bettyann Savory','Barton Stecklein','Harland Coolidge','Junie Ritenour','Pa Dargan','Mariah Barberio','Blanch Victoria','Williams Camire','Phyliss Houk','Phyliss Houk','Coleman Dunmire','Mariah Barberio','Gordon Perrine','Coleman Dunmire','Brittani Brin','Pa Dargan','Coleman Dunmire','Brittani Brin','Blanch Victoria','Coleman Dunmire','Gordon Perrine','Coleman Dunmire','Aldo Byler','Aldo Byler','Mariah Barberio','Williams Camire','Phyliss Houk','Aldo Byler','Williams Camire','Aldo Byler','Williams Camire','Coleman Dunmire','Phyliss Houk'],
    "Weight":[128,180,193,177,237,166,224,208,177,241,114,161,162,151,220,142,193,193,124,130,132,141,190,239,213,131,172,127,184,157,215,122,181,240,218,205,239,217,234,158,180,131,194,171,177,110,117,114,217,123,248,189,198,127,182,121,224,111,151,170,188,150,137,231,222,186,139,175,178,246,150,154,129,216,144,198,228,183,173,129,157,199,186,232,172,157,246,239,214,161,132,208,187,224,164,177,175,224,219,235,112,241,243,179,208,196,131,207,182,233,191,162,173,197,190,182,231,196,196,143,250,174,138,135,164,204,235,192,114,179,215,127,185,213,250,213,153,217,176,190,119,167,118,208,113,206,200,236,159,218,168,159,156,183,121,203,215,209,179,219,174,220,129,188,217,250,166,157,112,236,182,144,189,243,238,147,165,115,160,134,245,174,238,157,150,184,174,134,134,248,199,165,117,119,162,112,170,224,247,217],
    "Membership(Days)":[52,70,148,124,186,157,127,155,37,185,158,129,93,69,124,13,76,153,164,161,48,121,167,69,39,163,7,34,176,169,108,162,195,86,155,77,197,200,80,142,179,67,58,145,188,147,125,15,13,173,125,4,61,29,132,110,62,137,197,135,162,174,32,151,149,65,18,42,63,62,104,200,189,40,38,199,1,12,8,2,195,30,7,72,130,144,2,34,200,143,43,196,22,115,171,54,143,59,14,52,109,115,187,185,26,19,178,18,120,169,45,52,130,69,168,178,96,22,78,152,39,51,118,130,60,156,108,69,103,158,165,142,86,91,117,77,57,169,86,188,97,111,22,83,81,177,163,35,12,164,21,181,171,138,22,107,58,51,38,128,19,193,157,13,104,89,13,10,26,190,179,101,7,159,100,49,120,109,56,199,51,108,47,171,69,162,74,119,148,88,32,159,65,146,140,171,88,18,59,13]
})
training_df.head()
39/2:
# Import Dependencies
import pandas as pd
39/3:
# A gigantic DataFrame of individuals' names, their trainers, their weight, and their days as gym members
training_df = pd.DataFrame({
    "Name":["Gino Walker","Hiedi Wasser","Kerrie Wetzel","Elizabeth Sackett","Jack Mitten","Madalene Wayman","Jamee Horvath","Arlena Reddin","Tula Levan","Teisha Dreier","Leslie Carrier","Arlette Hartson","Romana Merkle","Heath Viviani","Andres Zimmer","Allyson Osman","Yadira Caggiano","Jeanmarie Friedrichs","Leann Ussery","Bee Mom","Pandora Charland","Karena Wooten","Elizabet Albanese","Augusta Borjas","Erma Yadon","Belia Lenser","Karmen Sancho","Edison Mannion","Sonja Hornsby","Morgan Frei","Florencio Murphy","Christoper Hertel","Thalia Stepney","Tarah Argento","Nicol Canfield","Pok Moretti","Barbera Stallings","Muoi Kelso","Cicely Ritz","Sid Demelo","Eura Langan","Vanita An","Frieda Fuhr","Ernest Fitzhenry","Ashlyn Tash","Melodi Mclendon","Rochell Leblanc","Jacqui Reasons","Freeda Mccroy","Vanna Runk","Florinda Milot","Cierra Lecompte","Nancey Kysar","Latasha Dalton","Charlyn Rinaldi","Erline Averett","Mariko Hillary","Rosalyn Trigg","Sherwood Brauer","Hortencia Olesen","Delana Kohut","Geoffrey Mcdade","Iona Delancey","Donnie Read","Cesar Bhatia","Evia Slate","Kaye Hugo","Denise Vento","Lang Kittle","Sherry Whittenberg","Jodi Bracero","Tamera Linneman","Katheryn Koelling","Tonia Shorty","Misha Baxley","Lisbeth Goering","Merle Ladwig","Tammie Omar","Jesusa Avilla","Alda Zabala","Junita Dogan","Jessia Anglin","Peggie Scranton","Dania Clodfelter","Janis Mccarthy","Edmund Galusha","Tonisha Posey","Arvilla Medley","Briana Barbour","Delfina Kiger","Nia Lenig","Ricarda Bulow","Odell Carson","Nydia Clonts","Andree Resendez","Daniela Puma","Sherill Paavola","Gilbert Bloomquist","Shanon Mach","Justin Bangert","Arden Hokanson","Evelyne Bridge","Hee Simek","Ward Deangelis","Jodie Childs","Janis Boehme","Beaulah Glowacki","Denver Stoneham","Tarra Vinton","Deborah Hummell","Ulysses Neil","Kathryn Marques","Rosanna Dake","Gavin Wheat","Tameka Stoke","Janella Clear","Kaye Ciriaco","Suk Bloxham","Gracia Whaley","Philomena Hemingway","Claudette Vaillancourt","Olevia Piche","Trey Chiles","Idalia Scardina","Jenine Tremble","Herbert Krider","Alycia Schrock","Miss Weibel","Pearlene Neidert","Kina Callender","Charlotte Skelley","Theodora Harrigan","Sydney Shreffler","Annamae Trinidad","Tobi Mumme","Rosia Elliot","Debbra Putt","Rena Delosantos","Genna Grennan","Nieves Huf","Berry Lugo","Ayana Verdugo","Joaquin Mazzei","Doris Harmon","Patience Poss","Magaret Zabel","Marylynn Hinojos","Earlene Marcantel","Yuki Evensen","Rema Gay","Delana Haak","Patricia Fetters","Vinnie Elrod","Octavia Bellew","Burma Revard","Lakenya Kato","Vinita Buchner","Sierra Margulies","Shae Funderburg","Jenae Groleau","Louetta Howie","Astrid Duffer","Caron Altizer","Kymberly Amavisca","Mohammad Diedrich","Thora Wrinkle","Bethel Wiemann","Patria Millet","Eldridge Burbach","Alyson Eddie","Zula Hanna","Devin Goodwin","Felipa Kirkwood","Kurtis Kempf","Kasey Lenart","Deena Blankenship","Kandra Wargo","Sherrie Cieslak","Ron Atha","Reggie Barreiro","Daria Saulter","Tandra Eastman","Donnell Lucious","Talisha Rosner","Emiko Bergh","Terresa Launius","Margy Hoobler","Marylou Stelling","Lavonne Justice","Kala Langstaff","China Truett","Louanne Dussault","Thomasena Samaniego","Charlesetta Tarbell","Fatimah Lade","Malisa Cantero","Florencia Litten","Francina Fraise","Patsy London","Deloris Mclaughlin"],
    "Trainer":['Bettyann Savory','Mariah Barberio','Gordon Perrine','Pa Dargan','Blanch Victoria','Aldo Byler','Aldo Byler','Williams Camire','Junie Ritenour','Gordon Perrine','Bettyann Savory','Mariah Barberio','Aldo Byler','Barton Stecklein','Bettyann Savory','Barton Stecklein','Gordon Perrine','Pa Dargan','Aldo Byler','Brittani Brin','Bettyann Savory','Phyliss Houk','Bettyann Savory','Junie Ritenour','Aldo Byler','Calvin North','Brittani Brin','Junie Ritenour','Blanch Victoria','Brittani Brin','Bettyann Savory','Blanch Victoria','Mariah Barberio','Bettyann Savory','Blanch Victoria','Brittani Brin','Junie Ritenour','Pa Dargan','Gordon Perrine','Phyliss Houk','Pa Dargan','Mariah Barberio','Phyliss Houk','Phyliss Houk','Calvin North','Williams Camire','Brittani Brin','Gordon Perrine','Bettyann Savory','Bettyann Savory','Pa Dargan','Phyliss Houk','Barton Stecklein','Blanch Victoria','Coleman Dunmire','Phyliss Houk','Blanch Victoria','Pa Dargan','Harland Coolidge','Calvin North','Bettyann Savory','Phyliss Houk','Bettyann Savory','Harland Coolidge','Gordon Perrine','Junie Ritenour','Harland Coolidge','Blanch Victoria','Mariah Barberio','Coleman Dunmire','Aldo Byler','Bettyann Savory','Gordon Perrine','Bettyann Savory','Barton Stecklein','Harland Coolidge','Aldo Byler','Aldo Byler','Pa Dargan','Junie Ritenour','Brittani Brin','Junie Ritenour','Gordon Perrine','Mariah Barberio','Mariah Barberio','Mariah Barberio','Bettyann Savory','Brittani Brin','Aldo Byler','Phyliss Houk','Blanch Victoria','Pa Dargan','Phyliss Houk','Brittani Brin','Barton Stecklein','Coleman Dunmire','Bettyann Savory','Bettyann Savory','Gordon Perrine','Blanch Victoria','Junie Ritenour','Phyliss Houk','Coleman Dunmire','Williams Camire','Harland Coolidge','Williams Camire','Aldo Byler','Harland Coolidge','Gordon Perrine','Brittani Brin','Coleman Dunmire','Calvin North','Phyliss Houk','Brittani Brin','Aldo Byler','Bettyann Savory','Brittani Brin','Gordon Perrine','Calvin North','Harland Coolidge','Coleman Dunmire','Harland Coolidge','Aldo Byler','Junie Ritenour','Blanch Victoria','Harland Coolidge','Blanch Victoria','Junie Ritenour','Harland Coolidge','Junie Ritenour','Gordon Perrine','Brittani Brin','Coleman Dunmire','Williams Camire','Junie Ritenour','Brittani Brin','Calvin North','Barton Stecklein','Barton Stecklein','Mariah Barberio','Coleman Dunmire','Bettyann Savory','Mariah Barberio','Pa Dargan','Barton Stecklein','Coleman Dunmire','Brittani Brin','Barton Stecklein','Pa Dargan','Barton Stecklein','Junie Ritenour','Bettyann Savory','Williams Camire','Pa Dargan','Calvin North','Williams Camire','Coleman Dunmire','Aldo Byler','Barton Stecklein','Coleman Dunmire','Blanch Victoria','Mariah Barberio','Mariah Barberio','Harland Coolidge','Barton Stecklein','Phyliss Houk','Pa Dargan','Bettyann Savory','Barton Stecklein','Harland Coolidge','Junie Ritenour','Pa Dargan','Mariah Barberio','Blanch Victoria','Williams Camire','Phyliss Houk','Phyliss Houk','Coleman Dunmire','Mariah Barberio','Gordon Perrine','Coleman Dunmire','Brittani Brin','Pa Dargan','Coleman Dunmire','Brittani Brin','Blanch Victoria','Coleman Dunmire','Gordon Perrine','Coleman Dunmire','Aldo Byler','Aldo Byler','Mariah Barberio','Williams Camire','Phyliss Houk','Aldo Byler','Williams Camire','Aldo Byler','Williams Camire','Coleman Dunmire','Phyliss Houk'],
    "Weight":[128,180,193,177,237,166,224,208,177,241,114,161,162,151,220,142,193,193,124,130,132,141,190,239,213,131,172,127,184,157,215,122,181,240,218,205,239,217,234,158,180,131,194,171,177,110,117,114,217,123,248,189,198,127,182,121,224,111,151,170,188,150,137,231,222,186,139,175,178,246,150,154,129,216,144,198,228,183,173,129,157,199,186,232,172,157,246,239,214,161,132,208,187,224,164,177,175,224,219,235,112,241,243,179,208,196,131,207,182,233,191,162,173,197,190,182,231,196,196,143,250,174,138,135,164,204,235,192,114,179,215,127,185,213,250,213,153,217,176,190,119,167,118,208,113,206,200,236,159,218,168,159,156,183,121,203,215,209,179,219,174,220,129,188,217,250,166,157,112,236,182,144,189,243,238,147,165,115,160,134,245,174,238,157,150,184,174,134,134,248,199,165,117,119,162,112,170,224,247,217],
    "Membership(Days)":[52,70,148,124,186,157,127,155,37,185,158,129,93,69,124,13,76,153,164,161,48,121,167,69,39,163,7,34,176,169,108,162,195,86,155,77,197,200,80,142,179,67,58,145,188,147,125,15,13,173,125,4,61,29,132,110,62,137,197,135,162,174,32,151,149,65,18,42,63,62,104,200,189,40,38,199,1,12,8,2,195,30,7,72,130,144,2,34,200,143,43,196,22,115,171,54,143,59,14,52,109,115,187,185,26,19,178,18,120,169,45,52,130,69,168,178,96,22,78,152,39,51,118,130,60,156,108,69,103,158,165,142,86,91,117,77,57,169,86,188,97,111,22,83,81,177,163,35,12,164,21,181,171,138,22,107,58,51,38,128,19,193,157,13,104,89,13,10,26,190,179,101,7,159,100,49,120,109,56,199,51,108,47,171,69,162,74,119,148,88,32,159,65,146,140,171,88,18,59,13]
})
training_df.head()
39/4:
# A gigantic DataFrame of individuals' names, their trainers, their weight, and their days as gym members
training_df = pd.DataFrame({
    "Name":["Gino Walker","Hiedi Wasser","Kerrie Wetzel","Elizabeth Sackett","Jack Mitten","Madalene Wayman","Jamee Horvath","Arlena Reddin","Tula Levan","Teisha Dreier","Leslie Carrier","Arlette Hartson","Romana Merkle","Heath Viviani","Andres Zimmer","Allyson Osman","Yadira Caggiano","Jeanmarie Friedrichs","Leann Ussery","Bee Mom","Pandora Charland","Karena Wooten","Elizabet Albanese","Augusta Borjas","Erma Yadon","Belia Lenser","Karmen Sancho","Edison Mannion","Sonja Hornsby","Morgan Frei","Florencio Murphy","Christoper Hertel","Thalia Stepney","Tarah Argento","Nicol Canfield","Pok Moretti","Barbera Stallings","Muoi Kelso","Cicely Ritz","Sid Demelo","Eura Langan","Vanita An","Frieda Fuhr","Ernest Fitzhenry","Ashlyn Tash","Melodi Mclendon","Rochell Leblanc","Jacqui Reasons","Freeda Mccroy","Vanna Runk","Florinda Milot","Cierra Lecompte","Nancey Kysar","Latasha Dalton","Charlyn Rinaldi","Erline Averett","Mariko Hillary","Rosalyn Trigg","Sherwood Brauer","Hortencia Olesen","Delana Kohut","Geoffrey Mcdade","Iona Delancey","Donnie Read","Cesar Bhatia","Evia Slate","Kaye Hugo","Denise Vento","Lang Kittle","Sherry Whittenberg","Jodi Bracero","Tamera Linneman","Katheryn Koelling","Tonia Shorty","Misha Baxley","Lisbeth Goering","Merle Ladwig","Tammie Omar","Jesusa Avilla","Alda Zabala","Junita Dogan","Jessia Anglin","Peggie Scranton","Dania Clodfelter","Janis Mccarthy","Edmund Galusha","Tonisha Posey","Arvilla Medley","Briana Barbour","Delfina Kiger","Nia Lenig","Ricarda Bulow","Odell Carson","Nydia Clonts","Andree Resendez","Daniela Puma","Sherill Paavola","Gilbert Bloomquist","Shanon Mach","Justin Bangert","Arden Hokanson","Evelyne Bridge","Hee Simek","Ward Deangelis","Jodie Childs","Janis Boehme","Beaulah Glowacki","Denver Stoneham","Tarra Vinton","Deborah Hummell","Ulysses Neil","Kathryn Marques","Rosanna Dake","Gavin Wheat","Tameka Stoke","Janella Clear","Kaye Ciriaco","Suk Bloxham","Gracia Whaley","Philomena Hemingway","Claudette Vaillancourt","Olevia Piche","Trey Chiles","Idalia Scardina","Jenine Tremble","Herbert Krider","Alycia Schrock","Miss Weibel","Pearlene Neidert","Kina Callender","Charlotte Skelley","Theodora Harrigan","Sydney Shreffler","Annamae Trinidad","Tobi Mumme","Rosia Elliot","Debbra Putt","Rena Delosantos","Genna Grennan","Nieves Huf","Berry Lugo","Ayana Verdugo","Joaquin Mazzei","Doris Harmon","Patience Poss","Magaret Zabel","Marylynn Hinojos","Earlene Marcantel","Yuki Evensen","Rema Gay","Delana Haak","Patricia Fetters","Vinnie Elrod","Octavia Bellew","Burma Revard","Lakenya Kato","Vinita Buchner","Sierra Margulies","Shae Funderburg","Jenae Groleau","Louetta Howie","Astrid Duffer","Caron Altizer","Kymberly Amavisca","Mohammad Diedrich","Thora Wrinkle","Bethel Wiemann","Patria Millet","Eldridge Burbach","Alyson Eddie","Zula Hanna","Devin Goodwin","Felipa Kirkwood","Kurtis Kempf","Kasey Lenart","Deena Blankenship","Kandra Wargo","Sherrie Cieslak","Ron Atha","Reggie Barreiro","Daria Saulter","Tandra Eastman","Donnell Lucious","Talisha Rosner","Emiko Bergh","Terresa Launius","Margy Hoobler","Marylou Stelling","Lavonne Justice","Kala Langstaff","China Truett","Louanne Dussault","Thomasena Samaniego","Charlesetta Tarbell","Fatimah Lade","Malisa Cantero","Florencia Litten","Francina Fraise","Patsy London","Deloris Mclaughlin"],
    "Trainer":['Bettyann Savory','Mariah Barberio','Gordon Perrine','Pa Dargan','Blanch Victoria','Aldo Byler','Aldo Byler','Williams Camire','Junie Ritenour','Gordon Perrine','Bettyann Savory','Mariah Barberio','Aldo Byler','Barton Stecklein','Bettyann Savory','Barton Stecklein','Gordon Perrine','Pa Dargan','Aldo Byler','Brittani Brin','Bettyann Savory','Phyliss Houk','Bettyann Savory','Junie Ritenour','Aldo Byler','Calvin North','Brittani Brin','Junie Ritenour','Blanch Victoria','Brittani Brin','Bettyann Savory','Blanch Victoria','Mariah Barberio','Bettyann Savory','Blanch Victoria','Brittani Brin','Junie Ritenour','Pa Dargan','Gordon Perrine','Phyliss Houk','Pa Dargan','Mariah Barberio','Phyliss Houk','Phyliss Houk','Calvin North','Williams Camire','Brittani Brin','Gordon Perrine','Bettyann Savory','Bettyann Savory','Pa Dargan','Phyliss Houk','Barton Stecklein','Blanch Victoria','Coleman Dunmire','Phyliss Houk','Blanch Victoria','Pa Dargan','Harland Coolidge','Calvin North','Bettyann Savory','Phyliss Houk','Bettyann Savory','Harland Coolidge','Gordon Perrine','Junie Ritenour','Harland Coolidge','Blanch Victoria','Mariah Barberio','Coleman Dunmire','Aldo Byler','Bettyann Savory','Gordon Perrine','Bettyann Savory','Barton Stecklein','Harland Coolidge','Aldo Byler','Aldo Byler','Pa Dargan','Junie Ritenour','Brittani Brin','Junie Ritenour','Gordon Perrine','Mariah Barberio','Mariah Barberio','Mariah Barberio','Bettyann Savory','Brittani Brin','Aldo Byler','Phyliss Houk','Blanch Victoria','Pa Dargan','Phyliss Houk','Brittani Brin','Barton Stecklein','Coleman Dunmire','Bettyann Savory','Bettyann Savory','Gordon Perrine','Blanch Victoria','Junie Ritenour','Phyliss Houk','Coleman Dunmire','Williams Camire','Harland Coolidge','Williams Camire','Aldo Byler','Harland Coolidge','Gordon Perrine','Brittani Brin','Coleman Dunmire','Calvin North','Phyliss Houk','Brittani Brin','Aldo Byler','Bettyann Savory','Brittani Brin','Gordon Perrine','Calvin North','Harland Coolidge','Coleman Dunmire','Harland Coolidge','Aldo Byler','Junie Ritenour','Blanch Victoria','Harland Coolidge','Blanch Victoria','Junie Ritenour','Harland Coolidge','Junie Ritenour','Gordon Perrine','Brittani Brin','Coleman Dunmire','Williams Camire','Junie Ritenour','Brittani Brin','Calvin North','Barton Stecklein','Barton Stecklein','Mariah Barberio','Coleman Dunmire','Bettyann Savory','Mariah Barberio','Pa Dargan','Barton Stecklein','Coleman Dunmire','Brittani Brin','Barton Stecklein','Pa Dargan','Barton Stecklein','Junie Ritenour','Bettyann Savory','Williams Camire','Pa Dargan','Calvin North','Williams Camire','Coleman Dunmire','Aldo Byler','Barton Stecklein','Coleman Dunmire','Blanch Victoria','Mariah Barberio','Mariah Barberio','Harland Coolidge','Barton Stecklein','Phyliss Houk','Pa Dargan','Bettyann Savory','Barton Stecklein','Harland Coolidge','Junie Ritenour','Pa Dargan','Mariah Barberio','Blanch Victoria','Williams Camire','Phyliss Houk','Phyliss Houk','Coleman Dunmire','Mariah Barberio','Gordon Perrine','Coleman Dunmire','Brittani Brin','Pa Dargan','Coleman Dunmire','Brittani Brin','Blanch Victoria','Coleman Dunmire','Gordon Perrine','Coleman Dunmire','Aldo Byler','Aldo Byler','Mariah Barberio','Williams Camire','Phyliss Houk','Aldo Byler','Williams Camire','Aldo Byler','Williams Camire','Coleman Dunmire','Phyliss Houk'],
    "Weight":[128,180,193,177,237,166,224,208,177,241,114,161,162,151,220,142,193,193,124,130,132,141,190,239,213,131,172,127,184,157,215,122,181,240,218,205,239,217,234,158,180,131,194,171,177,110,117,114,217,123,248,189,198,127,182,121,224,111,151,170,188,150,137,231,222,186,139,175,178,246,150,154,129,216,144,198,228,183,173,129,157,199,186,232,172,157,246,239,214,161,132,208,187,224,164,177,175,224,219,235,112,241,243,179,208,196,131,207,182,233,191,162,173,197,190,182,231,196,196,143,250,174,138,135,164,204,235,192,114,179,215,127,185,213,250,213,153,217,176,190,119,167,118,208,113,206,200,236,159,218,168,159,156,183,121,203,215,209,179,219,174,220,129,188,217,250,166,157,112,236,182,144,189,243,238,147,165,115,160,134,245,174,238,157,150,184,174,134,134,248,199,165,117,119,162,112,170,224,247,217],
    "Membership(Days)":[52,70,148,124,186,157,127,155,37,185,158,129,93,69,124,13,76,153,164,161,48,121,167,69,39,163,7,34,176,169,108,162,195,86,155,77,197,200,80,142,179,67,58,145,188,147,125,15,13,173,125,4,61,29,132,110,62,137,197,135,162,174,32,151,149,65,18,42,63,62,104,200,189,40,38,199,1,12,8,2,195,30,7,72,130,144,2,34,200,143,43,196,22,115,171,54,143,59,14,52,109,115,187,185,26,19,178,18,120,169,45,52,130,69,168,178,96,22,78,152,39,51,118,130,60,156,108,69,103,158,165,142,86,91,117,77,57,169,86,188,97,111,22,83,81,177,163,35,12,164,21,181,171,138,22,107,58,51,38,128,19,193,157,13,104,89,13,10,26,190,179,101,7,159,100,49,120,109,56,199,51,108,47,171,69,162,74,119,148,88,32,159,65,146,140,171,88,18,59,13]
})
training_df.head(10)
39/5:
# Collecting a summary of all numeric data
training_df_describe
39/6:
# Collecting a summary of all numeric data
training_df.describe
39/7:
# Collecting a summary of all numeric data
training_df.describe()
27/39:
# Iterate through the words in the "prefixes_suffixes" list and replace them with an empty space, "".
for word in prefixes_suffixes:
    student_data_df["student_name"] = student_data_df["student_name"].str.replace(word,"",regex=True)
    print(student_data_df.head()
27/40:
# Read the student data file and store it in a Pandas DataFrame.
student_data_df = pd.read_csv(student_data_to_load)
student_data_df.head()
27/41:
# Add each prefix and suffix to remove to a list.
prefixes_suffixes = ["Dr. ", "Mr. ","Ms. ", "Mrs. ", "Miss ", " MD", " DDS", " DVM", " PhD"]
27/42:
# Iterate through the words in the "prefixes_suffixes" list and replace them with an empty space, "".
for word in prefixes_suffixes:
    student_data_df["student_name"] = student_data_df["student_name"].str.replace(word,"",regex=True)
    print(student_data_df.head()
27/43:
# Iterate through the words in the "prefixes_suffixes" list and replace them with an empty space, "".
for word in prefixes_suffixes:
    student_data_df["student_name"] = student_data_df["student_name"].str.replace(word,"",regex=True)
    print(student_data_df.head(10)
27/44:
# Iterate through the words in the "prefixes_suffixes" list and replace them with an empty space, "".
for word in prefixes_suffixes:
    student_data_df["student_name"] = student_data_df["student_name"].str.replace(word,"",regex=True)
    print(student_data_df.head(10)
27/45:
# Add the Pandas dependency.
import pandas as pd
27/46:
school_data_to_load = "Resources/schools_complete.csv"
student_data_to_load = "Resources/students_complete.csv"
27/47:
# Determine if there are any missing values in the school data.
school_data_df.count()
27/48:
# Determine if there are any missing values in the student data.
student_data_df.count()
27/49: school_data_df.isnull()
27/50: student_data_df.isnull().sum()
27/51: student_data_df.notnull().sum()
27/52:
#Determin data types for the student DataFrame
school_data_df.dtypes
27/53:
# Determine data types for the student DataFrame.
student_data_df.dtypes
27/54:
# Read the school data file and store it in a Pandas DataFrame.
school_data_df= pd.read_csv(school_data_to_load)
school_data_df
27/55:
# Read the student data file and store it in a Pandas DataFrame.
student_data_df = pd.read_csv(student_data_to_load)
student_data_df.head()
27/56:
# Add each prefix and suffix to remove to a list.
prefixes_suffixes = ["Dr. ", "Mr. ","Ms. ", "Mrs. ", "Miss ", " MD", " DDS", " DVM", " PhD"]
27/57:
# Iterate through the words in the "prefixes_suffixes" list and replace them with an empty space, "".
for word in prefixes_suffixes:
    student_data_df["student_name"] = student_data_df["student_name"].str.replace(word,"",regex=True)
    print(student_data_df.head(10)
27/58:
# Iterate through the words in the "prefixes_suffixes" list and replace them with an empty space, "".
for word in prefixes_suffixes:
    student_data_df["student_name"] = student_data_df["student_name"].str.replace(word,"",regex=True)
    print(student_data_df.head(10))
27/59:
# Iterate through the words in the "prefixes_suffixes" list and replace them with an empty space, "".
for word in prefixes_suffixes:
    student_data_df["student_name"] = student_data_df["student_name"].str.replace(word,"",regex=True)
    print(student_data_df.head())
27/60:
# Iterate through the words in the "prefixes_suffixes" list and replace them with an empty space, "".
for word in prefixes_suffixes:
    student_data_df["student_name"] = student_data_df["student_name"].str.replace(word,"",regex=False)
    print(student_data_df.head())
39/8:
# Finding the names of the trainers
training_df.unique
39/9:
# Finding the names of the trainers
training_df.unique()
39/10:
# Collecting a summary of all numeric data
training_df.describe()
39/11:
# Finding the names of the trainers
training_df.unique()
39/12:
# Collecting a summary of all numeric data
training_df.describe()
39/13:
# Finding the names of the trainers
training_df["Trainer"].unique()
39/14:
# Finding the names of the trainers
training_df["Name"].unique()
39/15:
# Finding the names of the trainers
training_df["Trainer"].unique()
39/16:
# A gigantic DataFrame of individuals' names, their trainers, their weight, and their days as gym members
training_df = pd.DataFrame({
    "Name":["Gino Walker","Hiedi Wasser","Kerrie Wetzel","Elizabeth Sackett","Jack Mitten","Madalene Wayman","Jamee Horvath","Arlena Reddin","Tula Levan","Teisha Dreier","Leslie Carrier","Arlette Hartson","Romana Merkle","Heath Viviani","Andres Zimmer","Allyson Osman","Yadira Caggiano","Jeanmarie Friedrichs","Leann Ussery","Bee Mom","Pandora Charland","Karena Wooten","Elizabet Albanese","Augusta Borjas","Erma Yadon","Belia Lenser","Karmen Sancho","Edison Mannion","Sonja Hornsby","Morgan Frei","Florencio Murphy","Christoper Hertel","Thalia Stepney","Tarah Argento","Nicol Canfield","Pok Moretti","Barbera Stallings","Muoi Kelso","Cicely Ritz","Sid Demelo","Eura Langan","Vanita An","Frieda Fuhr","Ernest Fitzhenry","Ashlyn Tash","Melodi Mclendon","Rochell Leblanc","Jacqui Reasons","Freeda Mccroy","Vanna Runk","Florinda Milot","Cierra Lecompte","Nancey Kysar","Latasha Dalton","Charlyn Rinaldi","Erline Averett","Mariko Hillary","Rosalyn Trigg","Sherwood Brauer","Hortencia Olesen","Delana Kohut","Geoffrey Mcdade","Iona Delancey","Donnie Read","Cesar Bhatia","Evia Slate","Kaye Hugo","Denise Vento","Lang Kittle","Sherry Whittenberg","Jodi Bracero","Tamera Linneman","Katheryn Koelling","Tonia Shorty","Misha Baxley","Lisbeth Goering","Merle Ladwig","Tammie Omar","Jesusa Avilla","Alda Zabala","Junita Dogan","Jessia Anglin","Peggie Scranton","Dania Clodfelter","Janis Mccarthy","Edmund Galusha","Tonisha Posey","Arvilla Medley","Briana Barbour","Delfina Kiger","Nia Lenig","Ricarda Bulow","Odell Carson","Nydia Clonts","Andree Resendez","Daniela Puma","Sherill Paavola","Gilbert Bloomquist","Shanon Mach","Justin Bangert","Arden Hokanson","Evelyne Bridge","Hee Simek","Ward Deangelis","Jodie Childs","Janis Boehme","Beaulah Glowacki","Denver Stoneham","Tarra Vinton","Deborah Hummell","Ulysses Neil","Kathryn Marques","Rosanna Dake","Gavin Wheat","Tameka Stoke","Janella Clear","Kaye Ciriaco","Suk Bloxham","Gracia Whaley","Philomena Hemingway","Claudette Vaillancourt","Olevia Piche","Trey Chiles","Idalia Scardina","Jenine Tremble","Herbert Krider","Alycia Schrock","Miss Weibel","Pearlene Neidert","Kina Callender","Charlotte Skelley","Theodora Harrigan","Sydney Shreffler","Annamae Trinidad","Tobi Mumme","Rosia Elliot","Debbra Putt","Rena Delosantos","Genna Grennan","Nieves Huf","Berry Lugo","Ayana Verdugo","Joaquin Mazzei","Doris Harmon","Patience Poss","Magaret Zabel","Marylynn Hinojos","Earlene Marcantel","Yuki Evensen","Rema Gay","Delana Haak","Patricia Fetters","Vinnie Elrod","Octavia Bellew","Burma Revard","Lakenya Kato","Vinita Buchner","Sierra Margulies","Shae Funderburg","Jenae Groleau","Louetta Howie","Astrid Duffer","Caron Altizer","Kymberly Amavisca","Mohammad Diedrich","Thora Wrinkle","Bethel Wiemann","Patria Millet","Eldridge Burbach","Alyson Eddie","Zula Hanna","Devin Goodwin","Felipa Kirkwood","Kurtis Kempf","Kasey Lenart","Deena Blankenship","Kandra Wargo","Sherrie Cieslak","Ron Atha","Reggie Barreiro","Daria Saulter","Tandra Eastman","Donnell Lucious","Talisha Rosner","Emiko Bergh","Terresa Launius","Margy Hoobler","Marylou Stelling","Lavonne Justice","Kala Langstaff","China Truett","Louanne Dussault","Thomasena Samaniego","Charlesetta Tarbell","Fatimah Lade","Malisa Cantero","Florencia Litten","Francina Fraise","Patsy London","Deloris Mclaughlin"],
    "Trainer":['Bettyann Savory','Mariah Barberio','Gordon Perrine','Pa Dargan','Blanch Victoria','Aldo Byler','Aldo Byler','Williams Camire','Junie Ritenour','Gordon Perrine','Bettyann Savory','Mariah Barberio','Aldo Byler','Barton Stecklein','Bettyann Savory','Barton Stecklein','Gordon Perrine','Pa Dargan','Aldo Byler','Brittani Brin','Bettyann Savory','Phyliss Houk','Bettyann Savory','Junie Ritenour','Aldo Byler','Calvin North','Brittani Brin','Junie Ritenour','Blanch Victoria','Brittani Brin','Bettyann Savory','Blanch Victoria','Mariah Barberio','Bettyann Savory','Blanch Victoria','Brittani Brin','Junie Ritenour','Pa Dargan','Gordon Perrine','Phyliss Houk','Pa Dargan','Mariah Barberio','Phyliss Houk','Phyliss Houk','Calvin North','Williams Camire','Brittani Brin','Gordon Perrine','Bettyann Savory','Bettyann Savory','Pa Dargan','Phyliss Houk','Barton Stecklein','Blanch Victoria','Coleman Dunmire','Phyliss Houk','Blanch Victoria','Pa Dargan','Harland Coolidge','Calvin North','Bettyann Savory','Phyliss Houk','Bettyann Savory','Harland Coolidge','Gordon Perrine','Junie Ritenour','Harland Coolidge','Blanch Victoria','Mariah Barberio','Coleman Dunmire','Aldo Byler','Bettyann Savory','Gordon Perrine','Bettyann Savory','Barton Stecklein','Harland Coolidge','Aldo Byler','Aldo Byler','Pa Dargan','Junie Ritenour','Brittani Brin','Junie Ritenour','Gordon Perrine','Mariah Barberio','Mariah Barberio','Mariah Barberio','Bettyann Savory','Brittani Brin','Aldo Byler','Phyliss Houk','Blanch Victoria','Pa Dargan','Phyliss Houk','Brittani Brin','Barton Stecklein','Coleman Dunmire','Bettyann Savory','Bettyann Savory','Gordon Perrine','Blanch Victoria','Junie Ritenour','Phyliss Houk','Coleman Dunmire','Williams Camire','Harland Coolidge','Williams Camire','Aldo Byler','Harland Coolidge','Gordon Perrine','Brittani Brin','Coleman Dunmire','Calvin North','Phyliss Houk','Brittani Brin','Aldo Byler','Bettyann Savory','Brittani Brin','Gordon Perrine','Calvin North','Harland Coolidge','Coleman Dunmire','Harland Coolidge','Aldo Byler','Junie Ritenour','Blanch Victoria','Harland Coolidge','Blanch Victoria','Junie Ritenour','Harland Coolidge','Junie Ritenour','Gordon Perrine','Brittani Brin','Coleman Dunmire','Williams Camire','Junie Ritenour','Brittani Brin','Calvin North','Barton Stecklein','Barton Stecklein','Mariah Barberio','Coleman Dunmire','Bettyann Savory','Mariah Barberio','Pa Dargan','Barton Stecklein','Coleman Dunmire','Brittani Brin','Barton Stecklein','Pa Dargan','Barton Stecklein','Junie Ritenour','Bettyann Savory','Williams Camire','Pa Dargan','Calvin North','Williams Camire','Coleman Dunmire','Aldo Byler','Barton Stecklein','Coleman Dunmire','Blanch Victoria','Mariah Barberio','Mariah Barberio','Harland Coolidge','Barton Stecklein','Phyliss Houk','Pa Dargan','Bettyann Savory','Barton Stecklein','Harland Coolidge','Junie Ritenour','Pa Dargan','Mariah Barberio','Blanch Victoria','Williams Camire','Phyliss Houk','Phyliss Houk','Coleman Dunmire','Mariah Barberio','Gordon Perrine','Coleman Dunmire','Brittani Brin','Pa Dargan','Coleman Dunmire','Brittani Brin','Blanch Victoria','Coleman Dunmire','Gordon Perrine','Coleman Dunmire','Aldo Byler','Aldo Byler','Mariah Barberio','Williams Camire','Phyliss Houk','Aldo Byler','Williams Camire','Aldo Byler','Williams Camire','Coleman Dunmire','Phyliss Houk'],
    "Weight":[128,180,193,177,237,166,224,208,177,241,114,161,162,151,220,142,193,193,124,130,132,141,190,239,213,131,172,127,184,157,215,122,181,240,218,205,239,217,234,158,180,131,194,171,177,110,117,114,217,123,248,189,198,127,182,121,224,111,151,170,188,150,137,231,222,186,139,175,178,246,150,154,129,216,144,198,228,183,173,129,157,199,186,232,172,157,246,239,214,161,132,208,187,224,164,177,175,224,219,235,112,241,243,179,208,196,131,207,182,233,191,162,173,197,190,182,231,196,196,143,250,174,138,135,164,204,235,192,114,179,215,127,185,213,250,213,153,217,176,190,119,167,118,208,113,206,200,236,159,218,168,159,156,183,121,203,215,209,179,219,174,220,129,188,217,250,166,157,112,236,182,144,189,243,238,147,165,115,160,134,245,174,238,157,150,184,174,134,134,248,199,165,117,119,162,112,170,224,247,217],
    "Membership(Days)":[52,70,148,124,186,157,127,155,37,185,158,129,93,69,124,13,76,153,164,161,48,121,167,69,39,163,7,34,176,169,108,162,195,86,155,77,197,200,80,142,179,67,58,145,188,147,125,15,13,173,125,4,61,29,132,110,62,137,197,135,162,174,32,151,149,65,18,42,63,62,104,200,189,40,38,199,1,12,8,2,195,30,7,72,130,144,2,34,200,143,43,196,22,115,171,54,143,59,14,52,109,115,187,185,26,19,178,18,120,169,45,52,130,69,168,178,96,22,78,152,39,51,118,130,60,156,108,69,103,158,165,142,86,91,117,77,57,169,86,188,97,111,22,83,81,177,163,35,12,164,21,181,171,138,22,107,58,51,38,128,19,193,157,13,104,89,13,10,26,190,179,101,7,159,100,49,120,109,56,199,51,108,47,171,69,162,74,119,148,88,32,159,65,146,140,171,88,18,59,13]
})
training_df.head()
39/17:
# A gigantic DataFrame of individuals' names, their trainers, their weight, and their days as gym members
training_df = pd.DataFrame({
    "Name":["Gino Walker","Hiedi Wasser","Kerrie Wetzel","Elizabeth Sackett","Jack Mitten","Madalene Wayman","Jamee Horvath","Arlena Reddin","Tula Levan","Teisha Dreier","Leslie Carrier","Arlette Hartson","Romana Merkle","Heath Viviani","Andres Zimmer","Allyson Osman","Yadira Caggiano","Jeanmarie Friedrichs","Leann Ussery","Bee Mom","Pandora Charland","Karena Wooten","Elizabet Albanese","Augusta Borjas","Erma Yadon","Belia Lenser","Karmen Sancho","Edison Mannion","Sonja Hornsby","Morgan Frei","Florencio Murphy","Christoper Hertel","Thalia Stepney","Tarah Argento","Nicol Canfield","Pok Moretti","Barbera Stallings","Muoi Kelso","Cicely Ritz","Sid Demelo","Eura Langan","Vanita An","Frieda Fuhr","Ernest Fitzhenry","Ashlyn Tash","Melodi Mclendon","Rochell Leblanc","Jacqui Reasons","Freeda Mccroy","Vanna Runk","Florinda Milot","Cierra Lecompte","Nancey Kysar","Latasha Dalton","Charlyn Rinaldi","Erline Averett","Mariko Hillary","Rosalyn Trigg","Sherwood Brauer","Hortencia Olesen","Delana Kohut","Geoffrey Mcdade","Iona Delancey","Donnie Read","Cesar Bhatia","Evia Slate","Kaye Hugo","Denise Vento","Lang Kittle","Sherry Whittenberg","Jodi Bracero","Tamera Linneman","Katheryn Koelling","Tonia Shorty","Misha Baxley","Lisbeth Goering","Merle Ladwig","Tammie Omar","Jesusa Avilla","Alda Zabala","Junita Dogan","Jessia Anglin","Peggie Scranton","Dania Clodfelter","Janis Mccarthy","Edmund Galusha","Tonisha Posey","Arvilla Medley","Briana Barbour","Delfina Kiger","Nia Lenig","Ricarda Bulow","Odell Carson","Nydia Clonts","Andree Resendez","Daniela Puma","Sherill Paavola","Gilbert Bloomquist","Shanon Mach","Justin Bangert","Arden Hokanson","Evelyne Bridge","Hee Simek","Ward Deangelis","Jodie Childs","Janis Boehme","Beaulah Glowacki","Denver Stoneham","Tarra Vinton","Deborah Hummell","Ulysses Neil","Kathryn Marques","Rosanna Dake","Gavin Wheat","Tameka Stoke","Janella Clear","Kaye Ciriaco","Suk Bloxham","Gracia Whaley","Philomena Hemingway","Claudette Vaillancourt","Olevia Piche","Trey Chiles","Idalia Scardina","Jenine Tremble","Herbert Krider","Alycia Schrock","Miss Weibel","Pearlene Neidert","Kina Callender","Charlotte Skelley","Theodora Harrigan","Sydney Shreffler","Annamae Trinidad","Tobi Mumme","Rosia Elliot","Debbra Putt","Rena Delosantos","Genna Grennan","Nieves Huf","Berry Lugo","Ayana Verdugo","Joaquin Mazzei","Doris Harmon","Patience Poss","Magaret Zabel","Marylynn Hinojos","Earlene Marcantel","Yuki Evensen","Rema Gay","Delana Haak","Patricia Fetters","Vinnie Elrod","Octavia Bellew","Burma Revard","Lakenya Kato","Vinita Buchner","Sierra Margulies","Shae Funderburg","Jenae Groleau","Louetta Howie","Astrid Duffer","Caron Altizer","Kymberly Amavisca","Mohammad Diedrich","Thora Wrinkle","Bethel Wiemann","Patria Millet","Eldridge Burbach","Alyson Eddie","Zula Hanna","Devin Goodwin","Felipa Kirkwood","Kurtis Kempf","Kasey Lenart","Deena Blankenship","Kandra Wargo","Sherrie Cieslak","Ron Atha","Reggie Barreiro","Daria Saulter","Tandra Eastman","Donnell Lucious","Talisha Rosner","Emiko Bergh","Terresa Launius","Margy Hoobler","Marylou Stelling","Lavonne Justice","Kala Langstaff","China Truett","Louanne Dussault","Thomasena Samaniego","Charlesetta Tarbell","Fatimah Lade","Malisa Cantero","Florencia Litten","Francina Fraise","Patsy London","Deloris Mclaughlin"],
    "Trainer":['Bettyann Savory','Mariah Barberio','Gordon Perrine','Pa Dargan','Blanch Victoria','Aldo Byler','Aldo Byler','Williams Camire','Junie Ritenour','Gordon Perrine','Bettyann Savory','Mariah Barberio','Aldo Byler','Barton Stecklein','Bettyann Savory','Barton Stecklein','Gordon Perrine','Pa Dargan','Aldo Byler','Brittani Brin','Bettyann Savory','Phyliss Houk','Bettyann Savory','Junie Ritenour','Aldo Byler','Calvin North','Brittani Brin','Junie Ritenour','Blanch Victoria','Brittani Brin','Bettyann Savory','Blanch Victoria','Mariah Barberio','Bettyann Savory','Blanch Victoria','Brittani Brin','Junie Ritenour','Pa Dargan','Gordon Perrine','Phyliss Houk','Pa Dargan','Mariah Barberio','Phyliss Houk','Phyliss Houk','Calvin North','Williams Camire','Brittani Brin','Gordon Perrine','Bettyann Savory','Bettyann Savory','Pa Dargan','Phyliss Houk','Barton Stecklein','Blanch Victoria','Coleman Dunmire','Phyliss Houk','Blanch Victoria','Pa Dargan','Harland Coolidge','Calvin North','Bettyann Savory','Phyliss Houk','Bettyann Savory','Harland Coolidge','Gordon Perrine','Junie Ritenour','Harland Coolidge','Blanch Victoria','Mariah Barberio','Coleman Dunmire','Aldo Byler','Bettyann Savory','Gordon Perrine','Bettyann Savory','Barton Stecklein','Harland Coolidge','Aldo Byler','Aldo Byler','Pa Dargan','Junie Ritenour','Brittani Brin','Junie Ritenour','Gordon Perrine','Mariah Barberio','Mariah Barberio','Mariah Barberio','Bettyann Savory','Brittani Brin','Aldo Byler','Phyliss Houk','Blanch Victoria','Pa Dargan','Phyliss Houk','Brittani Brin','Barton Stecklein','Coleman Dunmire','Bettyann Savory','Bettyann Savory','Gordon Perrine','Blanch Victoria','Junie Ritenour','Phyliss Houk','Coleman Dunmire','Williams Camire','Harland Coolidge','Williams Camire','Aldo Byler','Harland Coolidge','Gordon Perrine','Brittani Brin','Coleman Dunmire','Calvin North','Phyliss Houk','Brittani Brin','Aldo Byler','Bettyann Savory','Brittani Brin','Gordon Perrine','Calvin North','Harland Coolidge','Coleman Dunmire','Harland Coolidge','Aldo Byler','Junie Ritenour','Blanch Victoria','Harland Coolidge','Blanch Victoria','Junie Ritenour','Harland Coolidge','Junie Ritenour','Gordon Perrine','Brittani Brin','Coleman Dunmire','Williams Camire','Junie Ritenour','Brittani Brin','Calvin North','Barton Stecklein','Barton Stecklein','Mariah Barberio','Coleman Dunmire','Bettyann Savory','Mariah Barberio','Pa Dargan','Barton Stecklein','Coleman Dunmire','Brittani Brin','Barton Stecklein','Pa Dargan','Barton Stecklein','Junie Ritenour','Bettyann Savory','Williams Camire','Pa Dargan','Calvin North','Williams Camire','Coleman Dunmire','Aldo Byler','Barton Stecklein','Coleman Dunmire','Blanch Victoria','Mariah Barberio','Mariah Barberio','Harland Coolidge','Barton Stecklein','Phyliss Houk','Pa Dargan','Bettyann Savory','Barton Stecklein','Harland Coolidge','Junie Ritenour','Pa Dargan','Mariah Barberio','Blanch Victoria','Williams Camire','Phyliss Houk','Phyliss Houk','Coleman Dunmire','Mariah Barberio','Gordon Perrine','Coleman Dunmire','Brittani Brin','Pa Dargan','Coleman Dunmire','Brittani Brin','Blanch Victoria','Coleman Dunmire','Gordon Perrine','Coleman Dunmire','Aldo Byler','Aldo Byler','Mariah Barberio','Williams Camire','Phyliss Houk','Aldo Byler','Williams Camire','Aldo Byler','Williams Camire','Coleman Dunmire','Phyliss Houk'],
    "Weight":[128,180,193,177,237,166,224,208,177,241,114,161,162,151,220,142,193,193,124,130,132,141,190,239,213,131,172,127,184,157,215,122,181,240,218,205,239,217,234,158,180,131,194,171,177,110,117,114,217,123,248,189,198,127,182,121,224,111,151,170,188,150,137,231,222,186,139,175,178,246,150,154,129,216,144,198,228,183,173,129,157,199,186,232,172,157,246,239,214,161,132,208,187,224,164,177,175,224,219,235,112,241,243,179,208,196,131,207,182,233,191,162,173,197,190,182,231,196,196,143,250,174,138,135,164,204,235,192,114,179,215,127,185,213,250,213,153,217,176,190,119,167,118,208,113,206,200,236,159,218,168,159,156,183,121,203,215,209,179,219,174,220,129,188,217,250,166,157,112,236,182,144,189,243,238,147,165,115,160,134,245,174,238,157,150,184,174,134,134,248,199,165,117,119,162,112,170,224,247,217],
    "Membership(Days)":[52,70,148,124,186,157,127,155,37,185,158,129,93,69,124,13,76,153,164,161,48,121,167,69,39,163,7,34,176,169,108,162,195,86,155,77,197,200,80,142,179,67,58,145,188,147,125,15,13,173,125,4,61,29,132,110,62,137,197,135,162,174,32,151,149,65,18,42,63,62,104,200,189,40,38,199,1,12,8,2,195,30,7,72,130,144,2,34,200,143,43,196,22,115,171,54,143,59,14,52,109,115,187,185,26,19,178,18,120,169,45,52,130,69,168,178,96,22,78,152,39,51,118,130,60,156,108,69,103,158,165,142,86,91,117,77,57,169,86,188,97,111,22,83,81,177,163,35,12,164,21,181,171,138,22,107,58,51,38,128,19,193,157,13,104,89,13,10,26,190,179,101,7,159,100,49,120,109,56,199,51,108,47,171,69,162,74,119,148,88,32,159,65,146,140,171,88,18,59,13]
})
training_df()
39/18:
# A gigantic DataFrame of individuals' names, their trainers, their weight, and their days as gym members
training_df = pd.DataFrame({
    "Name":["Gino Walker","Hiedi Wasser","Kerrie Wetzel","Elizabeth Sackett","Jack Mitten","Madalene Wayman","Jamee Horvath","Arlena Reddin","Tula Levan","Teisha Dreier","Leslie Carrier","Arlette Hartson","Romana Merkle","Heath Viviani","Andres Zimmer","Allyson Osman","Yadira Caggiano","Jeanmarie Friedrichs","Leann Ussery","Bee Mom","Pandora Charland","Karena Wooten","Elizabet Albanese","Augusta Borjas","Erma Yadon","Belia Lenser","Karmen Sancho","Edison Mannion","Sonja Hornsby","Morgan Frei","Florencio Murphy","Christoper Hertel","Thalia Stepney","Tarah Argento","Nicol Canfield","Pok Moretti","Barbera Stallings","Muoi Kelso","Cicely Ritz","Sid Demelo","Eura Langan","Vanita An","Frieda Fuhr","Ernest Fitzhenry","Ashlyn Tash","Melodi Mclendon","Rochell Leblanc","Jacqui Reasons","Freeda Mccroy","Vanna Runk","Florinda Milot","Cierra Lecompte","Nancey Kysar","Latasha Dalton","Charlyn Rinaldi","Erline Averett","Mariko Hillary","Rosalyn Trigg","Sherwood Brauer","Hortencia Olesen","Delana Kohut","Geoffrey Mcdade","Iona Delancey","Donnie Read","Cesar Bhatia","Evia Slate","Kaye Hugo","Denise Vento","Lang Kittle","Sherry Whittenberg","Jodi Bracero","Tamera Linneman","Katheryn Koelling","Tonia Shorty","Misha Baxley","Lisbeth Goering","Merle Ladwig","Tammie Omar","Jesusa Avilla","Alda Zabala","Junita Dogan","Jessia Anglin","Peggie Scranton","Dania Clodfelter","Janis Mccarthy","Edmund Galusha","Tonisha Posey","Arvilla Medley","Briana Barbour","Delfina Kiger","Nia Lenig","Ricarda Bulow","Odell Carson","Nydia Clonts","Andree Resendez","Daniela Puma","Sherill Paavola","Gilbert Bloomquist","Shanon Mach","Justin Bangert","Arden Hokanson","Evelyne Bridge","Hee Simek","Ward Deangelis","Jodie Childs","Janis Boehme","Beaulah Glowacki","Denver Stoneham","Tarra Vinton","Deborah Hummell","Ulysses Neil","Kathryn Marques","Rosanna Dake","Gavin Wheat","Tameka Stoke","Janella Clear","Kaye Ciriaco","Suk Bloxham","Gracia Whaley","Philomena Hemingway","Claudette Vaillancourt","Olevia Piche","Trey Chiles","Idalia Scardina","Jenine Tremble","Herbert Krider","Alycia Schrock","Miss Weibel","Pearlene Neidert","Kina Callender","Charlotte Skelley","Theodora Harrigan","Sydney Shreffler","Annamae Trinidad","Tobi Mumme","Rosia Elliot","Debbra Putt","Rena Delosantos","Genna Grennan","Nieves Huf","Berry Lugo","Ayana Verdugo","Joaquin Mazzei","Doris Harmon","Patience Poss","Magaret Zabel","Marylynn Hinojos","Earlene Marcantel","Yuki Evensen","Rema Gay","Delana Haak","Patricia Fetters","Vinnie Elrod","Octavia Bellew","Burma Revard","Lakenya Kato","Vinita Buchner","Sierra Margulies","Shae Funderburg","Jenae Groleau","Louetta Howie","Astrid Duffer","Caron Altizer","Kymberly Amavisca","Mohammad Diedrich","Thora Wrinkle","Bethel Wiemann","Patria Millet","Eldridge Burbach","Alyson Eddie","Zula Hanna","Devin Goodwin","Felipa Kirkwood","Kurtis Kempf","Kasey Lenart","Deena Blankenship","Kandra Wargo","Sherrie Cieslak","Ron Atha","Reggie Barreiro","Daria Saulter","Tandra Eastman","Donnell Lucious","Talisha Rosner","Emiko Bergh","Terresa Launius","Margy Hoobler","Marylou Stelling","Lavonne Justice","Kala Langstaff","China Truett","Louanne Dussault","Thomasena Samaniego","Charlesetta Tarbell","Fatimah Lade","Malisa Cantero","Florencia Litten","Francina Fraise","Patsy London","Deloris Mclaughlin"],
    "Trainer":['Bettyann Savory','Mariah Barberio','Gordon Perrine','Pa Dargan','Blanch Victoria','Aldo Byler','Aldo Byler','Williams Camire','Junie Ritenour','Gordon Perrine','Bettyann Savory','Mariah Barberio','Aldo Byler','Barton Stecklein','Bettyann Savory','Barton Stecklein','Gordon Perrine','Pa Dargan','Aldo Byler','Brittani Brin','Bettyann Savory','Phyliss Houk','Bettyann Savory','Junie Ritenour','Aldo Byler','Calvin North','Brittani Brin','Junie Ritenour','Blanch Victoria','Brittani Brin','Bettyann Savory','Blanch Victoria','Mariah Barberio','Bettyann Savory','Blanch Victoria','Brittani Brin','Junie Ritenour','Pa Dargan','Gordon Perrine','Phyliss Houk','Pa Dargan','Mariah Barberio','Phyliss Houk','Phyliss Houk','Calvin North','Williams Camire','Brittani Brin','Gordon Perrine','Bettyann Savory','Bettyann Savory','Pa Dargan','Phyliss Houk','Barton Stecklein','Blanch Victoria','Coleman Dunmire','Phyliss Houk','Blanch Victoria','Pa Dargan','Harland Coolidge','Calvin North','Bettyann Savory','Phyliss Houk','Bettyann Savory','Harland Coolidge','Gordon Perrine','Junie Ritenour','Harland Coolidge','Blanch Victoria','Mariah Barberio','Coleman Dunmire','Aldo Byler','Bettyann Savory','Gordon Perrine','Bettyann Savory','Barton Stecklein','Harland Coolidge','Aldo Byler','Aldo Byler','Pa Dargan','Junie Ritenour','Brittani Brin','Junie Ritenour','Gordon Perrine','Mariah Barberio','Mariah Barberio','Mariah Barberio','Bettyann Savory','Brittani Brin','Aldo Byler','Phyliss Houk','Blanch Victoria','Pa Dargan','Phyliss Houk','Brittani Brin','Barton Stecklein','Coleman Dunmire','Bettyann Savory','Bettyann Savory','Gordon Perrine','Blanch Victoria','Junie Ritenour','Phyliss Houk','Coleman Dunmire','Williams Camire','Harland Coolidge','Williams Camire','Aldo Byler','Harland Coolidge','Gordon Perrine','Brittani Brin','Coleman Dunmire','Calvin North','Phyliss Houk','Brittani Brin','Aldo Byler','Bettyann Savory','Brittani Brin','Gordon Perrine','Calvin North','Harland Coolidge','Coleman Dunmire','Harland Coolidge','Aldo Byler','Junie Ritenour','Blanch Victoria','Harland Coolidge','Blanch Victoria','Junie Ritenour','Harland Coolidge','Junie Ritenour','Gordon Perrine','Brittani Brin','Coleman Dunmire','Williams Camire','Junie Ritenour','Brittani Brin','Calvin North','Barton Stecklein','Barton Stecklein','Mariah Barberio','Coleman Dunmire','Bettyann Savory','Mariah Barberio','Pa Dargan','Barton Stecklein','Coleman Dunmire','Brittani Brin','Barton Stecklein','Pa Dargan','Barton Stecklein','Junie Ritenour','Bettyann Savory','Williams Camire','Pa Dargan','Calvin North','Williams Camire','Coleman Dunmire','Aldo Byler','Barton Stecklein','Coleman Dunmire','Blanch Victoria','Mariah Barberio','Mariah Barberio','Harland Coolidge','Barton Stecklein','Phyliss Houk','Pa Dargan','Bettyann Savory','Barton Stecklein','Harland Coolidge','Junie Ritenour','Pa Dargan','Mariah Barberio','Blanch Victoria','Williams Camire','Phyliss Houk','Phyliss Houk','Coleman Dunmire','Mariah Barberio','Gordon Perrine','Coleman Dunmire','Brittani Brin','Pa Dargan','Coleman Dunmire','Brittani Brin','Blanch Victoria','Coleman Dunmire','Gordon Perrine','Coleman Dunmire','Aldo Byler','Aldo Byler','Mariah Barberio','Williams Camire','Phyliss Houk','Aldo Byler','Williams Camire','Aldo Byler','Williams Camire','Coleman Dunmire','Phyliss Houk'],
    "Weight":[128,180,193,177,237,166,224,208,177,241,114,161,162,151,220,142,193,193,124,130,132,141,190,239,213,131,172,127,184,157,215,122,181,240,218,205,239,217,234,158,180,131,194,171,177,110,117,114,217,123,248,189,198,127,182,121,224,111,151,170,188,150,137,231,222,186,139,175,178,246,150,154,129,216,144,198,228,183,173,129,157,199,186,232,172,157,246,239,214,161,132,208,187,224,164,177,175,224,219,235,112,241,243,179,208,196,131,207,182,233,191,162,173,197,190,182,231,196,196,143,250,174,138,135,164,204,235,192,114,179,215,127,185,213,250,213,153,217,176,190,119,167,118,208,113,206,200,236,159,218,168,159,156,183,121,203,215,209,179,219,174,220,129,188,217,250,166,157,112,236,182,144,189,243,238,147,165,115,160,134,245,174,238,157,150,184,174,134,134,248,199,165,117,119,162,112,170,224,247,217],
    "Membership(Days)":[52,70,148,124,186,157,127,155,37,185,158,129,93,69,124,13,76,153,164,161,48,121,167,69,39,163,7,34,176,169,108,162,195,86,155,77,197,200,80,142,179,67,58,145,188,147,125,15,13,173,125,4,61,29,132,110,62,137,197,135,162,174,32,151,149,65,18,42,63,62,104,200,189,40,38,199,1,12,8,2,195,30,7,72,130,144,2,34,200,143,43,196,22,115,171,54,143,59,14,52,109,115,187,185,26,19,178,18,120,169,45,52,130,69,168,178,96,22,78,152,39,51,118,130,60,156,108,69,103,158,165,142,86,91,117,77,57,169,86,188,97,111,22,83,81,177,163,35,12,164,21,181,171,138,22,107,58,51,38,128,19,193,157,13,104,89,13,10,26,190,179,101,7,159,100,49,120,109,56,199,51,108,47,171,69,162,74,119,148,88,32,159,65,146,140,171,88,18,59,13]
})
training_df.
39/19:
# A gigantic DataFrame of individuals' names, their trainers, their weight, and their days as gym members
training_df = pd.DataFrame({
    "Name":["Gino Walker","Hiedi Wasser","Kerrie Wetzel","Elizabeth Sackett","Jack Mitten","Madalene Wayman","Jamee Horvath","Arlena Reddin","Tula Levan","Teisha Dreier","Leslie Carrier","Arlette Hartson","Romana Merkle","Heath Viviani","Andres Zimmer","Allyson Osman","Yadira Caggiano","Jeanmarie Friedrichs","Leann Ussery","Bee Mom","Pandora Charland","Karena Wooten","Elizabet Albanese","Augusta Borjas","Erma Yadon","Belia Lenser","Karmen Sancho","Edison Mannion","Sonja Hornsby","Morgan Frei","Florencio Murphy","Christoper Hertel","Thalia Stepney","Tarah Argento","Nicol Canfield","Pok Moretti","Barbera Stallings","Muoi Kelso","Cicely Ritz","Sid Demelo","Eura Langan","Vanita An","Frieda Fuhr","Ernest Fitzhenry","Ashlyn Tash","Melodi Mclendon","Rochell Leblanc","Jacqui Reasons","Freeda Mccroy","Vanna Runk","Florinda Milot","Cierra Lecompte","Nancey Kysar","Latasha Dalton","Charlyn Rinaldi","Erline Averett","Mariko Hillary","Rosalyn Trigg","Sherwood Brauer","Hortencia Olesen","Delana Kohut","Geoffrey Mcdade","Iona Delancey","Donnie Read","Cesar Bhatia","Evia Slate","Kaye Hugo","Denise Vento","Lang Kittle","Sherry Whittenberg","Jodi Bracero","Tamera Linneman","Katheryn Koelling","Tonia Shorty","Misha Baxley","Lisbeth Goering","Merle Ladwig","Tammie Omar","Jesusa Avilla","Alda Zabala","Junita Dogan","Jessia Anglin","Peggie Scranton","Dania Clodfelter","Janis Mccarthy","Edmund Galusha","Tonisha Posey","Arvilla Medley","Briana Barbour","Delfina Kiger","Nia Lenig","Ricarda Bulow","Odell Carson","Nydia Clonts","Andree Resendez","Daniela Puma","Sherill Paavola","Gilbert Bloomquist","Shanon Mach","Justin Bangert","Arden Hokanson","Evelyne Bridge","Hee Simek","Ward Deangelis","Jodie Childs","Janis Boehme","Beaulah Glowacki","Denver Stoneham","Tarra Vinton","Deborah Hummell","Ulysses Neil","Kathryn Marques","Rosanna Dake","Gavin Wheat","Tameka Stoke","Janella Clear","Kaye Ciriaco","Suk Bloxham","Gracia Whaley","Philomena Hemingway","Claudette Vaillancourt","Olevia Piche","Trey Chiles","Idalia Scardina","Jenine Tremble","Herbert Krider","Alycia Schrock","Miss Weibel","Pearlene Neidert","Kina Callender","Charlotte Skelley","Theodora Harrigan","Sydney Shreffler","Annamae Trinidad","Tobi Mumme","Rosia Elliot","Debbra Putt","Rena Delosantos","Genna Grennan","Nieves Huf","Berry Lugo","Ayana Verdugo","Joaquin Mazzei","Doris Harmon","Patience Poss","Magaret Zabel","Marylynn Hinojos","Earlene Marcantel","Yuki Evensen","Rema Gay","Delana Haak","Patricia Fetters","Vinnie Elrod","Octavia Bellew","Burma Revard","Lakenya Kato","Vinita Buchner","Sierra Margulies","Shae Funderburg","Jenae Groleau","Louetta Howie","Astrid Duffer","Caron Altizer","Kymberly Amavisca","Mohammad Diedrich","Thora Wrinkle","Bethel Wiemann","Patria Millet","Eldridge Burbach","Alyson Eddie","Zula Hanna","Devin Goodwin","Felipa Kirkwood","Kurtis Kempf","Kasey Lenart","Deena Blankenship","Kandra Wargo","Sherrie Cieslak","Ron Atha","Reggie Barreiro","Daria Saulter","Tandra Eastman","Donnell Lucious","Talisha Rosner","Emiko Bergh","Terresa Launius","Margy Hoobler","Marylou Stelling","Lavonne Justice","Kala Langstaff","China Truett","Louanne Dussault","Thomasena Samaniego","Charlesetta Tarbell","Fatimah Lade","Malisa Cantero","Florencia Litten","Francina Fraise","Patsy London","Deloris Mclaughlin"],
    "Trainer":['Bettyann Savory','Mariah Barberio','Gordon Perrine','Pa Dargan','Blanch Victoria','Aldo Byler','Aldo Byler','Williams Camire','Junie Ritenour','Gordon Perrine','Bettyann Savory','Mariah Barberio','Aldo Byler','Barton Stecklein','Bettyann Savory','Barton Stecklein','Gordon Perrine','Pa Dargan','Aldo Byler','Brittani Brin','Bettyann Savory','Phyliss Houk','Bettyann Savory','Junie Ritenour','Aldo Byler','Calvin North','Brittani Brin','Junie Ritenour','Blanch Victoria','Brittani Brin','Bettyann Savory','Blanch Victoria','Mariah Barberio','Bettyann Savory','Blanch Victoria','Brittani Brin','Junie Ritenour','Pa Dargan','Gordon Perrine','Phyliss Houk','Pa Dargan','Mariah Barberio','Phyliss Houk','Phyliss Houk','Calvin North','Williams Camire','Brittani Brin','Gordon Perrine','Bettyann Savory','Bettyann Savory','Pa Dargan','Phyliss Houk','Barton Stecklein','Blanch Victoria','Coleman Dunmire','Phyliss Houk','Blanch Victoria','Pa Dargan','Harland Coolidge','Calvin North','Bettyann Savory','Phyliss Houk','Bettyann Savory','Harland Coolidge','Gordon Perrine','Junie Ritenour','Harland Coolidge','Blanch Victoria','Mariah Barberio','Coleman Dunmire','Aldo Byler','Bettyann Savory','Gordon Perrine','Bettyann Savory','Barton Stecklein','Harland Coolidge','Aldo Byler','Aldo Byler','Pa Dargan','Junie Ritenour','Brittani Brin','Junie Ritenour','Gordon Perrine','Mariah Barberio','Mariah Barberio','Mariah Barberio','Bettyann Savory','Brittani Brin','Aldo Byler','Phyliss Houk','Blanch Victoria','Pa Dargan','Phyliss Houk','Brittani Brin','Barton Stecklein','Coleman Dunmire','Bettyann Savory','Bettyann Savory','Gordon Perrine','Blanch Victoria','Junie Ritenour','Phyliss Houk','Coleman Dunmire','Williams Camire','Harland Coolidge','Williams Camire','Aldo Byler','Harland Coolidge','Gordon Perrine','Brittani Brin','Coleman Dunmire','Calvin North','Phyliss Houk','Brittani Brin','Aldo Byler','Bettyann Savory','Brittani Brin','Gordon Perrine','Calvin North','Harland Coolidge','Coleman Dunmire','Harland Coolidge','Aldo Byler','Junie Ritenour','Blanch Victoria','Harland Coolidge','Blanch Victoria','Junie Ritenour','Harland Coolidge','Junie Ritenour','Gordon Perrine','Brittani Brin','Coleman Dunmire','Williams Camire','Junie Ritenour','Brittani Brin','Calvin North','Barton Stecklein','Barton Stecklein','Mariah Barberio','Coleman Dunmire','Bettyann Savory','Mariah Barberio','Pa Dargan','Barton Stecklein','Coleman Dunmire','Brittani Brin','Barton Stecklein','Pa Dargan','Barton Stecklein','Junie Ritenour','Bettyann Savory','Williams Camire','Pa Dargan','Calvin North','Williams Camire','Coleman Dunmire','Aldo Byler','Barton Stecklein','Coleman Dunmire','Blanch Victoria','Mariah Barberio','Mariah Barberio','Harland Coolidge','Barton Stecklein','Phyliss Houk','Pa Dargan','Bettyann Savory','Barton Stecklein','Harland Coolidge','Junie Ritenour','Pa Dargan','Mariah Barberio','Blanch Victoria','Williams Camire','Phyliss Houk','Phyliss Houk','Coleman Dunmire','Mariah Barberio','Gordon Perrine','Coleman Dunmire','Brittani Brin','Pa Dargan','Coleman Dunmire','Brittani Brin','Blanch Victoria','Coleman Dunmire','Gordon Perrine','Coleman Dunmire','Aldo Byler','Aldo Byler','Mariah Barberio','Williams Camire','Phyliss Houk','Aldo Byler','Williams Camire','Aldo Byler','Williams Camire','Coleman Dunmire','Phyliss Houk'],
    "Weight":[128,180,193,177,237,166,224,208,177,241,114,161,162,151,220,142,193,193,124,130,132,141,190,239,213,131,172,127,184,157,215,122,181,240,218,205,239,217,234,158,180,131,194,171,177,110,117,114,217,123,248,189,198,127,182,121,224,111,151,170,188,150,137,231,222,186,139,175,178,246,150,154,129,216,144,198,228,183,173,129,157,199,186,232,172,157,246,239,214,161,132,208,187,224,164,177,175,224,219,235,112,241,243,179,208,196,131,207,182,233,191,162,173,197,190,182,231,196,196,143,250,174,138,135,164,204,235,192,114,179,215,127,185,213,250,213,153,217,176,190,119,167,118,208,113,206,200,236,159,218,168,159,156,183,121,203,215,209,179,219,174,220,129,188,217,250,166,157,112,236,182,144,189,243,238,147,165,115,160,134,245,174,238,157,150,184,174,134,134,248,199,165,117,119,162,112,170,224,247,217],
    "Membership(Days)":[52,70,148,124,186,157,127,155,37,185,158,129,93,69,124,13,76,153,164,161,48,121,167,69,39,163,7,34,176,169,108,162,195,86,155,77,197,200,80,142,179,67,58,145,188,147,125,15,13,173,125,4,61,29,132,110,62,137,197,135,162,174,32,151,149,65,18,42,63,62,104,200,189,40,38,199,1,12,8,2,195,30,7,72,130,144,2,34,200,143,43,196,22,115,171,54,143,59,14,52,109,115,187,185,26,19,178,18,120,169,45,52,130,69,168,178,96,22,78,152,39,51,118,130,60,156,108,69,103,158,165,142,86,91,117,77,57,169,86,188,97,111,22,83,81,177,163,35,12,164,21,181,171,138,22,107,58,51,38,128,19,193,157,13,104,89,13,10,26,190,179,101,7,159,100,49,120,109,56,199,51,108,47,171,69,162,74,119,148,88,32,159,65,146,140,171,88,18,59,13]
})
training_df
39/20:
# A gigantic DataFrame of individuals' names, their trainers, their weight, and their days as gym members
training_df = pd.DataFrame({
    "Name":["Gino Walker","Hiedi Wasser","Kerrie Wetzel","Elizabeth Sackett","Jack Mitten","Madalene Wayman","Jamee Horvath","Arlena Reddin","Tula Levan","Teisha Dreier","Leslie Carrier","Arlette Hartson","Romana Merkle","Heath Viviani","Andres Zimmer","Allyson Osman","Yadira Caggiano","Jeanmarie Friedrichs","Leann Ussery","Bee Mom","Pandora Charland","Karena Wooten","Elizabet Albanese","Augusta Borjas","Erma Yadon","Belia Lenser","Karmen Sancho","Edison Mannion","Sonja Hornsby","Morgan Frei","Florencio Murphy","Christoper Hertel","Thalia Stepney","Tarah Argento","Nicol Canfield","Pok Moretti","Barbera Stallings","Muoi Kelso","Cicely Ritz","Sid Demelo","Eura Langan","Vanita An","Frieda Fuhr","Ernest Fitzhenry","Ashlyn Tash","Melodi Mclendon","Rochell Leblanc","Jacqui Reasons","Freeda Mccroy","Vanna Runk","Florinda Milot","Cierra Lecompte","Nancey Kysar","Latasha Dalton","Charlyn Rinaldi","Erline Averett","Mariko Hillary","Rosalyn Trigg","Sherwood Brauer","Hortencia Olesen","Delana Kohut","Geoffrey Mcdade","Iona Delancey","Donnie Read","Cesar Bhatia","Evia Slate","Kaye Hugo","Denise Vento","Lang Kittle","Sherry Whittenberg","Jodi Bracero","Tamera Linneman","Katheryn Koelling","Tonia Shorty","Misha Baxley","Lisbeth Goering","Merle Ladwig","Tammie Omar","Jesusa Avilla","Alda Zabala","Junita Dogan","Jessia Anglin","Peggie Scranton","Dania Clodfelter","Janis Mccarthy","Edmund Galusha","Tonisha Posey","Arvilla Medley","Briana Barbour","Delfina Kiger","Nia Lenig","Ricarda Bulow","Odell Carson","Nydia Clonts","Andree Resendez","Daniela Puma","Sherill Paavola","Gilbert Bloomquist","Shanon Mach","Justin Bangert","Arden Hokanson","Evelyne Bridge","Hee Simek","Ward Deangelis","Jodie Childs","Janis Boehme","Beaulah Glowacki","Denver Stoneham","Tarra Vinton","Deborah Hummell","Ulysses Neil","Kathryn Marques","Rosanna Dake","Gavin Wheat","Tameka Stoke","Janella Clear","Kaye Ciriaco","Suk Bloxham","Gracia Whaley","Philomena Hemingway","Claudette Vaillancourt","Olevia Piche","Trey Chiles","Idalia Scardina","Jenine Tremble","Herbert Krider","Alycia Schrock","Miss Weibel","Pearlene Neidert","Kina Callender","Charlotte Skelley","Theodora Harrigan","Sydney Shreffler","Annamae Trinidad","Tobi Mumme","Rosia Elliot","Debbra Putt","Rena Delosantos","Genna Grennan","Nieves Huf","Berry Lugo","Ayana Verdugo","Joaquin Mazzei","Doris Harmon","Patience Poss","Magaret Zabel","Marylynn Hinojos","Earlene Marcantel","Yuki Evensen","Rema Gay","Delana Haak","Patricia Fetters","Vinnie Elrod","Octavia Bellew","Burma Revard","Lakenya Kato","Vinita Buchner","Sierra Margulies","Shae Funderburg","Jenae Groleau","Louetta Howie","Astrid Duffer","Caron Altizer","Kymberly Amavisca","Mohammad Diedrich","Thora Wrinkle","Bethel Wiemann","Patria Millet","Eldridge Burbach","Alyson Eddie","Zula Hanna","Devin Goodwin","Felipa Kirkwood","Kurtis Kempf","Kasey Lenart","Deena Blankenship","Kandra Wargo","Sherrie Cieslak","Ron Atha","Reggie Barreiro","Daria Saulter","Tandra Eastman","Donnell Lucious","Talisha Rosner","Emiko Bergh","Terresa Launius","Margy Hoobler","Marylou Stelling","Lavonne Justice","Kala Langstaff","China Truett","Louanne Dussault","Thomasena Samaniego","Charlesetta Tarbell","Fatimah Lade","Malisa Cantero","Florencia Litten","Francina Fraise","Patsy London","Deloris Mclaughlin"],
    "Trainer":['Bettyann Savory','Mariah Barberio','Gordon Perrine','Pa Dargan','Blanch Victoria','Aldo Byler','Aldo Byler','Williams Camire','Junie Ritenour','Gordon Perrine','Bettyann Savory','Mariah Barberio','Aldo Byler','Barton Stecklein','Bettyann Savory','Barton Stecklein','Gordon Perrine','Pa Dargan','Aldo Byler','Brittani Brin','Bettyann Savory','Phyliss Houk','Bettyann Savory','Junie Ritenour','Aldo Byler','Calvin North','Brittani Brin','Junie Ritenour','Blanch Victoria','Brittani Brin','Bettyann Savory','Blanch Victoria','Mariah Barberio','Bettyann Savory','Blanch Victoria','Brittani Brin','Junie Ritenour','Pa Dargan','Gordon Perrine','Phyliss Houk','Pa Dargan','Mariah Barberio','Phyliss Houk','Phyliss Houk','Calvin North','Williams Camire','Brittani Brin','Gordon Perrine','Bettyann Savory','Bettyann Savory','Pa Dargan','Phyliss Houk','Barton Stecklein','Blanch Victoria','Coleman Dunmire','Phyliss Houk','Blanch Victoria','Pa Dargan','Harland Coolidge','Calvin North','Bettyann Savory','Phyliss Houk','Bettyann Savory','Harland Coolidge','Gordon Perrine','Junie Ritenour','Harland Coolidge','Blanch Victoria','Mariah Barberio','Coleman Dunmire','Aldo Byler','Bettyann Savory','Gordon Perrine','Bettyann Savory','Barton Stecklein','Harland Coolidge','Aldo Byler','Aldo Byler','Pa Dargan','Junie Ritenour','Brittani Brin','Junie Ritenour','Gordon Perrine','Mariah Barberio','Mariah Barberio','Mariah Barberio','Bettyann Savory','Brittani Brin','Aldo Byler','Phyliss Houk','Blanch Victoria','Pa Dargan','Phyliss Houk','Brittani Brin','Barton Stecklein','Coleman Dunmire','Bettyann Savory','Bettyann Savory','Gordon Perrine','Blanch Victoria','Junie Ritenour','Phyliss Houk','Coleman Dunmire','Williams Camire','Harland Coolidge','Williams Camire','Aldo Byler','Harland Coolidge','Gordon Perrine','Brittani Brin','Coleman Dunmire','Calvin North','Phyliss Houk','Brittani Brin','Aldo Byler','Bettyann Savory','Brittani Brin','Gordon Perrine','Calvin North','Harland Coolidge','Coleman Dunmire','Harland Coolidge','Aldo Byler','Junie Ritenour','Blanch Victoria','Harland Coolidge','Blanch Victoria','Junie Ritenour','Harland Coolidge','Junie Ritenour','Gordon Perrine','Brittani Brin','Coleman Dunmire','Williams Camire','Junie Ritenour','Brittani Brin','Calvin North','Barton Stecklein','Barton Stecklein','Mariah Barberio','Coleman Dunmire','Bettyann Savory','Mariah Barberio','Pa Dargan','Barton Stecklein','Coleman Dunmire','Brittani Brin','Barton Stecklein','Pa Dargan','Barton Stecklein','Junie Ritenour','Bettyann Savory','Williams Camire','Pa Dargan','Calvin North','Williams Camire','Coleman Dunmire','Aldo Byler','Barton Stecklein','Coleman Dunmire','Blanch Victoria','Mariah Barberio','Mariah Barberio','Harland Coolidge','Barton Stecklein','Phyliss Houk','Pa Dargan','Bettyann Savory','Barton Stecklein','Harland Coolidge','Junie Ritenour','Pa Dargan','Mariah Barberio','Blanch Victoria','Williams Camire','Phyliss Houk','Phyliss Houk','Coleman Dunmire','Mariah Barberio','Gordon Perrine','Coleman Dunmire','Brittani Brin','Pa Dargan','Coleman Dunmire','Brittani Brin','Blanch Victoria','Coleman Dunmire','Gordon Perrine','Coleman Dunmire','Aldo Byler','Aldo Byler','Mariah Barberio','Williams Camire','Phyliss Houk','Aldo Byler','Williams Camire','Aldo Byler','Williams Camire','Coleman Dunmire','Phyliss Houk'],
    "Weight":[128,180,193,177,237,166,224,208,177,241,114,161,162,151,220,142,193,193,124,130,132,141,190,239,213,131,172,127,184,157,215,122,181,240,218,205,239,217,234,158,180,131,194,171,177,110,117,114,217,123,248,189,198,127,182,121,224,111,151,170,188,150,137,231,222,186,139,175,178,246,150,154,129,216,144,198,228,183,173,129,157,199,186,232,172,157,246,239,214,161,132,208,187,224,164,177,175,224,219,235,112,241,243,179,208,196,131,207,182,233,191,162,173,197,190,182,231,196,196,143,250,174,138,135,164,204,235,192,114,179,215,127,185,213,250,213,153,217,176,190,119,167,118,208,113,206,200,236,159,218,168,159,156,183,121,203,215,209,179,219,174,220,129,188,217,250,166,157,112,236,182,144,189,243,238,147,165,115,160,134,245,174,238,157,150,184,174,134,134,248,199,165,117,119,162,112,170,224,247,217],
    "Membership(Days)":[52,70,148,124,186,157,127,155,37,185,158,129,93,69,124,13,76,153,164,161,48,121,167,69,39,163,7,34,176,169,108,162,195,86,155,77,197,200,80,142,179,67,58,145,188,147,125,15,13,173,125,4,61,29,132,110,62,137,197,135,162,174,32,151,149,65,18,42,63,62,104,200,189,40,38,199,1,12,8,2,195,30,7,72,130,144,2,34,200,143,43,196,22,115,171,54,143,59,14,52,109,115,187,185,26,19,178,18,120,169,45,52,130,69,168,178,96,22,78,152,39,51,118,130,60,156,108,69,103,158,165,142,86,91,117,77,57,169,86,188,97,111,22,83,81,177,163,35,12,164,21,181,171,138,22,107,58,51,38,128,19,193,157,13,104,89,13,10,26,190,179,101,7,159,100,49,120,109,56,199,51,108,47,171,69,162,74,119,148,88,32,159,65,146,140,171,88,18,59,13]
})
training_df.head()
40/1:
# A seriously gigantic DataFrame of individuals' names, their trainers, their weight, and their days as gym members
training_df = pd.DataFrame({
    "Name":["Gino Walker","Hiedi Wasser","Kerrie Wetzel","Elizabeth Sackett","Jack Mitten","Madalene Wayman","Jamee Horvath","Arlena Reddin","Tula Levan","Teisha Dreier","Leslie Carrier","Arlette Hartson","Romana Merkle","Heath Viviani","Andres Zimmer","Allyson Osman","Yadira Caggiano","Jeanmarie Friedrichs","Leann Ussery","Bee Mom","Pandora Charland","Karena Wooten","Elizabet Albanese","Augusta Borjas","Erma Yadon","Belia Lenser","Karmen Sancho","Edison Mannion","Sonja Hornsby","Morgan Frei","Florencio Murphy","Christoper Hertel","Thalia Stepney","Tarah Argento","Nicol Canfield","Pok Moretti","Barbera Stallings","Muoi Kelso","Cicely Ritz","Sid Demelo","Eura Langan","Vanita An","Frieda Fuhr","Ernest Fitzhenry","Ashlyn Tash","Melodi Mclendon","Rochell Leblanc","Jacqui Reasons","Freeda Mccroy","Vanna Runk","Florinda Milot","Cierra Lecompte","Nancey Kysar","Latasha Dalton","Charlyn Rinaldi","Erline Averett","Mariko Hillary","Rosalyn Trigg","Sherwood Brauer","Hortencia Olesen","Delana Kohut","Geoffrey Mcdade","Iona Delancey","Donnie Read","Cesar Bhatia","Evia Slate","Kaye Hugo","Denise Vento","Lang Kittle","Sherry Whittenberg","Jodi Bracero","Tamera Linneman","Katheryn Koelling","Tonia Shorty","Misha Baxley","Lisbeth Goering","Merle Ladwig","Tammie Omar","Jesusa Avilla","Alda Zabala","Junita Dogan","Jessia Anglin","Peggie Scranton","Dania Clodfelter","Janis Mccarthy","Edmund Galusha","Tonisha Posey","Arvilla Medley","Briana Barbour","Delfina Kiger","Nia Lenig","Ricarda Bulow","Odell Carson","Nydia Clonts","Andree Resendez","Daniela Puma","Sherill Paavola","Gilbert Bloomquist","Shanon Mach","Justin Bangert","Arden Hokanson","Evelyne Bridge","Hee Simek","Ward Deangelis","Jodie Childs","Janis Boehme","Beaulah Glowacki","Denver Stoneham","Tarra Vinton","Deborah Hummell","Ulysses Neil","Kathryn Marques","Rosanna Dake","Gavin Wheat","Tameka Stoke","Janella Clear","Kaye Ciriaco","Suk Bloxham","Gracia Whaley","Philomena Hemingway","Claudette Vaillancourt","Olevia Piche","Trey Chiles","Idalia Scardina","Jenine Tremble","Herbert Krider","Alycia Schrock","Miss Weibel","Pearlene Neidert","Kina Callender","Charlotte Skelley","Theodora Harrigan","Sydney Shreffler","Annamae Trinidad","Tobi Mumme","Rosia Elliot","Debbra Putt","Rena Delosantos","Genna Grennan","Nieves Huf","Berry Lugo","Ayana Verdugo","Joaquin Mazzei","Doris Harmon","Patience Poss","Magaret Zabel","Marylynn Hinojos","Earlene Marcantel","Yuki Evensen","Rema Gay","Delana Haak","Patricia Fetters","Vinnie Elrod","Octavia Bellew","Burma Revard","Lakenya Kato","Vinita Buchner","Sierra Margulies","Shae Funderburg","Jenae Groleau","Louetta Howie","Astrid Duffer","Caron Altizer","Kymberly Amavisca","Mohammad Diedrich","Thora Wrinkle","Bethel Wiemann","Patria Millet","Eldridge Burbach","Alyson Eddie","Zula Hanna","Devin Goodwin","Felipa Kirkwood","Kurtis Kempf","Kasey Lenart","Deena Blankenship","Kandra Wargo","Sherrie Cieslak","Ron Atha","Reggie Barreiro","Daria Saulter","Tandra Eastman","Donnell Lucious","Talisha Rosner","Emiko Bergh","Terresa Launius","Margy Hoobler","Marylou Stelling","Lavonne Justice","Kala Langstaff","China Truett","Louanne Dussault","Thomasena Samaniego","Charlesetta Tarbell","Fatimah Lade","Malisa Cantero","Florencia Litten","Francina Fraise","Patsy London","Deloris Mclaughlin"],
    "Trainer":['Bettyann Savory','Mariah Barberio','Gordon Perrine','Pa Dargan','Blanch Victoria','Aldo Byler','Aldo Byler','Williams Camire','Junie Ritenour','Gordon Perrine','Bettyann Savory','Mariah Barberio','Aldo Byler','Barton Stecklein','Bettyann Savory','Barton Stecklein','Gordon Perrine','Pa Dargan','Aldo Byler','Brittani Brin','Bettyann Savory','Phyliss Houk','Bettyann Savory','Junie Ritenour','Aldo Byler','Calvin North','Brittani Brin','Junie Ritenour','Blanch Victoria','Brittani Brin','Bettyann Savory','Blanch Victoria','Mariah Barberio','Bettyann Savory','Blanch Victoria','Brittani Brin','Junie Ritenour','Pa Dargan','Gordon Perrine','Phyliss Houk','Pa Dargan','Mariah Barberio','Phyliss Houk','Phyliss Houk','Calvin North','Williams Camire','Brittani Brin','Gordon Perrine','Bettyann Savory','Bettyann Savory','Pa Dargan','Phyliss Houk','Barton Stecklein','Blanch Victoria','Coleman Dunmire','Phyliss Houk','Blanch Victoria','Pa Dargan','Harland Coolidge','Calvin North','Bettyann Savory','Phyliss Houk','Bettyann Savory','Harland Coolidge','Gordon Perrine','Junie Ritenour','Harland Coolidge','Blanch Victoria','Mariah Barberio','Coleman Dunmire','Aldo Byler','Bettyann Savory','Gordon Perrine','Bettyann Savory','Barton Stecklein','Harland Coolidge','Aldo Byler','Aldo Byler','Pa Dargan','Junie Ritenour','Brittani Brin','Junie Ritenour','Gordon Perrine','Mariah Barberio','Mariah Barberio','Mariah Barberio','Bettyann Savory','Brittani Brin','Aldo Byler','Phyliss Houk','Blanch Victoria','Pa Dargan','Phyliss Houk','Brittani Brin','Barton Stecklein','Coleman Dunmire','Bettyann Savory','Bettyann Savory','Gordon Perrine','Blanch Victoria','Junie Ritenour','Phyliss Houk','Coleman Dunmire','Williams Camire','Harland Coolidge','Williams Camire','Aldo Byler','Harland Coolidge','Gordon Perrine','Brittani Brin','Coleman Dunmire','Calvin North','Phyliss Houk','Brittani Brin','Aldo Byler','Bettyann Savory','Brittani Brin','Gordon Perrine','Calvin North','Harland Coolidge','Coleman Dunmire','Harland Coolidge','Aldo Byler','Junie Ritenour','Blanch Victoria','Harland Coolidge','Blanch Victoria','Junie Ritenour','Harland Coolidge','Junie Ritenour','Gordon Perrine','Brittani Brin','Coleman Dunmire','Williams Camire','Junie Ritenour','Brittani Brin','Calvin North','Barton Stecklein','Barton Stecklein','Mariah Barberio','Coleman Dunmire','Bettyann Savory','Mariah Barberio','Pa Dargan','Barton Stecklein','Coleman Dunmire','Brittani Brin','Barton Stecklein','Pa Dargan','Barton Stecklein','Junie Ritenour','Bettyann Savory','Williams Camire','Pa Dargan','Calvin North','Williams Camire','Coleman Dunmire','Aldo Byler','Barton Stecklein','Coleman Dunmire','Blanch Victoria','Mariah Barberio','Mariah Barberio','Harland Coolidge','Barton Stecklein','Phyliss Houk','Pa Dargan','Bettyann Savory','Barton Stecklein','Harland Coolidge','Junie Ritenour','Pa Dargan','Mariah Barberio','Blanch Victoria','Williams Camire','Phyliss Houk','Phyliss Houk','Coleman Dunmire','Mariah Barberio','Gordon Perrine','Coleman Dunmire','Brittani Brin','Pa Dargan','Coleman Dunmire','Brittani Brin','Blanch Victoria','Coleman Dunmire','Gordon Perrine','Coleman Dunmire','Aldo Byler','Aldo Byler','Mariah Barberio','Williams Camire','Phyliss Houk','Aldo Byler','Williams Camire','Aldo Byler','Williams Camire','Coleman Dunmire','Phyliss Houk'],
    "Weight":[128,180,193,177,237,166,224,208,177,241,114,161,162,151,220,142,193,193,124,130,132,141,190,239,213,131,172,127,184,157,215,122,181,240,218,205,239,217,234,158,180,131,194,171,177,110,117,114,217,123,248,189,198,127,182,121,224,111,151,170,188,150,137,231,222,186,139,175,178,246,150,154,129,216,144,198,228,183,173,129,157,199,186,232,172,157,246,239,214,161,132,208,187,224,164,177,175,224,219,235,112,241,243,179,208,196,131,207,182,233,191,162,173,197,190,182,231,196,196,143,250,174,138,135,164,204,235,192,114,179,215,127,185,213,250,213,153,217,176,190,119,167,118,208,113,206,200,236,159,218,168,159,156,183,121,203,215,209,179,219,174,220,129,188,217,250,166,157,112,236,182,144,189,243,238,147,165,115,160,134,245,174,238,157,150,184,174,134,134,248,199,165,117,119,162,112,170,224,247,217],
    "Membership (Days)":[52,70,148,124,186,157,127,155,37,185,158,129,93,69,124,13,76,153,164,161,48,121,167,69,39,163,7,34,176,169,108,162,195,86,155,77,197,200,80,142,179,67,58,145,188,147,125,15,13,173,125,4,61,29,132,110,62,137,197,135,162,174,32,151,149,65,18,42,63,62,104,200,189,40,38,199,1,12,8,2,195,30,7,72,130,144,2,34,200,143,43,196,22,115,171,54,143,59,14,52,109,115,187,185,26,19,178,18,120,169,45,52,130,69,168,178,96,22,78,152,39,51,118,130,60,156,108,69,103,158,165,142,86,91,117,77,57,169,86,188,97,111,22,83,81,177,163,35,12,164,21,181,171,138,22,107,58,51,38,128,19,193,157,13,104,89,13,10,26,190,179,101,7,159,100,49,120,109,56,199,51,108,47,171,69,162,74,119,148,88,32,159,65,146,140,171,88,18,59,13]
})
training_df
40/2:
# Import Dependencies
import pandas as pd
40/3:
# A seriously gigantic DataFrame of individuals' names, their trainers, their weight, and their days as gym members
training_df = pd.DataFrame({
    "Name":["Gino Walker","Hiedi Wasser","Kerrie Wetzel","Elizabeth Sackett","Jack Mitten","Madalene Wayman","Jamee Horvath","Arlena Reddin","Tula Levan","Teisha Dreier","Leslie Carrier","Arlette Hartson","Romana Merkle","Heath Viviani","Andres Zimmer","Allyson Osman","Yadira Caggiano","Jeanmarie Friedrichs","Leann Ussery","Bee Mom","Pandora Charland","Karena Wooten","Elizabet Albanese","Augusta Borjas","Erma Yadon","Belia Lenser","Karmen Sancho","Edison Mannion","Sonja Hornsby","Morgan Frei","Florencio Murphy","Christoper Hertel","Thalia Stepney","Tarah Argento","Nicol Canfield","Pok Moretti","Barbera Stallings","Muoi Kelso","Cicely Ritz","Sid Demelo","Eura Langan","Vanita An","Frieda Fuhr","Ernest Fitzhenry","Ashlyn Tash","Melodi Mclendon","Rochell Leblanc","Jacqui Reasons","Freeda Mccroy","Vanna Runk","Florinda Milot","Cierra Lecompte","Nancey Kysar","Latasha Dalton","Charlyn Rinaldi","Erline Averett","Mariko Hillary","Rosalyn Trigg","Sherwood Brauer","Hortencia Olesen","Delana Kohut","Geoffrey Mcdade","Iona Delancey","Donnie Read","Cesar Bhatia","Evia Slate","Kaye Hugo","Denise Vento","Lang Kittle","Sherry Whittenberg","Jodi Bracero","Tamera Linneman","Katheryn Koelling","Tonia Shorty","Misha Baxley","Lisbeth Goering","Merle Ladwig","Tammie Omar","Jesusa Avilla","Alda Zabala","Junita Dogan","Jessia Anglin","Peggie Scranton","Dania Clodfelter","Janis Mccarthy","Edmund Galusha","Tonisha Posey","Arvilla Medley","Briana Barbour","Delfina Kiger","Nia Lenig","Ricarda Bulow","Odell Carson","Nydia Clonts","Andree Resendez","Daniela Puma","Sherill Paavola","Gilbert Bloomquist","Shanon Mach","Justin Bangert","Arden Hokanson","Evelyne Bridge","Hee Simek","Ward Deangelis","Jodie Childs","Janis Boehme","Beaulah Glowacki","Denver Stoneham","Tarra Vinton","Deborah Hummell","Ulysses Neil","Kathryn Marques","Rosanna Dake","Gavin Wheat","Tameka Stoke","Janella Clear","Kaye Ciriaco","Suk Bloxham","Gracia Whaley","Philomena Hemingway","Claudette Vaillancourt","Olevia Piche","Trey Chiles","Idalia Scardina","Jenine Tremble","Herbert Krider","Alycia Schrock","Miss Weibel","Pearlene Neidert","Kina Callender","Charlotte Skelley","Theodora Harrigan","Sydney Shreffler","Annamae Trinidad","Tobi Mumme","Rosia Elliot","Debbra Putt","Rena Delosantos","Genna Grennan","Nieves Huf","Berry Lugo","Ayana Verdugo","Joaquin Mazzei","Doris Harmon","Patience Poss","Magaret Zabel","Marylynn Hinojos","Earlene Marcantel","Yuki Evensen","Rema Gay","Delana Haak","Patricia Fetters","Vinnie Elrod","Octavia Bellew","Burma Revard","Lakenya Kato","Vinita Buchner","Sierra Margulies","Shae Funderburg","Jenae Groleau","Louetta Howie","Astrid Duffer","Caron Altizer","Kymberly Amavisca","Mohammad Diedrich","Thora Wrinkle","Bethel Wiemann","Patria Millet","Eldridge Burbach","Alyson Eddie","Zula Hanna","Devin Goodwin","Felipa Kirkwood","Kurtis Kempf","Kasey Lenart","Deena Blankenship","Kandra Wargo","Sherrie Cieslak","Ron Atha","Reggie Barreiro","Daria Saulter","Tandra Eastman","Donnell Lucious","Talisha Rosner","Emiko Bergh","Terresa Launius","Margy Hoobler","Marylou Stelling","Lavonne Justice","Kala Langstaff","China Truett","Louanne Dussault","Thomasena Samaniego","Charlesetta Tarbell","Fatimah Lade","Malisa Cantero","Florencia Litten","Francina Fraise","Patsy London","Deloris Mclaughlin"],
    "Trainer":['Bettyann Savory','Mariah Barberio','Gordon Perrine','Pa Dargan','Blanch Victoria','Aldo Byler','Aldo Byler','Williams Camire','Junie Ritenour','Gordon Perrine','Bettyann Savory','Mariah Barberio','Aldo Byler','Barton Stecklein','Bettyann Savory','Barton Stecklein','Gordon Perrine','Pa Dargan','Aldo Byler','Brittani Brin','Bettyann Savory','Phyliss Houk','Bettyann Savory','Junie Ritenour','Aldo Byler','Calvin North','Brittani Brin','Junie Ritenour','Blanch Victoria','Brittani Brin','Bettyann Savory','Blanch Victoria','Mariah Barberio','Bettyann Savory','Blanch Victoria','Brittani Brin','Junie Ritenour','Pa Dargan','Gordon Perrine','Phyliss Houk','Pa Dargan','Mariah Barberio','Phyliss Houk','Phyliss Houk','Calvin North','Williams Camire','Brittani Brin','Gordon Perrine','Bettyann Savory','Bettyann Savory','Pa Dargan','Phyliss Houk','Barton Stecklein','Blanch Victoria','Coleman Dunmire','Phyliss Houk','Blanch Victoria','Pa Dargan','Harland Coolidge','Calvin North','Bettyann Savory','Phyliss Houk','Bettyann Savory','Harland Coolidge','Gordon Perrine','Junie Ritenour','Harland Coolidge','Blanch Victoria','Mariah Barberio','Coleman Dunmire','Aldo Byler','Bettyann Savory','Gordon Perrine','Bettyann Savory','Barton Stecklein','Harland Coolidge','Aldo Byler','Aldo Byler','Pa Dargan','Junie Ritenour','Brittani Brin','Junie Ritenour','Gordon Perrine','Mariah Barberio','Mariah Barberio','Mariah Barberio','Bettyann Savory','Brittani Brin','Aldo Byler','Phyliss Houk','Blanch Victoria','Pa Dargan','Phyliss Houk','Brittani Brin','Barton Stecklein','Coleman Dunmire','Bettyann Savory','Bettyann Savory','Gordon Perrine','Blanch Victoria','Junie Ritenour','Phyliss Houk','Coleman Dunmire','Williams Camire','Harland Coolidge','Williams Camire','Aldo Byler','Harland Coolidge','Gordon Perrine','Brittani Brin','Coleman Dunmire','Calvin North','Phyliss Houk','Brittani Brin','Aldo Byler','Bettyann Savory','Brittani Brin','Gordon Perrine','Calvin North','Harland Coolidge','Coleman Dunmire','Harland Coolidge','Aldo Byler','Junie Ritenour','Blanch Victoria','Harland Coolidge','Blanch Victoria','Junie Ritenour','Harland Coolidge','Junie Ritenour','Gordon Perrine','Brittani Brin','Coleman Dunmire','Williams Camire','Junie Ritenour','Brittani Brin','Calvin North','Barton Stecklein','Barton Stecklein','Mariah Barberio','Coleman Dunmire','Bettyann Savory','Mariah Barberio','Pa Dargan','Barton Stecklein','Coleman Dunmire','Brittani Brin','Barton Stecklein','Pa Dargan','Barton Stecklein','Junie Ritenour','Bettyann Savory','Williams Camire','Pa Dargan','Calvin North','Williams Camire','Coleman Dunmire','Aldo Byler','Barton Stecklein','Coleman Dunmire','Blanch Victoria','Mariah Barberio','Mariah Barberio','Harland Coolidge','Barton Stecklein','Phyliss Houk','Pa Dargan','Bettyann Savory','Barton Stecklein','Harland Coolidge','Junie Ritenour','Pa Dargan','Mariah Barberio','Blanch Victoria','Williams Camire','Phyliss Houk','Phyliss Houk','Coleman Dunmire','Mariah Barberio','Gordon Perrine','Coleman Dunmire','Brittani Brin','Pa Dargan','Coleman Dunmire','Brittani Brin','Blanch Victoria','Coleman Dunmire','Gordon Perrine','Coleman Dunmire','Aldo Byler','Aldo Byler','Mariah Barberio','Williams Camire','Phyliss Houk','Aldo Byler','Williams Camire','Aldo Byler','Williams Camire','Coleman Dunmire','Phyliss Houk'],
    "Weight":[128,180,193,177,237,166,224,208,177,241,114,161,162,151,220,142,193,193,124,130,132,141,190,239,213,131,172,127,184,157,215,122,181,240,218,205,239,217,234,158,180,131,194,171,177,110,117,114,217,123,248,189,198,127,182,121,224,111,151,170,188,150,137,231,222,186,139,175,178,246,150,154,129,216,144,198,228,183,173,129,157,199,186,232,172,157,246,239,214,161,132,208,187,224,164,177,175,224,219,235,112,241,243,179,208,196,131,207,182,233,191,162,173,197,190,182,231,196,196,143,250,174,138,135,164,204,235,192,114,179,215,127,185,213,250,213,153,217,176,190,119,167,118,208,113,206,200,236,159,218,168,159,156,183,121,203,215,209,179,219,174,220,129,188,217,250,166,157,112,236,182,144,189,243,238,147,165,115,160,134,245,174,238,157,150,184,174,134,134,248,199,165,117,119,162,112,170,224,247,217],
    "Membership (Days)":[52,70,148,124,186,157,127,155,37,185,158,129,93,69,124,13,76,153,164,161,48,121,167,69,39,163,7,34,176,169,108,162,195,86,155,77,197,200,80,142,179,67,58,145,188,147,125,15,13,173,125,4,61,29,132,110,62,137,197,135,162,174,32,151,149,65,18,42,63,62,104,200,189,40,38,199,1,12,8,2,195,30,7,72,130,144,2,34,200,143,43,196,22,115,171,54,143,59,14,52,109,115,187,185,26,19,178,18,120,169,45,52,130,69,168,178,96,22,78,152,39,51,118,130,60,156,108,69,103,158,165,142,86,91,117,77,57,169,86,188,97,111,22,83,81,177,163,35,12,164,21,181,171,138,22,107,58,51,38,128,19,193,157,13,104,89,13,10,26,190,179,101,7,159,100,49,120,109,56,199,51,108,47,171,69,162,74,119,148,88,32,159,65,146,140,171,88,18,59,13]
})
training_df
40/4:
# A seriously gigantic DataFrame of individuals' names, their trainers, their weight, and their days as gym members
training_df = pd.DataFrame({
    "Name":["Gino Walker","Hiedi Wasser","Kerrie Wetzel","Elizabeth Sackett","Jack Mitten","Madalene Wayman","Jamee Horvath","Arlena Reddin","Tula Levan","Teisha Dreier","Leslie Carrier","Arlette Hartson","Romana Merkle","Heath Viviani","Andres Zimmer","Allyson Osman","Yadira Caggiano","Jeanmarie Friedrichs","Leann Ussery","Bee Mom","Pandora Charland","Karena Wooten","Elizabet Albanese","Augusta Borjas","Erma Yadon","Belia Lenser","Karmen Sancho","Edison Mannion","Sonja Hornsby","Morgan Frei","Florencio Murphy","Christoper Hertel","Thalia Stepney","Tarah Argento","Nicol Canfield","Pok Moretti","Barbera Stallings","Muoi Kelso","Cicely Ritz","Sid Demelo","Eura Langan","Vanita An","Frieda Fuhr","Ernest Fitzhenry","Ashlyn Tash","Melodi Mclendon","Rochell Leblanc","Jacqui Reasons","Freeda Mccroy","Vanna Runk","Florinda Milot","Cierra Lecompte","Nancey Kysar","Latasha Dalton","Charlyn Rinaldi","Erline Averett","Mariko Hillary","Rosalyn Trigg","Sherwood Brauer","Hortencia Olesen","Delana Kohut","Geoffrey Mcdade","Iona Delancey","Donnie Read","Cesar Bhatia","Evia Slate","Kaye Hugo","Denise Vento","Lang Kittle","Sherry Whittenberg","Jodi Bracero","Tamera Linneman","Katheryn Koelling","Tonia Shorty","Misha Baxley","Lisbeth Goering","Merle Ladwig","Tammie Omar","Jesusa Avilla","Alda Zabala","Junita Dogan","Jessia Anglin","Peggie Scranton","Dania Clodfelter","Janis Mccarthy","Edmund Galusha","Tonisha Posey","Arvilla Medley","Briana Barbour","Delfina Kiger","Nia Lenig","Ricarda Bulow","Odell Carson","Nydia Clonts","Andree Resendez","Daniela Puma","Sherill Paavola","Gilbert Bloomquist","Shanon Mach","Justin Bangert","Arden Hokanson","Evelyne Bridge","Hee Simek","Ward Deangelis","Jodie Childs","Janis Boehme","Beaulah Glowacki","Denver Stoneham","Tarra Vinton","Deborah Hummell","Ulysses Neil","Kathryn Marques","Rosanna Dake","Gavin Wheat","Tameka Stoke","Janella Clear","Kaye Ciriaco","Suk Bloxham","Gracia Whaley","Philomena Hemingway","Claudette Vaillancourt","Olevia Piche","Trey Chiles","Idalia Scardina","Jenine Tremble","Herbert Krider","Alycia Schrock","Miss Weibel","Pearlene Neidert","Kina Callender","Charlotte Skelley","Theodora Harrigan","Sydney Shreffler","Annamae Trinidad","Tobi Mumme","Rosia Elliot","Debbra Putt","Rena Delosantos","Genna Grennan","Nieves Huf","Berry Lugo","Ayana Verdugo","Joaquin Mazzei","Doris Harmon","Patience Poss","Magaret Zabel","Marylynn Hinojos","Earlene Marcantel","Yuki Evensen","Rema Gay","Delana Haak","Patricia Fetters","Vinnie Elrod","Octavia Bellew","Burma Revard","Lakenya Kato","Vinita Buchner","Sierra Margulies","Shae Funderburg","Jenae Groleau","Louetta Howie","Astrid Duffer","Caron Altizer","Kymberly Amavisca","Mohammad Diedrich","Thora Wrinkle","Bethel Wiemann","Patria Millet","Eldridge Burbach","Alyson Eddie","Zula Hanna","Devin Goodwin","Felipa Kirkwood","Kurtis Kempf","Kasey Lenart","Deena Blankenship","Kandra Wargo","Sherrie Cieslak","Ron Atha","Reggie Barreiro","Daria Saulter","Tandra Eastman","Donnell Lucious","Talisha Rosner","Emiko Bergh","Terresa Launius","Margy Hoobler","Marylou Stelling","Lavonne Justice","Kala Langstaff","China Truett","Louanne Dussault","Thomasena Samaniego","Charlesetta Tarbell","Fatimah Lade","Malisa Cantero","Florencia Litten","Francina Fraise","Patsy London","Deloris Mclaughlin"],
    "Trainer":['Bettyann Savory','Mariah Barberio','Gordon Perrine','Pa Dargan','Blanch Victoria','Aldo Byler','Aldo Byler','Williams Camire','Junie Ritenour','Gordon Perrine','Bettyann Savory','Mariah Barberio','Aldo Byler','Barton Stecklein','Bettyann Savory','Barton Stecklein','Gordon Perrine','Pa Dargan','Aldo Byler','Brittani Brin','Bettyann Savory','Phyliss Houk','Bettyann Savory','Junie Ritenour','Aldo Byler','Calvin North','Brittani Brin','Junie Ritenour','Blanch Victoria','Brittani Brin','Bettyann Savory','Blanch Victoria','Mariah Barberio','Bettyann Savory','Blanch Victoria','Brittani Brin','Junie Ritenour','Pa Dargan','Gordon Perrine','Phyliss Houk','Pa Dargan','Mariah Barberio','Phyliss Houk','Phyliss Houk','Calvin North','Williams Camire','Brittani Brin','Gordon Perrine','Bettyann Savory','Bettyann Savory','Pa Dargan','Phyliss Houk','Barton Stecklein','Blanch Victoria','Coleman Dunmire','Phyliss Houk','Blanch Victoria','Pa Dargan','Harland Coolidge','Calvin North','Bettyann Savory','Phyliss Houk','Bettyann Savory','Harland Coolidge','Gordon Perrine','Junie Ritenour','Harland Coolidge','Blanch Victoria','Mariah Barberio','Coleman Dunmire','Aldo Byler','Bettyann Savory','Gordon Perrine','Bettyann Savory','Barton Stecklein','Harland Coolidge','Aldo Byler','Aldo Byler','Pa Dargan','Junie Ritenour','Brittani Brin','Junie Ritenour','Gordon Perrine','Mariah Barberio','Mariah Barberio','Mariah Barberio','Bettyann Savory','Brittani Brin','Aldo Byler','Phyliss Houk','Blanch Victoria','Pa Dargan','Phyliss Houk','Brittani Brin','Barton Stecklein','Coleman Dunmire','Bettyann Savory','Bettyann Savory','Gordon Perrine','Blanch Victoria','Junie Ritenour','Phyliss Houk','Coleman Dunmire','Williams Camire','Harland Coolidge','Williams Camire','Aldo Byler','Harland Coolidge','Gordon Perrine','Brittani Brin','Coleman Dunmire','Calvin North','Phyliss Houk','Brittani Brin','Aldo Byler','Bettyann Savory','Brittani Brin','Gordon Perrine','Calvin North','Harland Coolidge','Coleman Dunmire','Harland Coolidge','Aldo Byler','Junie Ritenour','Blanch Victoria','Harland Coolidge','Blanch Victoria','Junie Ritenour','Harland Coolidge','Junie Ritenour','Gordon Perrine','Brittani Brin','Coleman Dunmire','Williams Camire','Junie Ritenour','Brittani Brin','Calvin North','Barton Stecklein','Barton Stecklein','Mariah Barberio','Coleman Dunmire','Bettyann Savory','Mariah Barberio','Pa Dargan','Barton Stecklein','Coleman Dunmire','Brittani Brin','Barton Stecklein','Pa Dargan','Barton Stecklein','Junie Ritenour','Bettyann Savory','Williams Camire','Pa Dargan','Calvin North','Williams Camire','Coleman Dunmire','Aldo Byler','Barton Stecklein','Coleman Dunmire','Blanch Victoria','Mariah Barberio','Mariah Barberio','Harland Coolidge','Barton Stecklein','Phyliss Houk','Pa Dargan','Bettyann Savory','Barton Stecklein','Harland Coolidge','Junie Ritenour','Pa Dargan','Mariah Barberio','Blanch Victoria','Williams Camire','Phyliss Houk','Phyliss Houk','Coleman Dunmire','Mariah Barberio','Gordon Perrine','Coleman Dunmire','Brittani Brin','Pa Dargan','Coleman Dunmire','Brittani Brin','Blanch Victoria','Coleman Dunmire','Gordon Perrine','Coleman Dunmire','Aldo Byler','Aldo Byler','Mariah Barberio','Williams Camire','Phyliss Houk','Aldo Byler','Williams Camire','Aldo Byler','Williams Camire','Coleman Dunmire','Phyliss Houk'],
    "Weight":[128,180,193,177,237,166,224,208,177,241,114,161,162,151,220,142,193,193,124,130,132,141,190,239,213,131,172,127,184,157,215,122,181,240,218,205,239,217,234,158,180,131,194,171,177,110,117,114,217,123,248,189,198,127,182,121,224,111,151,170,188,150,137,231,222,186,139,175,178,246,150,154,129,216,144,198,228,183,173,129,157,199,186,232,172,157,246,239,214,161,132,208,187,224,164,177,175,224,219,235,112,241,243,179,208,196,131,207,182,233,191,162,173,197,190,182,231,196,196,143,250,174,138,135,164,204,235,192,114,179,215,127,185,213,250,213,153,217,176,190,119,167,118,208,113,206,200,236,159,218,168,159,156,183,121,203,215,209,179,219,174,220,129,188,217,250,166,157,112,236,182,144,189,243,238,147,165,115,160,134,245,174,238,157,150,184,174,134,134,248,199,165,117,119,162,112,170,224,247,217],
    "Membership (Days)":[52,70,148,124,186,157,127,155,37,185,158,129,93,69,124,13,76,153,164,161,48,121,167,69,39,163,7,34,176,169,108,162,195,86,155,77,197,200,80,142,179,67,58,145,188,147,125,15,13,173,125,4,61,29,132,110,62,137,197,135,162,174,32,151,149,65,18,42,63,62,104,200,189,40,38,199,1,12,8,2,195,30,7,72,130,144,2,34,200,143,43,196,22,115,171,54,143,59,14,52,109,115,187,185,26,19,178,18,120,169,45,52,130,69,168,178,96,22,78,152,39,51,118,130,60,156,108,69,103,158,165,142,86,91,117,77,57,169,86,188,97,111,22,83,81,177,163,35,12,164,21,181,171,138,22,107,58,51,38,128,19,193,157,13,104,89,13,10,26,190,179,101,7,159,100,49,120,109,56,199,51,108,47,171,69,162,74,119,148,88,32,159,65,146,140,171,88,18,59,13]
})
training_df.head(50)
40/5:
# A seriously gigantic DataFrame of individuals' names, their trainers, their weight, and their days as gym members
training_df = pd.DataFrame({
    "Name":["Gino Walker","Hiedi Wasser","Kerrie Wetzel","Elizabeth Sackett","Jack Mitten","Madalene Wayman","Jamee Horvath","Arlena Reddin","Tula Levan","Teisha Dreier","Leslie Carrier","Arlette Hartson","Romana Merkle","Heath Viviani","Andres Zimmer","Allyson Osman","Yadira Caggiano","Jeanmarie Friedrichs","Leann Ussery","Bee Mom","Pandora Charland","Karena Wooten","Elizabet Albanese","Augusta Borjas","Erma Yadon","Belia Lenser","Karmen Sancho","Edison Mannion","Sonja Hornsby","Morgan Frei","Florencio Murphy","Christoper Hertel","Thalia Stepney","Tarah Argento","Nicol Canfield","Pok Moretti","Barbera Stallings","Muoi Kelso","Cicely Ritz","Sid Demelo","Eura Langan","Vanita An","Frieda Fuhr","Ernest Fitzhenry","Ashlyn Tash","Melodi Mclendon","Rochell Leblanc","Jacqui Reasons","Freeda Mccroy","Vanna Runk","Florinda Milot","Cierra Lecompte","Nancey Kysar","Latasha Dalton","Charlyn Rinaldi","Erline Averett","Mariko Hillary","Rosalyn Trigg","Sherwood Brauer","Hortencia Olesen","Delana Kohut","Geoffrey Mcdade","Iona Delancey","Donnie Read","Cesar Bhatia","Evia Slate","Kaye Hugo","Denise Vento","Lang Kittle","Sherry Whittenberg","Jodi Bracero","Tamera Linneman","Katheryn Koelling","Tonia Shorty","Misha Baxley","Lisbeth Goering","Merle Ladwig","Tammie Omar","Jesusa Avilla","Alda Zabala","Junita Dogan","Jessia Anglin","Peggie Scranton","Dania Clodfelter","Janis Mccarthy","Edmund Galusha","Tonisha Posey","Arvilla Medley","Briana Barbour","Delfina Kiger","Nia Lenig","Ricarda Bulow","Odell Carson","Nydia Clonts","Andree Resendez","Daniela Puma","Sherill Paavola","Gilbert Bloomquist","Shanon Mach","Justin Bangert","Arden Hokanson","Evelyne Bridge","Hee Simek","Ward Deangelis","Jodie Childs","Janis Boehme","Beaulah Glowacki","Denver Stoneham","Tarra Vinton","Deborah Hummell","Ulysses Neil","Kathryn Marques","Rosanna Dake","Gavin Wheat","Tameka Stoke","Janella Clear","Kaye Ciriaco","Suk Bloxham","Gracia Whaley","Philomena Hemingway","Claudette Vaillancourt","Olevia Piche","Trey Chiles","Idalia Scardina","Jenine Tremble","Herbert Krider","Alycia Schrock","Miss Weibel","Pearlene Neidert","Kina Callender","Charlotte Skelley","Theodora Harrigan","Sydney Shreffler","Annamae Trinidad","Tobi Mumme","Rosia Elliot","Debbra Putt","Rena Delosantos","Genna Grennan","Nieves Huf","Berry Lugo","Ayana Verdugo","Joaquin Mazzei","Doris Harmon","Patience Poss","Magaret Zabel","Marylynn Hinojos","Earlene Marcantel","Yuki Evensen","Rema Gay","Delana Haak","Patricia Fetters","Vinnie Elrod","Octavia Bellew","Burma Revard","Lakenya Kato","Vinita Buchner","Sierra Margulies","Shae Funderburg","Jenae Groleau","Louetta Howie","Astrid Duffer","Caron Altizer","Kymberly Amavisca","Mohammad Diedrich","Thora Wrinkle","Bethel Wiemann","Patria Millet","Eldridge Burbach","Alyson Eddie","Zula Hanna","Devin Goodwin","Felipa Kirkwood","Kurtis Kempf","Kasey Lenart","Deena Blankenship","Kandra Wargo","Sherrie Cieslak","Ron Atha","Reggie Barreiro","Daria Saulter","Tandra Eastman","Donnell Lucious","Talisha Rosner","Emiko Bergh","Terresa Launius","Margy Hoobler","Marylou Stelling","Lavonne Justice","Kala Langstaff","China Truett","Louanne Dussault","Thomasena Samaniego","Charlesetta Tarbell","Fatimah Lade","Malisa Cantero","Florencia Litten","Francina Fraise","Patsy London","Deloris Mclaughlin"],
    "Trainer":['Bettyann Savory','Mariah Barberio','Gordon Perrine','Pa Dargan','Blanch Victoria','Aldo Byler','Aldo Byler','Williams Camire','Junie Ritenour','Gordon Perrine','Bettyann Savory','Mariah Barberio','Aldo Byler','Barton Stecklein','Bettyann Savory','Barton Stecklein','Gordon Perrine','Pa Dargan','Aldo Byler','Brittani Brin','Bettyann Savory','Phyliss Houk','Bettyann Savory','Junie Ritenour','Aldo Byler','Calvin North','Brittani Brin','Junie Ritenour','Blanch Victoria','Brittani Brin','Bettyann Savory','Blanch Victoria','Mariah Barberio','Bettyann Savory','Blanch Victoria','Brittani Brin','Junie Ritenour','Pa Dargan','Gordon Perrine','Phyliss Houk','Pa Dargan','Mariah Barberio','Phyliss Houk','Phyliss Houk','Calvin North','Williams Camire','Brittani Brin','Gordon Perrine','Bettyann Savory','Bettyann Savory','Pa Dargan','Phyliss Houk','Barton Stecklein','Blanch Victoria','Coleman Dunmire','Phyliss Houk','Blanch Victoria','Pa Dargan','Harland Coolidge','Calvin North','Bettyann Savory','Phyliss Houk','Bettyann Savory','Harland Coolidge','Gordon Perrine','Junie Ritenour','Harland Coolidge','Blanch Victoria','Mariah Barberio','Coleman Dunmire','Aldo Byler','Bettyann Savory','Gordon Perrine','Bettyann Savory','Barton Stecklein','Harland Coolidge','Aldo Byler','Aldo Byler','Pa Dargan','Junie Ritenour','Brittani Brin','Junie Ritenour','Gordon Perrine','Mariah Barberio','Mariah Barberio','Mariah Barberio','Bettyann Savory','Brittani Brin','Aldo Byler','Phyliss Houk','Blanch Victoria','Pa Dargan','Phyliss Houk','Brittani Brin','Barton Stecklein','Coleman Dunmire','Bettyann Savory','Bettyann Savory','Gordon Perrine','Blanch Victoria','Junie Ritenour','Phyliss Houk','Coleman Dunmire','Williams Camire','Harland Coolidge','Williams Camire','Aldo Byler','Harland Coolidge','Gordon Perrine','Brittani Brin','Coleman Dunmire','Calvin North','Phyliss Houk','Brittani Brin','Aldo Byler','Bettyann Savory','Brittani Brin','Gordon Perrine','Calvin North','Harland Coolidge','Coleman Dunmire','Harland Coolidge','Aldo Byler','Junie Ritenour','Blanch Victoria','Harland Coolidge','Blanch Victoria','Junie Ritenour','Harland Coolidge','Junie Ritenour','Gordon Perrine','Brittani Brin','Coleman Dunmire','Williams Camire','Junie Ritenour','Brittani Brin','Calvin North','Barton Stecklein','Barton Stecklein','Mariah Barberio','Coleman Dunmire','Bettyann Savory','Mariah Barberio','Pa Dargan','Barton Stecklein','Coleman Dunmire','Brittani Brin','Barton Stecklein','Pa Dargan','Barton Stecklein','Junie Ritenour','Bettyann Savory','Williams Camire','Pa Dargan','Calvin North','Williams Camire','Coleman Dunmire','Aldo Byler','Barton Stecklein','Coleman Dunmire','Blanch Victoria','Mariah Barberio','Mariah Barberio','Harland Coolidge','Barton Stecklein','Phyliss Houk','Pa Dargan','Bettyann Savory','Barton Stecklein','Harland Coolidge','Junie Ritenour','Pa Dargan','Mariah Barberio','Blanch Victoria','Williams Camire','Phyliss Houk','Phyliss Houk','Coleman Dunmire','Mariah Barberio','Gordon Perrine','Coleman Dunmire','Brittani Brin','Pa Dargan','Coleman Dunmire','Brittani Brin','Blanch Victoria','Coleman Dunmire','Gordon Perrine','Coleman Dunmire','Aldo Byler','Aldo Byler','Mariah Barberio','Williams Camire','Phyliss Houk','Aldo Byler','Williams Camire','Aldo Byler','Williams Camire','Coleman Dunmire','Phyliss Houk'],
    "Weight":[128,180,193,177,237,166,224,208,177,241,114,161,162,151,220,142,193,193,124,130,132,141,190,239,213,131,172,127,184,157,215,122,181,240,218,205,239,217,234,158,180,131,194,171,177,110,117,114,217,123,248,189,198,127,182,121,224,111,151,170,188,150,137,231,222,186,139,175,178,246,150,154,129,216,144,198,228,183,173,129,157,199,186,232,172,157,246,239,214,161,132,208,187,224,164,177,175,224,219,235,112,241,243,179,208,196,131,207,182,233,191,162,173,197,190,182,231,196,196,143,250,174,138,135,164,204,235,192,114,179,215,127,185,213,250,213,153,217,176,190,119,167,118,208,113,206,200,236,159,218,168,159,156,183,121,203,215,209,179,219,174,220,129,188,217,250,166,157,112,236,182,144,189,243,238,147,165,115,160,134,245,174,238,157,150,184,174,134,134,248,199,165,117,119,162,112,170,224,247,217],
    "Membership (Days)":[52,70,148,124,186,157,127,155,37,185,158,129,93,69,124,13,76,153,164,161,48,121,167,69,39,163,7,34,176,169,108,162,195,86,155,77,197,200,80,142,179,67,58,145,188,147,125,15,13,173,125,4,61,29,132,110,62,137,197,135,162,174,32,151,149,65,18,42,63,62,104,200,189,40,38,199,1,12,8,2,195,30,7,72,130,144,2,34,200,143,43,196,22,115,171,54,143,59,14,52,109,115,187,185,26,19,178,18,120,169,45,52,130,69,168,178,96,22,78,152,39,51,118,130,60,156,108,69,103,158,165,142,86,91,117,77,57,169,86,188,97,111,22,83,81,177,163,35,12,164,21,181,171,138,22,107,58,51,38,128,19,193,157,13,104,89,13,10,26,190,179,101,7,159,100,49,120,109,56,199,51,108,47,171,69,162,74,119,148,88,32,159,65,146,140,171,88,18,59,13]
})
training_df.head(10)
40/6:
# Collecting a summary of all numeric data
training_df.describe()
40/7:
# Finding the names of the trainers
training_df["Trainer"].unique()
39/21:
# Finding how many students each trainer has
training_df[Trainer].value_count
39/22:
# Finding how many students each trainer has
training_df["Trainer"].value_count()
39/23:
# Finding how many students each trainer has
training_df["Trainer"].value_counts()
39/24:
# Finding the names of the trainers
training_df["Names"].unique()
39/25:
# Collecting a summary of all numeric data
training_df.describe()
39/26:
# Finding the names of the trainers
training_df["Names"].unique()
39/27:
# Collecting a summary of all numeric data
training_df.describe()
39/28:
# Finding the names of the trainers
training_df["Name"].unique()
39/29:
# Finding how many students each trainer has
training_df["name"].value_counts()
39/30:
# Finding how many students each trainer has
training_df["Name"].value_counts()
40/8:
# Finding how many students each trainer has

len((training_df)["Name"])
40/9:
# Finding how many students each trainer has
training_df["Trainer"].value_counts()
39/31:
# Finding the average weight of all students
training.df["Weight"]
39/32:
# Finding the average weight of all students
training.df["Weight"].sum
39/33:
# Finding how many students each trainer has
training_df["Name"].value_counts()
39/34:
# Finding the average weight of all students
training.df["Weight"].sum
39/35:
# A gigantic DataFrame of individuals' names, their trainers, their weight, and their days as gym members
training_df = pd.DataFrame({
    "Name":["Gino Walker","Hiedi Wasser","Kerrie Wetzel","Elizabeth Sackett","Jack Mitten","Madalene Wayman","Jamee Horvath","Arlena Reddin","Tula Levan","Teisha Dreier","Leslie Carrier","Arlette Hartson","Romana Merkle","Heath Viviani","Andres Zimmer","Allyson Osman","Yadira Caggiano","Jeanmarie Friedrichs","Leann Ussery","Bee Mom","Pandora Charland","Karena Wooten","Elizabet Albanese","Augusta Borjas","Erma Yadon","Belia Lenser","Karmen Sancho","Edison Mannion","Sonja Hornsby","Morgan Frei","Florencio Murphy","Christoper Hertel","Thalia Stepney","Tarah Argento","Nicol Canfield","Pok Moretti","Barbera Stallings","Muoi Kelso","Cicely Ritz","Sid Demelo","Eura Langan","Vanita An","Frieda Fuhr","Ernest Fitzhenry","Ashlyn Tash","Melodi Mclendon","Rochell Leblanc","Jacqui Reasons","Freeda Mccroy","Vanna Runk","Florinda Milot","Cierra Lecompte","Nancey Kysar","Latasha Dalton","Charlyn Rinaldi","Erline Averett","Mariko Hillary","Rosalyn Trigg","Sherwood Brauer","Hortencia Olesen","Delana Kohut","Geoffrey Mcdade","Iona Delancey","Donnie Read","Cesar Bhatia","Evia Slate","Kaye Hugo","Denise Vento","Lang Kittle","Sherry Whittenberg","Jodi Bracero","Tamera Linneman","Katheryn Koelling","Tonia Shorty","Misha Baxley","Lisbeth Goering","Merle Ladwig","Tammie Omar","Jesusa Avilla","Alda Zabala","Junita Dogan","Jessia Anglin","Peggie Scranton","Dania Clodfelter","Janis Mccarthy","Edmund Galusha","Tonisha Posey","Arvilla Medley","Briana Barbour","Delfina Kiger","Nia Lenig","Ricarda Bulow","Odell Carson","Nydia Clonts","Andree Resendez","Daniela Puma","Sherill Paavola","Gilbert Bloomquist","Shanon Mach","Justin Bangert","Arden Hokanson","Evelyne Bridge","Hee Simek","Ward Deangelis","Jodie Childs","Janis Boehme","Beaulah Glowacki","Denver Stoneham","Tarra Vinton","Deborah Hummell","Ulysses Neil","Kathryn Marques","Rosanna Dake","Gavin Wheat","Tameka Stoke","Janella Clear","Kaye Ciriaco","Suk Bloxham","Gracia Whaley","Philomena Hemingway","Claudette Vaillancourt","Olevia Piche","Trey Chiles","Idalia Scardina","Jenine Tremble","Herbert Krider","Alycia Schrock","Miss Weibel","Pearlene Neidert","Kina Callender","Charlotte Skelley","Theodora Harrigan","Sydney Shreffler","Annamae Trinidad","Tobi Mumme","Rosia Elliot","Debbra Putt","Rena Delosantos","Genna Grennan","Nieves Huf","Berry Lugo","Ayana Verdugo","Joaquin Mazzei","Doris Harmon","Patience Poss","Magaret Zabel","Marylynn Hinojos","Earlene Marcantel","Yuki Evensen","Rema Gay","Delana Haak","Patricia Fetters","Vinnie Elrod","Octavia Bellew","Burma Revard","Lakenya Kato","Vinita Buchner","Sierra Margulies","Shae Funderburg","Jenae Groleau","Louetta Howie","Astrid Duffer","Caron Altizer","Kymberly Amavisca","Mohammad Diedrich","Thora Wrinkle","Bethel Wiemann","Patria Millet","Eldridge Burbach","Alyson Eddie","Zula Hanna","Devin Goodwin","Felipa Kirkwood","Kurtis Kempf","Kasey Lenart","Deena Blankenship","Kandra Wargo","Sherrie Cieslak","Ron Atha","Reggie Barreiro","Daria Saulter","Tandra Eastman","Donnell Lucious","Talisha Rosner","Emiko Bergh","Terresa Launius","Margy Hoobler","Marylou Stelling","Lavonne Justice","Kala Langstaff","China Truett","Louanne Dussault","Thomasena Samaniego","Charlesetta Tarbell","Fatimah Lade","Malisa Cantero","Florencia Litten","Francina Fraise","Patsy London","Deloris Mclaughlin"],
    "Trainer":['Bettyann Savory','Mariah Barberio','Gordon Perrine','Pa Dargan','Blanch Victoria','Aldo Byler','Aldo Byler','Williams Camire','Junie Ritenour','Gordon Perrine','Bettyann Savory','Mariah Barberio','Aldo Byler','Barton Stecklein','Bettyann Savory','Barton Stecklein','Gordon Perrine','Pa Dargan','Aldo Byler','Brittani Brin','Bettyann Savory','Phyliss Houk','Bettyann Savory','Junie Ritenour','Aldo Byler','Calvin North','Brittani Brin','Junie Ritenour','Blanch Victoria','Brittani Brin','Bettyann Savory','Blanch Victoria','Mariah Barberio','Bettyann Savory','Blanch Victoria','Brittani Brin','Junie Ritenour','Pa Dargan','Gordon Perrine','Phyliss Houk','Pa Dargan','Mariah Barberio','Phyliss Houk','Phyliss Houk','Calvin North','Williams Camire','Brittani Brin','Gordon Perrine','Bettyann Savory','Bettyann Savory','Pa Dargan','Phyliss Houk','Barton Stecklein','Blanch Victoria','Coleman Dunmire','Phyliss Houk','Blanch Victoria','Pa Dargan','Harland Coolidge','Calvin North','Bettyann Savory','Phyliss Houk','Bettyann Savory','Harland Coolidge','Gordon Perrine','Junie Ritenour','Harland Coolidge','Blanch Victoria','Mariah Barberio','Coleman Dunmire','Aldo Byler','Bettyann Savory','Gordon Perrine','Bettyann Savory','Barton Stecklein','Harland Coolidge','Aldo Byler','Aldo Byler','Pa Dargan','Junie Ritenour','Brittani Brin','Junie Ritenour','Gordon Perrine','Mariah Barberio','Mariah Barberio','Mariah Barberio','Bettyann Savory','Brittani Brin','Aldo Byler','Phyliss Houk','Blanch Victoria','Pa Dargan','Phyliss Houk','Brittani Brin','Barton Stecklein','Coleman Dunmire','Bettyann Savory','Bettyann Savory','Gordon Perrine','Blanch Victoria','Junie Ritenour','Phyliss Houk','Coleman Dunmire','Williams Camire','Harland Coolidge','Williams Camire','Aldo Byler','Harland Coolidge','Gordon Perrine','Brittani Brin','Coleman Dunmire','Calvin North','Phyliss Houk','Brittani Brin','Aldo Byler','Bettyann Savory','Brittani Brin','Gordon Perrine','Calvin North','Harland Coolidge','Coleman Dunmire','Harland Coolidge','Aldo Byler','Junie Ritenour','Blanch Victoria','Harland Coolidge','Blanch Victoria','Junie Ritenour','Harland Coolidge','Junie Ritenour','Gordon Perrine','Brittani Brin','Coleman Dunmire','Williams Camire','Junie Ritenour','Brittani Brin','Calvin North','Barton Stecklein','Barton Stecklein','Mariah Barberio','Coleman Dunmire','Bettyann Savory','Mariah Barberio','Pa Dargan','Barton Stecklein','Coleman Dunmire','Brittani Brin','Barton Stecklein','Pa Dargan','Barton Stecklein','Junie Ritenour','Bettyann Savory','Williams Camire','Pa Dargan','Calvin North','Williams Camire','Coleman Dunmire','Aldo Byler','Barton Stecklein','Coleman Dunmire','Blanch Victoria','Mariah Barberio','Mariah Barberio','Harland Coolidge','Barton Stecklein','Phyliss Houk','Pa Dargan','Bettyann Savory','Barton Stecklein','Harland Coolidge','Junie Ritenour','Pa Dargan','Mariah Barberio','Blanch Victoria','Williams Camire','Phyliss Houk','Phyliss Houk','Coleman Dunmire','Mariah Barberio','Gordon Perrine','Coleman Dunmire','Brittani Brin','Pa Dargan','Coleman Dunmire','Brittani Brin','Blanch Victoria','Coleman Dunmire','Gordon Perrine','Coleman Dunmire','Aldo Byler','Aldo Byler','Mariah Barberio','Williams Camire','Phyliss Houk','Aldo Byler','Williams Camire','Aldo Byler','Williams Camire','Coleman Dunmire','Phyliss Houk'],
    "Weight":[128,180,193,177,237,166,224,208,177,241,114,161,162,151,220,142,193,193,124,130,132,141,190,239,213,131,172,127,184,157,215,122,181,240,218,205,239,217,234,158,180,131,194,171,177,110,117,114,217,123,248,189,198,127,182,121,224,111,151,170,188,150,137,231,222,186,139,175,178,246,150,154,129,216,144,198,228,183,173,129,157,199,186,232,172,157,246,239,214,161,132,208,187,224,164,177,175,224,219,235,112,241,243,179,208,196,131,207,182,233,191,162,173,197,190,182,231,196,196,143,250,174,138,135,164,204,235,192,114,179,215,127,185,213,250,213,153,217,176,190,119,167,118,208,113,206,200,236,159,218,168,159,156,183,121,203,215,209,179,219,174,220,129,188,217,250,166,157,112,236,182,144,189,243,238,147,165,115,160,134,245,174,238,157,150,184,174,134,134,248,199,165,117,119,162,112,170,224,247,217],
    "Membership(Days)":[52,70,148,124,186,157,127,155,37,185,158,129,93,69,124,13,76,153,164,161,48,121,167,69,39,163,7,34,176,169,108,162,195,86,155,77,197,200,80,142,179,67,58,145,188,147,125,15,13,173,125,4,61,29,132,110,62,137,197,135,162,174,32,151,149,65,18,42,63,62,104,200,189,40,38,199,1,12,8,2,195,30,7,72,130,144,2,34,200,143,43,196,22,115,171,54,143,59,14,52,109,115,187,185,26,19,178,18,120,169,45,52,130,69,168,178,96,22,78,152,39,51,118,130,60,156,108,69,103,158,165,142,86,91,117,77,57,169,86,188,97,111,22,83,81,177,163,35,12,164,21,181,171,138,22,107,58,51,38,128,19,193,157,13,104,89,13,10,26,190,179,101,7,159,100,49,120,109,56,199,51,108,47,171,69,162,74,119,148,88,32,159,65,146,140,171,88,18,59,13]
})
training_df.head()
39/36:
# Collecting a summary of all numeric data
training_df.describe()
39/37:
# Finding the names of the trainers
training_df["Name"].unique()
39/38:
# Finding how many students each trainer has
training_df["Name"].value_counts()
39/39:
# Finding the average weight of all students
training.df["Weight"].sum
39/40:
# Finding the average weight of all students
training_df["Weight"]
39/41:
# Finding the average weight of all students
training_df["Weight"].sum
39/42:
# Finding the average weight of all students
training_df["Weight"].sum()
39/43:
# Finding how many students each trainer has
training_df["Trainer"].value_counts()
39/44:
# Finding the average weight of all students
raining_df["Weight"].mean()
39/45:
# Finding how many students each trainer has
training_df["Trainer"].value_counts()
39/46:
# Finding the average weight of all students
raining_df["Weight"].mean()
39/47:
# Finding the average weight of all students
training_df["Weight"].mean()
39/48:
# Finding the combined weight of all students
training_df["Weight"].sum()
39/49:
# Finding the names of the trainers
training_df["Trainer"].unique()
39/50:
# Converting the membership days into weeks and then adding a column to the DataFrame
weeks = training_df["Membership(Days)"]/7
training_df["Membership_Weeks"] = weeks
training_df.head(20)
39/51:
# Converting the membership days into weeks and then adding a column to the DataFrame
weeks = training_df["Membership(Days)"]/7
training_df["Membership(Weeks)"] = weeks
training_df.head(20)
39/52:
# Finding the combined weight of all students
training_df["Weight"].sum()
39/53:
# Converting the membership days into weeks and then adding a column to the DataFrame
weeks = training_df["Membership(Days)"]/7
training_df["Membership(Weeks)"] = weeks
training_df.head(20)
39/54:
# Converting the membership days into weeks and then adding a column to the DataFrame
weeks = training_df["Membership(Days)"]/7
training_df["Membership(Weeks)"] = weeks
training_df.head(20)
39/55:
# Converting the membership days into weeks and then adding a column to the DataFrame
weeks = training_df["Membership(Days)"]/7
training_df["Membership(Weeks)"] = weeks
del["Membership_Weeks"]
training_df.head(20)
39/56:
# Import Dependencies
import pandas as pd
39/57:
# A gigantic DataFrame of individuals' names, their trainers, their weight, and their days as gym members
training_df = pd.DataFrame({
    "Name":["Gino Walker","Hiedi Wasser","Kerrie Wetzel","Elizabeth Sackett","Jack Mitten","Madalene Wayman","Jamee Horvath","Arlena Reddin","Tula Levan","Teisha Dreier","Leslie Carrier","Arlette Hartson","Romana Merkle","Heath Viviani","Andres Zimmer","Allyson Osman","Yadira Caggiano","Jeanmarie Friedrichs","Leann Ussery","Bee Mom","Pandora Charland","Karena Wooten","Elizabet Albanese","Augusta Borjas","Erma Yadon","Belia Lenser","Karmen Sancho","Edison Mannion","Sonja Hornsby","Morgan Frei","Florencio Murphy","Christoper Hertel","Thalia Stepney","Tarah Argento","Nicol Canfield","Pok Moretti","Barbera Stallings","Muoi Kelso","Cicely Ritz","Sid Demelo","Eura Langan","Vanita An","Frieda Fuhr","Ernest Fitzhenry","Ashlyn Tash","Melodi Mclendon","Rochell Leblanc","Jacqui Reasons","Freeda Mccroy","Vanna Runk","Florinda Milot","Cierra Lecompte","Nancey Kysar","Latasha Dalton","Charlyn Rinaldi","Erline Averett","Mariko Hillary","Rosalyn Trigg","Sherwood Brauer","Hortencia Olesen","Delana Kohut","Geoffrey Mcdade","Iona Delancey","Donnie Read","Cesar Bhatia","Evia Slate","Kaye Hugo","Denise Vento","Lang Kittle","Sherry Whittenberg","Jodi Bracero","Tamera Linneman","Katheryn Koelling","Tonia Shorty","Misha Baxley","Lisbeth Goering","Merle Ladwig","Tammie Omar","Jesusa Avilla","Alda Zabala","Junita Dogan","Jessia Anglin","Peggie Scranton","Dania Clodfelter","Janis Mccarthy","Edmund Galusha","Tonisha Posey","Arvilla Medley","Briana Barbour","Delfina Kiger","Nia Lenig","Ricarda Bulow","Odell Carson","Nydia Clonts","Andree Resendez","Daniela Puma","Sherill Paavola","Gilbert Bloomquist","Shanon Mach","Justin Bangert","Arden Hokanson","Evelyne Bridge","Hee Simek","Ward Deangelis","Jodie Childs","Janis Boehme","Beaulah Glowacki","Denver Stoneham","Tarra Vinton","Deborah Hummell","Ulysses Neil","Kathryn Marques","Rosanna Dake","Gavin Wheat","Tameka Stoke","Janella Clear","Kaye Ciriaco","Suk Bloxham","Gracia Whaley","Philomena Hemingway","Claudette Vaillancourt","Olevia Piche","Trey Chiles","Idalia Scardina","Jenine Tremble","Herbert Krider","Alycia Schrock","Miss Weibel","Pearlene Neidert","Kina Callender","Charlotte Skelley","Theodora Harrigan","Sydney Shreffler","Annamae Trinidad","Tobi Mumme","Rosia Elliot","Debbra Putt","Rena Delosantos","Genna Grennan","Nieves Huf","Berry Lugo","Ayana Verdugo","Joaquin Mazzei","Doris Harmon","Patience Poss","Magaret Zabel","Marylynn Hinojos","Earlene Marcantel","Yuki Evensen","Rema Gay","Delana Haak","Patricia Fetters","Vinnie Elrod","Octavia Bellew","Burma Revard","Lakenya Kato","Vinita Buchner","Sierra Margulies","Shae Funderburg","Jenae Groleau","Louetta Howie","Astrid Duffer","Caron Altizer","Kymberly Amavisca","Mohammad Diedrich","Thora Wrinkle","Bethel Wiemann","Patria Millet","Eldridge Burbach","Alyson Eddie","Zula Hanna","Devin Goodwin","Felipa Kirkwood","Kurtis Kempf","Kasey Lenart","Deena Blankenship","Kandra Wargo","Sherrie Cieslak","Ron Atha","Reggie Barreiro","Daria Saulter","Tandra Eastman","Donnell Lucious","Talisha Rosner","Emiko Bergh","Terresa Launius","Margy Hoobler","Marylou Stelling","Lavonne Justice","Kala Langstaff","China Truett","Louanne Dussault","Thomasena Samaniego","Charlesetta Tarbell","Fatimah Lade","Malisa Cantero","Florencia Litten","Francina Fraise","Patsy London","Deloris Mclaughlin"],
    "Trainer":['Bettyann Savory','Mariah Barberio','Gordon Perrine','Pa Dargan','Blanch Victoria','Aldo Byler','Aldo Byler','Williams Camire','Junie Ritenour','Gordon Perrine','Bettyann Savory','Mariah Barberio','Aldo Byler','Barton Stecklein','Bettyann Savory','Barton Stecklein','Gordon Perrine','Pa Dargan','Aldo Byler','Brittani Brin','Bettyann Savory','Phyliss Houk','Bettyann Savory','Junie Ritenour','Aldo Byler','Calvin North','Brittani Brin','Junie Ritenour','Blanch Victoria','Brittani Brin','Bettyann Savory','Blanch Victoria','Mariah Barberio','Bettyann Savory','Blanch Victoria','Brittani Brin','Junie Ritenour','Pa Dargan','Gordon Perrine','Phyliss Houk','Pa Dargan','Mariah Barberio','Phyliss Houk','Phyliss Houk','Calvin North','Williams Camire','Brittani Brin','Gordon Perrine','Bettyann Savory','Bettyann Savory','Pa Dargan','Phyliss Houk','Barton Stecklein','Blanch Victoria','Coleman Dunmire','Phyliss Houk','Blanch Victoria','Pa Dargan','Harland Coolidge','Calvin North','Bettyann Savory','Phyliss Houk','Bettyann Savory','Harland Coolidge','Gordon Perrine','Junie Ritenour','Harland Coolidge','Blanch Victoria','Mariah Barberio','Coleman Dunmire','Aldo Byler','Bettyann Savory','Gordon Perrine','Bettyann Savory','Barton Stecklein','Harland Coolidge','Aldo Byler','Aldo Byler','Pa Dargan','Junie Ritenour','Brittani Brin','Junie Ritenour','Gordon Perrine','Mariah Barberio','Mariah Barberio','Mariah Barberio','Bettyann Savory','Brittani Brin','Aldo Byler','Phyliss Houk','Blanch Victoria','Pa Dargan','Phyliss Houk','Brittani Brin','Barton Stecklein','Coleman Dunmire','Bettyann Savory','Bettyann Savory','Gordon Perrine','Blanch Victoria','Junie Ritenour','Phyliss Houk','Coleman Dunmire','Williams Camire','Harland Coolidge','Williams Camire','Aldo Byler','Harland Coolidge','Gordon Perrine','Brittani Brin','Coleman Dunmire','Calvin North','Phyliss Houk','Brittani Brin','Aldo Byler','Bettyann Savory','Brittani Brin','Gordon Perrine','Calvin North','Harland Coolidge','Coleman Dunmire','Harland Coolidge','Aldo Byler','Junie Ritenour','Blanch Victoria','Harland Coolidge','Blanch Victoria','Junie Ritenour','Harland Coolidge','Junie Ritenour','Gordon Perrine','Brittani Brin','Coleman Dunmire','Williams Camire','Junie Ritenour','Brittani Brin','Calvin North','Barton Stecklein','Barton Stecklein','Mariah Barberio','Coleman Dunmire','Bettyann Savory','Mariah Barberio','Pa Dargan','Barton Stecklein','Coleman Dunmire','Brittani Brin','Barton Stecklein','Pa Dargan','Barton Stecklein','Junie Ritenour','Bettyann Savory','Williams Camire','Pa Dargan','Calvin North','Williams Camire','Coleman Dunmire','Aldo Byler','Barton Stecklein','Coleman Dunmire','Blanch Victoria','Mariah Barberio','Mariah Barberio','Harland Coolidge','Barton Stecklein','Phyliss Houk','Pa Dargan','Bettyann Savory','Barton Stecklein','Harland Coolidge','Junie Ritenour','Pa Dargan','Mariah Barberio','Blanch Victoria','Williams Camire','Phyliss Houk','Phyliss Houk','Coleman Dunmire','Mariah Barberio','Gordon Perrine','Coleman Dunmire','Brittani Brin','Pa Dargan','Coleman Dunmire','Brittani Brin','Blanch Victoria','Coleman Dunmire','Gordon Perrine','Coleman Dunmire','Aldo Byler','Aldo Byler','Mariah Barberio','Williams Camire','Phyliss Houk','Aldo Byler','Williams Camire','Aldo Byler','Williams Camire','Coleman Dunmire','Phyliss Houk'],
    "Weight":[128,180,193,177,237,166,224,208,177,241,114,161,162,151,220,142,193,193,124,130,132,141,190,239,213,131,172,127,184,157,215,122,181,240,218,205,239,217,234,158,180,131,194,171,177,110,117,114,217,123,248,189,198,127,182,121,224,111,151,170,188,150,137,231,222,186,139,175,178,246,150,154,129,216,144,198,228,183,173,129,157,199,186,232,172,157,246,239,214,161,132,208,187,224,164,177,175,224,219,235,112,241,243,179,208,196,131,207,182,233,191,162,173,197,190,182,231,196,196,143,250,174,138,135,164,204,235,192,114,179,215,127,185,213,250,213,153,217,176,190,119,167,118,208,113,206,200,236,159,218,168,159,156,183,121,203,215,209,179,219,174,220,129,188,217,250,166,157,112,236,182,144,189,243,238,147,165,115,160,134,245,174,238,157,150,184,174,134,134,248,199,165,117,119,162,112,170,224,247,217],
    "Membership(Days)":[52,70,148,124,186,157,127,155,37,185,158,129,93,69,124,13,76,153,164,161,48,121,167,69,39,163,7,34,176,169,108,162,195,86,155,77,197,200,80,142,179,67,58,145,188,147,125,15,13,173,125,4,61,29,132,110,62,137,197,135,162,174,32,151,149,65,18,42,63,62,104,200,189,40,38,199,1,12,8,2,195,30,7,72,130,144,2,34,200,143,43,196,22,115,171,54,143,59,14,52,109,115,187,185,26,19,178,18,120,169,45,52,130,69,168,178,96,22,78,152,39,51,118,130,60,156,108,69,103,158,165,142,86,91,117,77,57,169,86,188,97,111,22,83,81,177,163,35,12,164,21,181,171,138,22,107,58,51,38,128,19,193,157,13,104,89,13,10,26,190,179,101,7,159,100,49,120,109,56,199,51,108,47,171,69,162,74,119,148,88,32,159,65,146,140,171,88,18,59,13]
})
training_df.head()
39/58:
# Collecting a summary of all numeric data
training_df.describe()
39/59:
# Finding the names of the trainers
training_df["Trainer"].unique()
39/60:
# Finding how many students each trainer has
training_df["Trainer"].value_counts()
39/61:
# Finding the average weight of all students
training_df["Weight"].mean()
39/62:
# Finding the combined weight of all students
training_df["Weight"].sum()
39/63:
# Converting the membership days into weeks and then adding a column to the DataFrame
weeks = training_df["Membership(Days)"]/7
training_df["Membership(Weeks)"] = weeks
training_df.head(20)
39/64:
# Finding the combined weight of all students
training_df["Weight"].sum()
39/65:
# Converting the membership days into weeks and then adding a column to the DataFrame
weeks = training_df["Membership(Days)"]/7

training_df["Membership(Weeks)"] = weeks

training_df.head(20)
39/66:
# Converting the membership days into weeks and then adding a column to the DataFrame
weeks = training_df["Membership(Days)"]/7

training_df["Membership(Weeks)"] = weeks

training_df.head.
39/67:
# Converting the membership days into weeks and then adding a column to the DataFrame
weeks = training_df["Membership(Days)"]/7

training_df["Membership(Weeks)"] = weeks

training_df.head()
41/1:
# Reference the file where the CSV is located
crime_csv_path = "Resources/crime_incident_data2017.csv"

# Import the data into a Pandas DataFrame
crime_df = pd.read_csv(crime_csv_path)
41/2:
# Import Dependencies
import pandas as pd
41/3:
# Reference the file where the CSV is located
crime_csv_path = "Resources/crime_incident_data2017.csv"

# Import the data into a Pandas DataFrame
crime_df = pd.read_csv(crime_csv_path)
41/4:
# look for missing values
crime_df.count()
41/5:
# Reference the file where the CSV is located
crime_csv_path = "Resources/crime_incident_data2017.csv"

# Import the data into a Pandas DataFrame
crime_df = pd.read_csv(crime_csv_path)
41/6:
# Reference the file where the CSV is located
crime_csv_path = "Resources/crime_incident_data2017.csv"

# Import the data into a Pandas DataFrame
crime_df = pd.read_csv(crime_csv_path)
crime_df
41/7:
# look for missing values
crime_df.count()
41/8:
# drop null rows
crime_df = df.dropna(how=any)
41/9:
# drop null rows
crime_df = crime_df.dropna(how=any)
41/10:
# Import Dependencies
import pandas as pd
41/11:
# Reference the file where the CSV is located
crime_csv_path = "Resources/crime_incident_data2017.csv"

# Import the data into a Pandas DataFrame
crime_df = pd.read_csv(crime_csv_path)
crime_df
41/12:
# look for missing values
crime_df.count()
41/13:
# drop null rows
crime_df = crime_df.dropna(how=any)
41/14:
# drop null rows
crime_df = crime_df.dropna(how='any')
41/15:
# drop null rows
crime_df = crime_df.dropna(how='any')
41/16:
# drop null rows
crime_df = crime_df.dropna(how='any')
crime_df
41/17:
# Reference the file where the CSV is located
crime_csv_path = "Resources/crime_incident_data2017.csv"

# Import the data into a Pandas DataFrame
crime_df = pd.read_csv(crime_csv_path)
crime_df.head()
41/18:
# drop null rows
crime_df = crime_df.dropna(how='any')
41/19:
# verify counts
crime_df.count()
41/20:
# Check to see if there are any values with mispelled or similar values in "Offense Type"
crime_df.count("Offense Type")
41/21:
# Check to see if there are any values with mispelled or similar values in "Offense Type"
crime_df.count.value("Offense Type")
41/22:
# Check to see if there are any values with mispelled or similar values in "Offense Type"
crime_df("Offense Type").value.count
41/23:
# Check to see if there are any values with mispelled or similar values in "Offense Type"
crime_df[Offense Type"].value.count()
41/24:
# Check to see if there are any values with mispelled or similar values in "Offense Type"
crime_df[Offense Type"].value.counts()
41/25:
# verify counts
crime_df.count()
41/26:
# Check to see if there are any values with mispelled or similar values in "Offense Type"
crime_df[Offense Type"].value.counts()
41/27:
# Check to see if there are any values with mispelled or similar values in "Offense Type"
crime_df["Offense Type"].value.counts()
41/28:
# Check to see if there are any values with mispelled or similar values in "Offense Type"
crime_df["Offense Type"].value_counts()
#no_null_crime_df["Offense Type"].value_counts()
41/29:
# Combine similar offenses
crime_df = crime_df.replace(
    {"Theft From Motor Vehicle Parts or Accessorie"}:"Theft","Theft From Motor Vehicle":"Theft","Theft From Building":"Theft"})
crime_df
41/30:
# Combine similar offenses
crime_df = crime_df.replace(
    {"Theft From Motor Vehicle Parts or Accessorie":"Theft","Theft From Motor Vehicle":"Theft","Theft From Building":"Theft"})
#no_null_crime_df = no_null_crime_df.replace({"Commercial Sex Acts": "Prostitution", "Assisting or Promoting Prostitution": "Prostitution"})
crime_df
41/31:
# Combine similar offenses
crime_df = crime_df.replace(
    {"Theft From Motor Vehicle Parts or Accessorie":"Theft","Theft From Motor Vehicle":"Theft","Theft From Building":"Theft"})
#no_null_crime_df = no_null_crime_df.replace({"Commercial Sex Acts": "Prostitution", "Assisting or Promoting Prostitution": "Prostitution"})
crime_df.head()
41/32:
# Combine similar offenses
crime_df = crime_df.replace(
    {"Theft From Motor Vehicle Parts or Accessorie":"Theft","Theft From Motor Vehicle":"Theft","Theft From Building":"Theft"})
#no_null_crime_df = no_null_crime_df.replace({"Commercial Sex Acts": "Prostitution", "Assisting or Promoting Prostitution": "Prostitution"})
crime_df.head(20)
41/33:
# Combine similar offenses
crime_df = crime_df.replace(
    {"Theft From Motor Vehicle Parts or Accessorie":"Theft","Theft From Motor Vehicle":"Theft","Theft From Building":"Theft"})

crime_df.head(5)
41/34:
# Check to see if you comnbined similar offenses correctly in "Offense Type".
crime_df("Offense Type").count_value
41/35:
# Check to see if you comnbined similar offenses correctly in "Offense Type".
crime_df("Offense Type").value_counts()
41/36:
# Combine similar offenses
crime_df = crime_df.replace(
    {"Theft From Motor Vehicle Parts or Accessorie":"Theft","Theft From Motor Vehicle":"Theft","Theft From Building":"Theft"})

crime_df.head(5)
41/37:
# Check to see if you comnbined similar offenses correctly in "Offense Type".
crime_df("Offense Type").value_counts()
41/38:
# Check to see if you comnbined similar offenses correctly in "Offense Type".
crime_df["Offense Type"].value_counts()
41/39: crime_df["Crime Against"]
41/40: crime_df["Crime Against"].value.counts()
41/41: crime_df["Crime Against"].value_counts()
44/1:
# Add the Pandas dependency.
import pandas as pd
44/2:
school_data_to_load = "Resources/schools_complete.csv"
student_data_to_load = "Resources/students_complete.csv"
44/3:
# Determine if there are any missing values in the school data.
school_data_df.count()
44/4:
# Determine if there are any missing values in the student data.
student_data_df.count()
44/5: school_data_df.isnull()
44/6: student_data_df.isnull().sum()
44/7: student_data_df.notnull().sum()
44/8:
#Determin data types for the student DataFrame
school_data_df.dtypes
44/9:
# Add the Pandas dependency.
import pandas as pd
44/10:
school_data_to_load = "Resources/schools_complete.csv"
student_data_to_load = "Resources/students_complete.csv"
44/11:
# Determine if there are any missing values in the school data.
school_data_df.count()
44/12:
# Determine if there are any missing values in the school data.
school_data_df.count()
44/13:
# Determine if there are any missing values in the school data.
school_data_df.count()
44/14:
# Determine if there are any missing values in the student data.
student_data_df.count()
44/15: school_data_df.isnull()
45/1:
#Import dependencies
import pandas as pd
45/2:
student_data_to_load = "Resources/students_complete.csv"
student_data_df = pd.read_csv(student_data_to_load)
student_data_df.head()
45/3:
# Put the student names in a list.
student_names = student_data_df["student_name"].tolist()
student_names
45/4:
# Split the student name and determine the length of the split name.
for name in student_names:
    print(name.split(), len(name.split()))
45/5:
# Create a new list and use it for the for loop to iterate through the list.
students_to_fix = []

# Use an if statement to check the length of the name.
# If the name is greater than or equal to "3", add the name to the list.

for name in student_names:
    if len(name.split()) >= 3:
        students_to_fix.append(name)

# Get the length of the students whose names are greater than or equal to "3".
len(students_to_fix)
print(students_to_fix)
45/6:
# Add the prefixes less than or equal to 4 to a new list.
prefixes = []
for name in students_to_fix:
    if len(name.split()[0]) <= 4:
        prefixes.append(name.split()[0])

print(prefixes)
45/7:
# Add the suffixes less than or equal to 3 to a new list.
suffixes = []
for name in students_to_fix:
    if len(name.split()[-1]) <= 3:
        suffixes.append(name.split()[-1])

print(suffixes)
45/8: set(prefixes)
45/9:
# Get the unique items in the "suffixes" list.
set(suffixes)
45/10:
# Strip "Mrs." from the student names
for name in students_to_fix:
    print(name.strip("Mrs."))
44/16:
# Determine if there are any missing values in the school data.
school_data_df.count()
44/17:
# Determine if there are any missing values in the student data.
student_data_df.count()
44/18: school_data_df.isnull()
44/19: student_data_df.isnull().sum()
44/20:
# Add the Pandas dependency.
import pandas as pd
44/21:
school_data_to_load = "Resources/schools_complete.csv"
student_data_to_load = "Resources/students_complete.csv"
44/22:
# Determine if there are any missing values in the school data.
school_data_df.count()
44/23:
# Determine if there are any missing values in the student data.
student_data_df.count()
44/24: school_data_df.isnull()
44/25:
school_data_to_load = "Resources/schools_complete.csv"
student_data_to_load = "Resources/students_complete.csv"
44/26:
school_data_df = pd.read_csv(school_data_to_load)
school_data_df
44/27:
# Determine if there are any missing values in the school data.
school_data_df.count()
44/28:
# Determine if there are any missing values in the student data.
student_data_df.count()
44/29:
# Read the school data file and store it in a Pandas DataFrame.
school_data_df = pd.read_csv(school_data_to_load)
school_data_df
44/30:
# Read the student data file and store it in a Pandas DataFrame.
student_data_df = pd.read_csv(student_data_to_load)
student_data_df.head()
44/31:
# Determine if there are any missing values in the school data.
school_data_df.count()
44/32:
# Determine if there are any missing values in the student data.
student_data_df.count()
44/33: school_data_df.isnull()
44/34: student_data_df.isnull().sum()
44/35: student_data_df.notnull().sum()
44/36:
#Determin data types for the student DataFrame
school_data_df.dtypes
44/37:
# Determine data types for the student DataFrame.
student_data_df.dtypes
44/38:
# Read the school data file and store it in a Pandas DataFrame.
school_data_df= pd.read_csv(school_data_to_load)
school_data_df
44/39:
# Read the student data file and store it in a Pandas DataFrame.
student_data_df = pd.read_csv(student_data_to_load)
student_data_df.head()
44/40:
# Add each prefix and suffix to remove to a list.
prefixes_suffixes = ["Dr. ", "Mr. ","Ms. ", "Mrs. ", "Miss ", " MD", " DDS", " DVM", " PhD"]
44/41:
# Iterate through the words in the "prefixes_suffixes" list and replace them with an empty space, "".
for word in prefixes_suffixes:
    student_data_df["student_name"] = student_data_df["student_name"].str.replace(word,"",regex=False)
    print(student_data_df.head())
44/42:
# Combine the data into a single dataset.
school_data_complete_df = pd.merge(student_data_df, school_data_df, on=["school_name", "school_name"])
school_data_complete_df.head()
44/43:
#Get the total number of students
student_count = school_data_complete_df
school_data_complete_df
44/44:
#Get the total number of students
student_count = school_data_complete_df
school_data_complete_df.head()
44/45:
#Get the total number of students
student_count = school_data_complete_df
student_count
44/46:
#Get the total number of students
student_count = school_data_complete_df.count
student_count
44/47:
#Get the total number of students
student_count = school_data_complete_df.count()
student_count
44/48:
#Get the total number of students
#student_count = school_data_complete_df.count()
#student_count
school_data_complete_df["Student ID"].count()
44/49:
#Get the total number of students
student_count = school_data_complete_df.count()
#student_count
#school_data_complete_df["Student ID"].count()
44/50:
#Get the total number of students
#student_count = 
school_data_complete_df.count()
#student_count
#school_data_complete_df["Student ID"].count()
44/51:
#Get the total number of students
student_count = school_data_complete_df.count()
#student_count
#school_data_complete_df["Student ID"].count()
44/52:
#Get the total number of students
#student_count = school_data_complete_df.count()
#student_count
school_data_complete_df["Student ID"].count()
44/53:
#Calculate the total number of schools
school_count=school_data_df.count()
school_count
44/54:
#Calculate the total number of schools
school_count=school_data_df["school_name"].count()
school_count
44/55:
#Calculate the total number of schools
school_count=school_data_df["school_name"].count()
#school_count
44/56:
#Calculate the total number of schools
school_count=school_data_df["school_name"].count()
school_count
44/57:
#Calculate the total number of schools
#school_count=
school_data_df["school_name"].count()
#school_count
44/58:
# Combine the data into a single dataset.
school_data_complete_df = pd.merge(student_data_df, school_data_df, on=["school_name", "school_name"])
school_data_complete_df
44/59:
# Combine the data into a single dataset.
school_data_complete_df = pd.merge(student_data_df, school_data_df, on=["school_name", "school_name"])
school_data_complete_df.head()
44/60:
# Calculate the total number of schools
school_count_2 = school_data_complete_df["school_name"].unique()
school_count_2
44/61:
#Running the code: 
len(school_data_complete_df["school_name"].unique())
44/62:
# Iterate through the words in the "prefixes_suffixes" list and replace them with an empty space, "".
for word in prefixes_suffixes:
    student_data_df["student_name"] = student_data_df["student_name"].str.replace(word,"")
    print(student_data_df.head())
44/63:
# Iterate through the words in the "prefixes_suffixes" list and replace them with an empty space, "".
for word in prefixes_suffixes:
    student_data_df["student_name"] = student_data_df["student_name"].str.replace(word,"",Regex=True)
    print(student_data_df.head())
44/64:
# Add each prefix and suffix to remove to a list.
prefixes_suffixes = ["Dr. ", "Mr. ","Ms. ", "Mrs. ", "Miss ", " MD", " DDS", " DVM", " PhD"]
44/65:
# Iterate through the words in the "prefixes_suffixes" list and replace them with an empty space, "".
for word in prefixes_suffixes:
    student_data_df["student_name"] = student_data_df["student_name"].str.replace(word,"",Regex=True)
    print(student_data_df.head())
44/66:
# Iterate through the words in the "prefixes_suffixes" list and replace them with an empty space, "".
for word in prefixes_suffixes:
    student_data_df["student_name"] = student_data_df["student_name"].str.replace(word,"", Regex=True)
    print(student_data_df.head())
44/67:
# Iterate through the words in the "prefixes_suffixes" list and replace them with an empty space, "".
for word in prefixes_suffixes:
    student_data_df["student_name"] = student_data_df["student_name"].str.replace(word,"", Regex =True)
    print(student_data_df.head())
44/68:
# Iterate through the words in the "prefixes_suffixes" list and replace them with an empty space, "".
for word in prefixes_suffixes:
    student_data_df["student_name"] = student_data_df["student_name"].str.replace(word,"", regex =True)
    print(student_data_df.head())
44/69:
# Iterate through the words in the "prefixes_suffixes" list and replace them with an empty space, "".
for word in prefixes_suffixes:
    student_data_df["student_name"] = student_data_df["student_name"].str.replace(word,"", regex =True)
    print(student_data_df.head(1))
44/70:
# Iterate through the words in the "prefixes_suffixes" list and replace them with an empty space, "".
for word in prefixes_suffixes:
    student_data_df["student_name"] = student_data_df["student_name"].str.replace(word,"", regex =True)
    print(student_data_df.head())
44/71:
# Iterate through the words in the "prefixes_suffixes" list and replace them with an empty space, "".
for word in prefixes_suffixes:
    student_data_df = student_data_df["student_name"].str.replace(word,"", regex =True)
    print(student_data_df.head())
44/72:
# Iterate through the words in the "prefixes_suffixes" list and replace them with an empty space, "".
for word in prefixes_suffixes:
    student_data_df["student_name"] = student_data_df["student_name"].str.replace(word,"", regex =True)
    print(student_data_df.head())
44/73:
# Combine the data into a single dataset.
school_data_complete_df = pd.merge(student_data_df, school_data_df, on=["school_name", "school_name"])
school_data_complete_df.head()
44/74:
# Add each prefix and suffix to remove to a list.
prefixes_suffixes = ["Dr. ", "Mr. ","Ms. ", "Mrs. ", "Miss ", " MD", " DDS", " DVM", " PhD"]
44/75:
# Iterate through the words in the "prefixes_suffixes" list and replace them with an empty space, "".
for word in prefixes_suffixes:
    student_data_df["student_name"] = student_data_df["student_name"].str.replace(word,"", regex =True)
    print(student_data_df.head())
44/76:
# Iterate through the words in the "prefixes_suffixes" list and replace them with an empty space, "".
for word in prefixes_suffixes:
    student_data_df ["student_name"]= student_data_df["student_name"].str.replace(word,"", regex =True)
    print(student_data_df.head())
44/77:
# Read the student data file and store it in a Pandas DataFrame.
student_data_df = pd.read_csv(student_data_to_load)
student_data_df.head()
44/78:
# Read the student data file and store it in a Pandas DataFrame.
student_data_df = pd.read_csv(student_data_to_load)
student_data_df.head()
44/79:
# Iterate through the words in the "prefixes_suffixes" list and replace them with an empty space, "".
for word in prefixes_suffixes:
    student_data_df["student_name"]= student_data_df["student_name"].str.replace(word,"", regex =True)
    print(student_data_df.head())
44/80:
# Combine the data into a single dataset.
school_data_complete_df = pd.merge(student_data_df, school_data_df, on=["school_name", "school_name"])
school_data_complete_df.head()
44/81:
#Get the total number of students
#student_count = school_data_complete_df.count()
#student_count
school_data_complete_df["Student ID"].count()
44/82:
#Calculate the total number of schools
school_count=school_data_df["school_name"].count()
school_count
44/83:
# Calculate the total budget.
total_budget = school_data_df["Budget"].sum()
total_budget
44/84:
# Calculate the total budget.
total_budget = school_data_df["budget"].sum()
total_budget
44/85:
# Calculate the total budget.
#total_budget = 
school_data_df["budget"].sum()
#total_budget
44/86:
# Combine the data into a single dataset.
school_data_complete_df = pd.merge(student_data_df, school_data_df, on=["school_name", "school_name"])
school_data_complete_df
44/87:
# Combine the data into a single dataset.
school_data_complete_df = pd.merge(student_data_df, school_data_df, on=["school_name", "school_name"])
school_data_complete_df.head()
44/88:
#Calculate the average reading score
average_reading_score = school_data_complete["reading_score"].average
average_reading_score
44/89:
#Calculate the average reading score
average_reading_score = school_data_complete_df["reading_score"].average
average_reading_score
44/90:
# Calculate the total number of schools
school_count_2 = school_data_complete_df["school_name"].unique()
school_count_2
44/91:
#Running the code: 
len(school_data_complete_df["school_name"].unique())
44/92:
# Calculate the total budget.
total_budget = school_data_df["budget"].sum()
total_budget
44/93:
#Calculate the average reading score
average_reading_score = school_data_complete_df["reading_score"].average
average_reading_score
44/94:
#Calculate the average reading score
average_reading_score = school_data_complete_df["reading_score"].average()
average_reading_score
44/95:
#Calculate the average reading score
average_reading_score = school_data_complete_df["reading_score"].mean()
average_reading_score
44/96:
# Calculate the average math score.
average_math_score = school_data_complete_df["math_score"].mean()
average_math_score
44/97:
#Determine the passing grade
passing_math = school_data_complete_df["math_score"] >= 70
passing_reading = school_data_complete_df["reading_score"] >= 70
44/98: passing_reading
44/99: passing_math
44/100:
#Determine the passing grade
passing_math = school_data_complete_df["math_score"] >= 70
passing_math
44/101:
passing_reading = school_data_complete_df["reading_score"] >= 70
passing_reading
44/102:
passing_math = school_data_complete_df[school_data_complete_df["math_score"] >= 70]
passing_math.head()
44/103:
# Get all the students that are passing reading in a new DataFrame.
passing_reading = school_data_complete_df[school_data_complete_df["reading_score"] >= 70]
44/104:
# Get all the students that are passing reading in a new DataFrame.
passing_reading = school_data_complete_df[school_data_complete_df["reading_score"] >= 70]
passing_reading
44/105:
# Get all the students that are passing reading in a new DataFrame.
passing_reading = school_data_complete_df[school_data_complete_df["reading_score"] >= 70]
passing_reading.head()
44/106: passing_math["student_name"].count()
44/107:
len(passing_math["student_name"])
#.count()
44/108: passing_math["student_name"].count()
44/109:
# Calculate the number of students passing math.
passing_math_count = passing_math["student_name"].count()

# Calculate the number of students passing reading.
passing_reading_count = passing_reading["student_name"].count()
44/110:
# Calculate the number of students passing math.
passing_math_count = passing_math["student_name"].count()
44/111:
# Calculate the number of students passing reading.
passing_reading_count = passing_reading["student_name"].count()
44/112:
# Calculate the number of students passing math.
passing_math_count = passing_math["student_name"].count()
passing_math_count
44/113:
# Calculate the number of students passing reading.
passing_reading_count = passing_reading["student_name"].count()
passing_reading_count
44/114:
# Calculate the number of students passing math.
passing_math_count = passing_math["student_name"].count()
passing_math_count
# Calculate the number of students passing reading.
passing_reading_count = passing_reading["student_name"].count()
passing_reading_count
44/115:
# Calculate the number of students passing math.
passing_math_count = passing_math["student_name"].count()
passing_math_count
# Calculate the number of students passing reading.
passing_reading_count = passing_reading["student_name"].count()
passing_reading_count
44/116:
# Calculate the number of students passing math.
passing_math_count = passing_math["student_name"].count()
passing_math_count
# Calculate the number of students passing reading.
passing_reading_count = passing_reading["student_name"].count()
passing_reading_count
44/117:
# Calculate the number of students passing math.
passing_math_count = passing_math["student_name"].count()
print(passing_math_count)
# Calculate the number of students passing reading.
passing_reading_count = passing_reading["student_name"].count()
print(passing_reading_count)
44/118:
# Calculate the percent that passed math.
passing_math_percentage = passing_math_count / float(student_count) * 100

# Calculate the percent that passed reading.
passing_reading_percentage = passing_reading_count / float(student_count) * 100
44/119:
#Get the total number of students
student_count = school_data_complete_df.count()
student_count
#school_data_complete_df["Student ID"].count()
44/120:
# Calculate the percent that passed math.
passing_math_percentage = passing_math_count / float(student_count) * 100

# Calculate the percent that passed reading.
passing_reading_percentage = passing_reading_count / float(student_count) * 100
44/121:
# Calculate the percent that passed math.
passing_math_percentage = passing_math_count / float(student_count) * 100
passing_math_percentage
# Calculate the percent that passed reading.
passing_reading_percentage = passing_reading_count / float(student_count) * 100
passing_reading_percentage
44/122:
# Calculate the percent that passed math.
passing_math_percentage = passing_math_count / float(student_count) * 100
print(passing_math_percentage)
# Calculate the percent that passed reading.
passing_reading_percentage = passing_reading_count / float(student_count) * 100
print(passing_reading_percentage)
44/123:
# Calculate the percent that passed math.
passing_math_percentage = passing_math_count / float(student_count) * 100
print(passing_math_percentage)
# Calculate the percent that passed reading.
passing_reading_percentage = passing_reading_count / float(student_count) * 100
print(passing_reading_percentage)
44/124:
print(passing_math_percentage)
print(passing_reading_percentage)
44/125:
#Get the total number of students
student_count = school_data_complete_df.count()
student_count
#school_data_complete_df["Student ID"].count()
44/126:
#Running the code: 
school_data_complete_df["school_name"].unique()
44/127:
#Running the code: 
len(school_data_complete_df["school_name"].unique())
44/128:
#Running the code: 
#len(school_data_complete_df["school_name"].unique())
44/129:
# Calculate the percent that passed math.
passing_math_percentage = passing_math_count / float(student_count) * 100
passing_math_percentage
# Calculate the percent that passed reading.
passing_reading_percentage = passing_reading_count / float(student_count) * 100
passing_reading_percentage
44/130:
# Calculate the percent that passed math.
passing_math_percentage = passing_math_count / float(student_count) * 100
print(passing_math_percentage)
# Calculate the percent that passed reading.
passing_reading_percentage = passing_reading_count / float(student_count) * 100
print(passing_reading_percentage)
44/131:
# Calculate the number of students passing math.
passing_math_count = passing_math["student_name"].count()
print(passing_math_count)
# Calculate the number of students passing reading.
passing_reading_count = passing_reading["student_name"].count()
print(passing_reading_count)
44/132:
# Calculate the percent that passed math.
passing_math_percentage = passing_math_count / float(student_count) * 100
print(passing_math_percentage)
# Calculate the percent that passed reading.
passing_reading_percentage = passing_reading_count / float(student_count) * 100
print(passing_reading_percentage)
44/133:
print(passing_math_percentage)
print(passing_reading_percentage)
44/134:
# Calculate the percent that passed math.
passing_math_percentage = passing_math_count / float(student_count) * 100
# Calculate the percent that passed reading.
passing_reading_percentage = passing_reading_count / float(student_count) * 100
print(passing_math_percentage)
print(passing_reading_percentage)
44/135:
# Calculate the percent that passed math.
passing_math_percentage=passing_math_count / float(student_count) * 100
# Calculate the percent that passed reading.
passing_reading_percentage=passing_reading_count / float(student_count) * 100
print(passing_math_percentage)
print(passing_reading_percentage)
44/136:
# Iterate through the words in the "prefixes_suffixes" list and replace them with an empty space, "".
for word in prefixes_suffixes:
    student_data_df["student_name"]= student_data_df["student_name"].str.replace(word,"", )
    print(student_data_df.head())
44/137:
# Combine the data into a single dataset.
school_data_complete_df = pd.merge(student_data_df, school_data_df, on=["school_name", "school_name"])
school_data_complete_df.head()
44/138:
# Iterate through the words in the "prefixes_suffixes" list and replace them with an empty space, "".
for word in prefixes_suffixes:
    student_data_df["student_name"]= student_data_df["student_name"].str.replace(word,"",regex =True )
    print(student_data_df.head())
44/139:
#Get the total number of students
student_count = school_data_complete_df.count()
student_count
#school_data_complete_df["Student ID"].count()
44/140:
# Add the Pandas dependency.
import pandas as pd
44/141:
school_data_to_load = "Resources/schools_complete.csv"
student_data_to_load = "Resources/students_complete.csv"
44/142:
# Read the school data file and store it in a Pandas DataFrame.
school_data_df = pd.read_csv(school_data_to_load)
school_data_df
44/143:
# Read the student data file and store it in a Pandas DataFrame.
student_data_df = pd.read_csv(student_data_to_load)
student_data_df.head()
44/144:
# Determine if there are any missing values in the school data.
school_data_df.count()
44/145:
# Determine if there are any missing values in the student data.
student_data_df.count()
44/146: school_data_df.isnull()
44/147: student_data_df.isnull().sum()
44/148: student_data_df.notnull().sum()
44/149:
#Determin data types for the student DataFrame
school_data_df.dtypes
44/150:
# Determine data types for the student DataFrame.
student_data_df.dtypes
44/151:
# Read the school data file and store it in a Pandas DataFrame.
school_data_df= pd.read_csv(school_data_to_load)
school_data_df
44/152:
# Read the student data file and store it in a Pandas DataFrame.
student_data_df = pd.read_csv(student_data_to_load)
student_data_df.head()
44/153:
# Add each prefix and suffix to remove to a list.
prefixes_suffixes = ["Dr. ", "Mr. ","Ms. ", "Mrs. ", "Miss ", " MD", " DDS", " DVM", " PhD"]
44/154:
# Iterate through the words in the "prefixes_suffixes" list and replace them with an empty space, "".
for word in prefixes_suffixes:
    student_data_df["student_name"]= student_data_df["student_name"].str.replace(word,"",regex =True )
    print(student_data_df.head())
44/155:
# Combine the data into a single dataset.
school_data_complete_df = pd.merge(student_data_df, school_data_df, on=["school_name", "school_name"])
school_data_complete_df.head()
44/156:
#Get the total number of students
student_count = school_data_complete_df.count()
student_count
#school_data_complete_df["Student ID"].count()
44/157:
#Calculate the total number of schools
school_count=school_data_df["school_name"].count()
school_count
44/158:
# Calculate the total number of schools
school_count_2 = school_data_complete_df["school_name"].unique()
school_count_2
44/159:
#Running the code: 
#len(school_data_complete_df["school_name"].unique())
44/160:
# Calculate the total budget.
total_budget = school_data_df["budget"].sum()
total_budget
44/161:
#Calculate the average reading score
average_reading_score = school_data_complete_df["reading_score"].mean()
average_reading_score
44/162:
# Calculate the average math score.
average_math_score = school_data_complete_df["math_score"].mean()
average_math_score
44/163:
#Determine the passing grade
passing_math = school_data_complete_df["math_score"] >= 70
passing_math
44/164:
passing_reading = school_data_complete_df["reading_score"] >= 70
passing_reading
44/165:
passing_math = school_data_complete_df[school_data_complete_df["math_score"] >= 70]
passing_math.head()
44/166:
# Get all the students that are passing reading in a new DataFrame.
passing_reading = school_data_complete_df[school_data_complete_df["reading_score"] >= 70]
passing_reading.head()
44/167:
# Calculate the number of students passing math.
passing_math_count = passing_math["student_name"].count()
print(passing_math_count)
# Calculate the number of students passing reading.
passing_reading_count = passing_reading["student_name"].count()
print(passing_reading_count)
44/168:
# Calculate the percent that passed math.
passing_math_percentage=passing_math_count / float(student_count) * 100
# Calculate the percent that passed reading.
passing_reading_percentage=passing_reading_count / float(student_count) * 100
print(passing_math_percentage)
print(passing_reading_percentage)
44/169:
#Get the total number of students
student_count = school_data_complete_df.count()
student_count
#school_data_complete_df["Student ID"].count()
44/170:
#Get the total number of students
#student_count = school_data_complete_df.count()
student_count =school_data_complete_df["Student ID"].count()
student_count
44/171:
#Calculate the total number of schools
school_count=school_data_df["school_name"].count()
school_count
44/172:
# Calculate the total number of schools
school_count_2 = school_data_complete_df["school_name"].unique()
school_count_2
44/173:
#Running the code: 
#len(school_data_complete_df["school_name"].unique())
44/174:
# Calculate the total budget.
total_budget = school_data_df["budget"].sum()
total_budget
44/175:
#Calculate the average reading score
average_reading_score = school_data_complete_df["reading_score"].mean()
average_reading_score
44/176:
# Calculate the average math score.
average_math_score = school_data_complete_df["math_score"].mean()
average_math_score
44/177:
#Determine the passing grade
passing_math = school_data_complete_df["math_score"] >= 70
passing_math
44/178:
passing_reading = school_data_complete_df["reading_score"] >= 70
passing_reading
44/179:
passing_math = school_data_complete_df[school_data_complete_df["math_score"] >= 70]
passing_math.head()
44/180:
# Add the Pandas dependency.
import pandas as pd
44/181:
school_data_to_load = "Resources/schools_complete.csv"
student_data_to_load = "Resources/students_complete.csv"
44/182:
# Read the school data file and store it in a Pandas DataFrame.
school_data_df = pd.read_csv(school_data_to_load)
school_data_df
44/183:
# Read the student data file and store it in a Pandas DataFrame.
student_data_df = pd.read_csv(student_data_to_load)
student_data_df.head()
44/184:
# Determine if there are any missing values in the school data.
school_data_df.count()
44/185:
# Determine if there are any missing values in the student data.
student_data_df.count()
44/186: school_data_df.isnull()
44/187: student_data_df.isnull().sum()
44/188: student_data_df.notnull().sum()
44/189:
#Determin data types for the student DataFrame
school_data_df.dtypes
44/190:
# Determine data types for the student DataFrame.
student_data_df.dtypes
44/191:
# Read the school data file and store it in a Pandas DataFrame.
school_data_df= pd.read_csv(school_data_to_load)
school_data_df
44/192:
# Read the student data file and store it in a Pandas DataFrame.
student_data_df = pd.read_csv(student_data_to_load)
student_data_df.head()
44/193:
# Add each prefix and suffix to remove to a list.
prefixes_suffixes = ["Dr. ", "Mr. ","Ms. ", "Mrs. ", "Miss ", " MD", " DDS", " DVM", " PhD"]
44/194:
# Iterate through the words in the "prefixes_suffixes" list and replace them with an empty space, "".
for word in prefixes_suffixes:
    student_data_df["student_name"]= student_data_df["student_name"].str.replace(word,"",regex =True )
    print(student_data_df.head())
44/195:
# Combine the data into a single dataset.
school_data_complete_df = pd.merge(student_data_df, school_data_df, on=["school_name", "school_name"])
school_data_complete_df.head()
44/196:
#Get the total number of students
#student_count = school_data_complete_df.count()
student_count =school_data_complete_df["Student ID"].count()
student_count
44/197:
#Calculate the total number of schools
school_count=school_data_df["school_name"].count()
school_count
44/198:
# Calculate the total number of schools
school_count_2 = school_data_complete_df["school_name"].unique()
school_count_2
44/199:
#Running the code: 
#len(school_data_complete_df["school_name"].unique())
44/200:
# Calculate the total budget.
total_budget = school_data_df["budget"].sum()
total_budget
44/201:
#Calculate the average reading score
average_reading_score = school_data_complete_df["reading_score"].mean()
average_reading_score
44/202:
# Calculate the average math score.
average_math_score = school_data_complete_df["math_score"].mean()
average_math_score
44/203:
#Determine the passing grade
passing_math = school_data_complete_df["math_score"] >= 70
passing_math
44/204:
passing_reading = school_data_complete_df["reading_score"] >= 70
passing_reading
44/205:
passing_math = school_data_complete_df[school_data_complete_df["math_score"] >= 70]
passing_math.head()
44/206:
# Get all the students that are passing reading in a new DataFrame.
passing_reading = school_data_complete_df[school_data_complete_df["reading_score"] >= 70]
passing_reading.head()
44/207:
# Calculate the number of students passing math.
passing_math_count = passing_math["student_name"].count()
print(passing_math_count)
# Calculate the number of students passing reading.
passing_reading_count = passing_reading["student_name"].count()
print(passing_reading_count)
44/208:
# Calculate the percent that passed math.
passing_math_percentage=passing_math_count / float(student_count) * 100
# Calculate the percent that passed reading.
passing_reading_percentage=passing_reading_count / float(student_count) * 100
print(passing_math_percentage)
print(passing_reading_percentage)
44/209:
# Calculate the students who passed both math and reading.
passing_math_reading = school_data_complete_df[(school_data_complete_df["math_score"] >= 70) & (school_data_complete_df["reading_score"] >= 70)]

passing_math_reading.head()
44/210:
overall_passing_math_reading_count = passing_math_reading["student_name"].count()
overall_passing_math_reading_count
44/211:
# Calculate the students who passed both math and reading.
passing_math_reading = school_data_complete_df[(school_data_complete_df["math_score"] >= 70) & (school_data_complete_df["reading_score"] >= 70)]

passing_math_reading.head()
44/212:
overall_passing_math_reading_count = passing_math_reading["student_name"].count()
overall_passing_math_reading_count
44/213:
overall_passing_math_reading_count = passing_math_reading["student_name"].count()*100
overall_passing_math_reading_count
44/214:
# Calculate the overall passing percentage.
overall_passing_percentage = overall_passing_math_reading_count / student_count * 100
overall_passing_percentage
44/215:
# Calculate the number of students who passed both math and reading.
overall_passing_math_reading_count = passing_math_reading["student_name"].count()
44/216:
# Calculate the overall passing percentage.
overall_passing_percentage = overall_passing_math_reading_count / student_count * 100
overall_passing_percentage
44/217:
# Adding a list of values with keys to create a new DataFrame.
district_summary_df = pd.DataFrame(
          [{"Total Schools": school_count,
          "Total Students": student_count,
          "Total Budget": total_budget,
          "Average Math Score": average_math_score,
          "Average Reading Score": average_reading_score,
          "% Passing Math": passing_math_percentage,
         "% Passing Reading": passing_reading_percentage,
        "% Overall Passing": overall_passing_percentage}])
district_summary_df
46/1:
def say_hello():
    print("Hello!")
46/2:
def say_hello():
    print("Hello!")
46/3: say_hello
46/4: say_hello()
46/5:
def say_something:
    print(something)
46/6:
def say_something:
    print("something")
46/7:
def say_something:
    print(something)
46/8:
def say_hello():
    print("Hello!")
46/9: say_hello()
46/10:
def say_something:
    print(something)
46/11:
def say_something():
    print(something)
46/12: say_something()
46/13:
def say_something():
    print(something)
46/14: say_something()
46/15:
def say_hello():
    print("Hello!")
46/16: say_hello()
46/17:
def say_something():
    print("something")
46/18: say_something()
46/19: say_something("Hello World")
46/20: say_something("something")
46/21:
def say_something():
    print("something")
46/22: say_something("something")
46/23:
def say_something():
    print("something")
46/24: say_something()
46/25:
Jane_says = "Hi, my name is Jane. I'm learning Python!"
say_something(Jane_says)
46/26: say_something()
46/27:
Jane_says = "Hi, my name is Jane. I'm learning Python!"
say_something(Jane_says)
46/28:
def say_something():
    print("something")
46/29: say_something()
46/30:
Jane_says = "Hi, my name is Jane. I'm learning Python!"
say_something(Jane_says)
46/31:
def say_something():
    
    print("something")
46/32:
def say_something():
    Jane_says = "Hi, my name is Jane. I'm learning Python!"
    print("something")
46/33: say_something()
46/34:

say_something(Jane_says)
46/35: say_something(Jane_says)
46/36: say_something("Hello World")
46/37:
def say_something():
    print("something")
46/38: say_something()
46/39: say_something("Hello World")
46/40: say_something()
46/41:
def say_something():
    print("Hello World")
46/42: say_something()
46/43:
def say_something():
    Jane_says = "Hi, my name is Jane. I'm learning Python!
46/44:
def say_something():
    Jane_says = "Hi, my name is Jane. I'm learning Python!
    print("Jane_says")
46/45:
def say_something():
    Jane_says = "Hi, my name is Jane. I'm learning Python!
    print("Jane_says")
46/46:
def say_something():
    print("something")
46/47:
def say_something():
    Jane_says ="Hi, my name is Jane. I'm learning Python!"
    print("something("Jane_says")")
46/48:
def say_something():
    
    print("something")
46/49:
Jane_says ="Hi, my name is Jane. I'm learning Python!"
say_something("Jane_says")
46/50:
def say_something():
    
    print("something")
46/51:
Jane_says = "Hi, my name is Jane. I'm learning Python!"
say_something("Jane_says")
46/52:
def say_something():
    
    print("something")
46/53:
Jane_says = "Hi, my name is Jane. I'm learning Python!"
say_something(Jane_says)
46/54:
def Jane_says = "Hi, my name is Jane. I'm learning Python!":
    print("Jane_says")
46/55:
def Jane_says ():
    print("Jane_says")
46/56:
Jane_says = "Hi, my name is Jane. I'm learning Python!"
say_something(Jane_says)
46/57:
def say_something():
    
    print("Jane_says")
46/58:
Jane_says = "Hi, my name is Jane. I'm learning Python!"
say_something(Jane_says)
46/59:
def say_something():
    print("Hi, my name is Jane. I'm learning Python!")
46/60:
Jane_says = "Hi, my name is Jane. I'm learning Python!"
say_something(Jane_says)
46/61:
def say_hello():
    print("Hello!")
46/62: say_hello()
46/63:
def say_something():
    print("something")
46/64: say_something()
46/65:
def say_something():
    print("Hello World")
46/66: say_something()
46/67:
def say_something():
    print("Hi, my name is Jane. I'm learning Python!")
46/68:
Jane_says = "Hi, my name is Jane. I'm learning Python!"
say_something(Jane_says)
46/69: say_something()
46/70:
def say_something():
    print("Hi, my name is Jane. I'm learning Python!")
46/71:
Jane_says = "Hi, my name is Jane. I'm learning Python!"
say_something(Jane_says)
46/72:
def say_hello():
    print("Hello!")
46/73: say_hello()
46/74:
def say_something():
    print("something")
46/75: say_something()
46/76: say_something()
46/77: say_something("Hello World")
46/78:
def say_hello():
    print("Hello!")
46/79: say_hello()
46/80:
def say_something():
    print("something")
46/81: say_something()
46/82: say_something("Hello World")
46/83:
def say_something():
    print("something")
46/84: say_something()
46/85: say_something("Hello World")
46/86:
def say_something():
    print("Hello World")
46/87:
def say_something():
    print("Hello World")
    say_something()
46/88: say_something()
47/1:
def say_something():
    print("Hello World")
47/2:
def say_something():
    print("Hello World")
47/3: say_something()
47/4:
def say_something():
    print(Jane_says)
47/5: Jane_says = "Hi, my name is Jane. I'm learning Python!"
47/6: say_something()
47/7:
def say_something():
    print(Jane_says)
Jane_says = "Hi, my name is Jane. I'm learning Python!"
47/8: say_something()
47/9:
def say_hello():
    print("Hello!")
47/10: say_hello()
47/11:
def say_something():
    print("something")
47/12: say_something()
47/13:
def say_something():
    print("Hello World")
47/14: say_something()
47/15:
def say_something():
    print(Jane_says)
Jane_says = "Hi, my name is Jane. I'm learning Python!"
47/16: say_something()
44/218:
# Add the Pandas dependency.
import pandas as pd
44/219:
school_data_to_load = "Resources/schools_complete.csv"
student_data_to_load = "Resources/students_complete.csv"
44/220:
# Read the school data file and store it in a Pandas DataFrame.
school_data_df = pd.read_csv(school_data_to_load)
school_data_df
44/221:
# Read the student data file and store it in a Pandas DataFrame.
student_data_df = pd.read_csv(student_data_to_load)
student_data_df.head()
44/222:
# Determine if there are any missing values in the school data.
school_data_df.count()
44/223:
# Determine if there are any missing values in the student data.
student_data_df.count()
44/224: school_data_df.isnull()
44/225: student_data_df.isnull().sum()
44/226: student_data_df.notnull().sum()
44/227:
#Determin data types for the student DataFrame
school_data_df.dtypes
44/228:
# Determine data types for the student DataFrame.
student_data_df.dtypes
44/229:
# Read the school data file and store it in a Pandas DataFrame.
school_data_df= pd.read_csv(school_data_to_load)
school_data_df
44/230:
# Read the student data file and store it in a Pandas DataFrame.
student_data_df = pd.read_csv(student_data_to_load)
student_data_df.head()
44/231:
# Add each prefix and suffix to remove to a list.
prefixes_suffixes = ["Dr. ", "Mr. ","Ms. ", "Mrs. ", "Miss ", " MD", " DDS", " DVM", " PhD"]
44/232:
# Iterate through the words in the "prefixes_suffixes" list and replace them with an empty space, "".
for word in prefixes_suffixes:
    student_data_df["student_name"]= student_data_df["student_name"].str.replace(word,"",regex =True )
    print(student_data_df.head())
44/233:
# Combine the data into a single dataset.
school_data_complete_df = pd.merge(student_data_df, school_data_df, on=["school_name", "school_name"])
school_data_complete_df.head()
44/234:
#Get the total number of students
#student_count = school_data_complete_df.count()
student_count =school_data_complete_df["Student ID"].count()
student_count
44/235:
#Calculate the total number of schools
school_count=school_data_df["school_name"].count()
school_count
44/236:
# Calculate the total number of schools
school_count_2 = school_data_complete_df["school_name"].unique()
school_count_2
44/237:
#Running the code: 
#len(school_data_complete_df["school_name"].unique())
44/238:
# Calculate the total budget.
total_budget = school_data_df["budget"].sum()
total_budget
44/239:
#Calculate the average reading score
average_reading_score = school_data_complete_df["reading_score"].mean()
average_reading_score
44/240:
# Calculate the average math score.
average_math_score = school_data_complete_df["math_score"].mean()
average_math_score
44/241:
#Determine the passing grade
passing_math = school_data_complete_df["math_score"] >= 70
passing_math
44/242:
passing_reading = school_data_complete_df["reading_score"] >= 70
passing_reading
44/243:
passing_math = school_data_complete_df[school_data_complete_df["math_score"] >= 70]
passing_math.head()
44/244:
# Get all the students that are passing reading in a new DataFrame.
passing_reading = school_data_complete_df[school_data_complete_df["reading_score"] >= 70]
passing_reading.head()
44/245:
# Calculate the number of students passing math.
passing_math_count = passing_math["student_name"].count()
print(passing_math_count)
# Calculate the number of students passing reading.
passing_reading_count = passing_reading["student_name"].count()
print(passing_reading_count)
44/246:
# Calculate the percent that passed math.
passing_math_percentage=passing_math_count / float(student_count) * 100
# Calculate the percent that passed reading.
passing_reading_percentage=passing_reading_count / float(student_count) * 100
print(passing_math_percentage)
print(passing_reading_percentage)
44/247:
# Calculate the students who passed both math and reading.
passing_math_reading = school_data_complete_df[(school_data_complete_df["math_score"] >= 70) & (school_data_complete_df["reading_score"] >= 70)]

passing_math_reading.head()
44/248:
# Calculate the number of students who passed both math and reading.
overall_passing_math_reading_count = passing_math_reading["student_name"].count()
44/249:
# Calculate the overall passing percentage.
overall_passing_percentage = overall_passing_math_reading_count / student_count * 100
overall_passing_percentage
44/250:
# Adding a list of values with keys to create a new DataFrame.
district_summary_df = pd.DataFrame(
          [{"Total Schools": school_count,
          "Total Students": student_count,
          "Total Budget": total_budget,
          "Average Math Score": average_math_score,
          "Average Reading Score": average_reading_score,
          "% Passing Math": passing_math_percentage,
         "% Passing Reading": passing_reading_percentage,
        "% Overall Passing": overall_passing_percentage}])
district_summary_df
47/17:
def say_something(Jane_says):
    print(Jane_says)
Jane_says = "Hi, my name is Jane. I'm learning Python!"
47/18: say_something()
47/19:
say_something()
Jane_says = "Hi, my name is Jane. I'm learning Python!
47/20:
def say_something(Jane_says):
    print(Jane_says)
47/21:
say_something(Jane_says)
Jane_says = "Hi, my name is Jane. I'm learning Python!
47/22:
def say_something(Jane_says):
    print(Jane_says)
    Jane_says = "Hi, my name is Jane. I'm learning Python!
47/23: say_something(Jane_says)
47/24:
def say_something(Jane_says):
    print(Jane_says)
    Jane_says = "Hi, my name is Jane. I'm learning Python!
47/25: say_something(Jane_says)
47/26:
def say_something():
    print(Jane_says)
    Jane_says = "Hi, my name is Jane. I'm learning Python!
47/27: say_something(Jane_says)
47/28:
def say_something():
    print(Jane_says)
    Jane_says = "Hi, my name is Jane. I'm learning Python!
47/29: say_something(Jane_says)
47/30:
def say_something():
    print(Jane_says)
Jane_says = "Hi, my name is Jane. I'm learning Python!
47/31: say_something(Jane_says)
47/32: say_something()
47/33:
def say_something():
    print(Jane_says)
Jane_says = "Hi, my name is Jane. I'm learning Python!
47/34: say_something(Jane_says)
47/35:
def say_hello():
    print("Hello!")
47/36: say_hello()
47/37:
def say_something():
    print("something")
47/38: say_something()
47/39:
def say_something():
    print("Hello World")
47/40: say_something()
47/41:
def say_something():
    print(Jane_says)
Jane_says = "Hi, my name is Jane. I'm learning Python!"
47/42: say_something()
47/43:
def say_something():
    print(Jane_says)
Jane_says = "Hi, my name is Jane. I'm learning Python!
47/44: say_something(Jane_says)
44/251:
# Define a function that calculates the percentage of students that passed both 
# math and reading and returns the passing percentage when the function is called.

def passing_math_percent(pass_math_count, student_count):
    return pass_math_count / float(student_count) * 100
44/252: passing_math_percent
44/253: passing_math_percent()
44/254: passing_math_percent
44/255: passing_math_percent(pass_math_count, student_count)
44/256: passing_math_percent
44/257:
# Define a function that calculates the percentage of students that passed both 
# math and reading and returns the passing percentage when the function is called.

def passing_math_percent(pass_math_count, student_count):
    return pass_math_count / float(student_count) * 100
44/258: passing_math_percent(pass_math_count, student_count)
44/259:
# Define a function that calculates the percentage of students that passed both 
# math and reading and returns the passing percentage when the function is called.

def passing_math_percent(pass_math_count, student_count):
    return pass_math_count / float(student_count) * 100
44/260:
passing_math_count = 29370
total_student_count = 39170
44/261: passing_math_percent(passing_math_count, total_student_count)
47/45: say_something()
47/46:
def say_something():
    print(Jane_says)
47/47: Jane_says = "Hi, my name is Jane. I'm learning Python!
47/48: Jane_says = "Hi, my name is Jane. I'm learning Python!
47/49: say_something()
47/50: Jane_says = "Hi, my name is Jane. I'm learning Python!"
47/51: say_something()
47/52:
#Import pandas
import panda as pd
#Convert the my_grades to a Series
my_grades = pd.Series(my_grades)
my_grades
47/53:
# A list of my mu grades.
my_grades = ['B', 'C', 'B' , 'D']
47/54:
#Import pandas
import panda as pd
#Convert the my_grades to a Series
my_grades = pd.Series(my_grades)
my_grades
47/55:
#Import pandas
import pandas as pd
#Convert the my_grades to a Series
my_grades = pd.Series(my_grades)
my_grades
47/56:
# A list of my mu grades.
my_grades = ['B', 'C', 'B' , 'D']
47/57:
#Import pandas
import pandas as pd
#Convert the my_grades to a Series
my_grades = pd.Series(my_grades)
my_grades
47/58: map(my_grades('B':'A','C':'B','D':'C'))
47/59:
#Import pandas
import pandas as pd
#Convert the my_grades to a Series
my_grades = pd.Series(my_grades)
my_grades
47/60: map(my_grades("B":"A","C":"B","D":"C"))
47/61:
x = map(my_grades("B":"A","C":"B","D":"C"))
print(x)
47/62:
#Import pandas
import pandas as pd
#Convert the my_grades to a Series
my_grades = pd.Series(my_grades)
my_grades
47/63:
x = map(my_grades("B":"A","C":"B","D":"C"))
print(x)
47/64:
x=map(my_grades("B":"A","C":"B","D":"C"))
print(x)
47/65: my_grades.map({'B': 'A', 'C': 'B', 'D': 'C'})
47/66:
# Using the format() function.
my_grades = [92.34, 84.56, 86.78, 98.32]

for grade in my_grades:
    print("{:.0f}".format(grade))
47/67:
# Using the format() function.
my_grades = [92.34, 84.56, 86.78, 98.32]

for grade in my_grades:
    print(format(grade))
47/68:
# Using the format() function.
my_grades = [92.34, 84.56, 86.78, 98.32]

for grade in my_grades:
    print("{:.0f}".format(grade))
47/69:
# Using the format() function.
my_grades = [92.34, 84.56, 86.78, 98.32]

for grade in my_grades:
    print("{:.1f}".format(grade))
47/70:
# Using the format() function.
my_grades = [92.34, 84.56, 86.78, 98.32]

for grade in my_grades:
    print("{:.0f}".format(grade))
47/71:
# A list of my mu grades.
my_grades = ['B', 'C', 'B' , 'D']
47/72:
# A list of my mu grades.
my_grades = ['B', 'C', 'B' , 'D']
print(my_grades)
47/73:
# A list of my mu grades.
my_grades = ['B', 'C', 'B' , 'D']
47/74:
#Import pandas
import pandas as pd
#Convert the my_grades to a Series
my_grades = pd.Series(my_grades)
my_grades
47/75: my_grades.map({'B': 'A', 'C': 'B', 'D': 'C'})
47/76:
# Convert the numerical grades to a Series.
my_grades = pd.Series([92.34, 84.56, 86.78, 78.32])
my_grades
47/77:
# Format the grades to the nearest whole number percent.
my_grades.map("{:.0f}".format)
47/78:
# Format the grades to the nearest whole number percent.
my_grades("{:.0f}".format)
47/79:
# Format the grades to the nearest whole number percent.
my_grades.map("{:.0f}".format)
44/262:
# Add the Pandas dependency.
import pandas as pd
44/263:
school_data_to_load = "Resources/schools_complete.csv"
student_data_to_load = "Resources/students_complete.csv"
44/264:
# Determine if there are any missing values in the school data.
school_data_df.count()
44/265:
# Determine if there are any missing values in the student data.
student_data_df.count()
44/266: school_data_df.isnull()
44/267: student_data_df.isnull().sum()
44/268: student_data_df.notnull().sum()
44/269:
#Determin data types for the student DataFrame
school_data_df.dtypes
44/270:
# Determine data types for the student DataFrame.
student_data_df.dtypes
44/271:
# Read the school data file and store it in a Pandas DataFrame.
school_data_df= pd.read_csv(school_data_to_load)
school_data_df
44/272:
# Read the student data file and store it in a Pandas DataFrame.
student_data_df = pd.read_csv(student_data_to_load)
student_data_df.head()
44/273:
# Add each prefix and suffix to remove to a list.
prefixes_suffixes = ["Dr. ", "Mr. ","Ms. ", "Mrs. ", "Miss ", " MD", " DDS", " DVM", " PhD"]
44/274:
# Iterate through the words in the "prefixes_suffixes" list and replace them with an empty space, "".
for word in prefixes_suffixes:
    student_data_df["student_name"] = student_data_df["student_name"].str.replace(word,"",regex=False)
    print(student_data_df.head())
44/275:
# Combine the data into a single dataset.
school_data_complete_df = pd.merge(student_data_df, school_data_df, on=["school_name", "school_name"])
school_data_complete_df.head()
44/276:
school_data_to_load = "Resources/schools_complete.csv"
student_data_to_load = "Resources/students_complete.csv"
44/277:
# Read the school data file and store it in a Pandas DataFrame.
school_data_df = pd.read_csv(school_data_to_load)
school_data_df
44/278:
#Determine the passing grade
passing_math = school_data_complete_df["math_score"] >= 70
passing_math.head()
44/279:
# Format the "Total Students" to have the comma for a thousands separator.
district_summary_df["Total Students"] = district_summary_df["Total Students"].map("{:,}".format)

district_summary_df["Total Students"]
44/280:
district_summary_df["Total Budget"] = district_summary_df["Total Students"].map("{:"$"}".format)

district_summary_df["Total Budget"]
44/281:
district_summary_df["Total Budget"] = district_summary_df["Total Students"].map("{:,}".format)

district_summary_df["Total Budget"]
44/282:
# Format the "Total Students" to have the comma for a thousands separator.
district_summary_df["Total Students"] = district_summary_df["Total Students"].map("{:,}".format)

district_summary_df["Total Students"]
44/283:
# Add the Pandas dependency.
import pandas as pd
44/284:
school_data_to_load = "Resources/schools_complete.csv"
student_data_to_load = "Resources/students_complete.csv"
44/285:
# Read the school data file and store it in a Pandas DataFrame.
school_data_df = pd.read_csv(school_data_to_load)
school_data_df
44/286:
# Read the student data file and store it in a Pandas DataFrame.
student_data_df = pd.read_csv(student_data_to_load)
student_data_df.head()
44/287:
# Determine if there are any missing values in the school data.
school_data_df.count()
44/288:
# Determine if there are any missing values in the student data.
student_data_df.count()
44/289: school_data_df.isnull()
44/290: student_data_df.isnull().sum()
44/291: student_data_df.notnull().sum()
44/292:
#Determin data types for the student DataFrame
school_data_df.dtypes
44/293:
# Determine data types for the student DataFrame.
student_data_df.dtypes
44/294:
# Read the school data file and store it in a Pandas DataFrame.
school_data_df= pd.read_csv(school_data_to_load)
school_data_df
44/295:
# Read the student data file and store it in a Pandas DataFrame.
student_data_df = pd.read_csv(student_data_to_load)
student_data_df.head()
44/296:
# Add each prefix and suffix to remove to a list.
prefixes_suffixes = ["Dr. ", "Mr. ","Ms. ", "Mrs. ", "Miss ", " MD", " DDS", " DVM", " PhD"]
44/297:
# Iterate through the words in the "prefixes_suffixes" list and replace them with an empty space, "".
for word in prefixes_suffixes:
    student_data_df["student_name"]= student_data_df["student_name"].str.replace(word,"",regex =True )
    print(student_data_df.head())
44/298:
# Combine the data into a single dataset.
school_data_complete_df = pd.merge(student_data_df, school_data_df, on=["school_name", "school_name"])
school_data_complete_df.head()
44/299:
#Get the total number of students
#student_count = school_data_complete_df.count()
student_count =school_data_complete_df["Student ID"].count()
student_count
44/300:
#Calculate the total number of schools
school_count=school_data_df["school_name"].count()
school_count
44/301:
# Calculate the total number of schools
school_count_2 = school_data_complete_df["school_name"].unique()
school_count_2
44/302:
#Running the code: 
#len(school_data_complete_df["school_name"].unique())
44/303:
# Calculate the total budget.
total_budget = school_data_df["budget"].sum()
total_budget
44/304:
#Calculate the average reading score
average_reading_score = school_data_complete_df["reading_score"].mean()
average_reading_score
44/305:
# Calculate the average math score.
average_math_score = school_data_complete_df["math_score"].mean()
average_math_score
44/306:
#Determine the passing grade
passing_math = school_data_complete_df["math_score"] >= 70
passing_math.head()
44/307:
passing_reading = school_data_complete_df["reading_score"] >= 70
passing_reading
44/308:
passing_math = school_data_complete_df[school_data_complete_df["math_score"] >= 70]
passing_math.head()
44/309:
# Get all the students that are passing reading in a new DataFrame.
passing_reading = school_data_complete_df[school_data_complete_df["reading_score"] >= 70]
passing_reading.head()
44/310:
# Calculate the number of students passing math.
passing_math_count = passing_math["student_name"].count()
print(passing_math_count)
# Calculate the number of students passing reading.
passing_reading_count = passing_reading["student_name"].count()
print(passing_reading_count)
44/311:
# Calculate the percent that passed math.
passing_math_percentage=passing_math_count / float(student_count) * 100
# Calculate the percent that passed reading.
passing_reading_percentage=passing_reading_count / float(student_count) * 100
print(passing_math_percentage)
print(passing_reading_percentage)
44/312:
# Calculate the students who passed both math and reading.
passing_math_reading = school_data_complete_df[(school_data_complete_df["math_score"] >= 70) & (school_data_complete_df["reading_score"] >= 70)]

passing_math_reading.head()
44/313:
# Calculate the number of students who passed both math and reading.
overall_passing_math_reading_count = passing_math_reading["student_name"].count()
44/314:
# Calculate the overall passing percentage.
overall_passing_percentage = overall_passing_math_reading_count / student_count * 100
overall_passing_percentage
44/315:
# Adding a list of values with keys to create a new DataFrame.
district_summary_df = pd.DataFrame(
          [{"Total Schools": school_count,
          "Total Students": student_count,
          "Total Budget": total_budget,
          "Average Math Score": average_math_score,
          "Average Reading Score": average_reading_score,
          "% Passing Math": passing_math_percentage,
         "% Passing Reading": passing_reading_percentage,
        "% Overall Passing": overall_passing_percentage}])
district_summary_df
44/316:
# Define a function that calculates the percentage of students that passed both 
# math and reading and returns the passing percentage when the function is called.

def passing_math_percent(pass_math_count, student_count):
    return pass_math_count / float(student_count) * 100
44/317:
passing_math_count = 29370
total_student_count = 39170
44/318: passing_math_percent(passing_math_count, total_student_count)
44/319:
# Format the "Total Students" to have the comma for a thousands separator.
district_summary_df["Total Students"] = district_summary_df["Total Students"].map("{:,}".format)

district_summary_df["Total Students"]
44/320:
district_summary_df["Total Budget"] = district_summary_df["Total Students"].map("{:,}".format)

district_summary_df["Total Budget"]
44/321:
district_summary_df["Total Budget"] = district_summary_df["Budget"].map("{:,}".format)

district_summary_df["Total Budget"]
44/322:
district_summary_df["Total Budget"] = district_summary_df["Total Budget"].map("{:,}".format)

district_summary_df["Total Budget"]
44/323:
district_summary_df["Total Budget"] = district_summary_df["Total Budget"].map("${:,2f}".format)

district_summary_df["Total Budget"]
44/324:
# Format the "Total Students" to have the comma for a thousands separator.
district_summary_df["Total Students"] = district_summary_df["Total Students"].map("{:,}".format)

district_summary_df["Total Students"]
44/325:
# Add the Pandas dependency.
import pandas as pd
44/326:
school_data_to_load = "Resources/schools_complete.csv"
student_data_to_load = "Resources/students_complete.csv"
44/327:
# Read the school data file and store it in a Pandas DataFrame.
school_data_df = pd.read_csv(school_data_to_load)
school_data_df
44/328:
# Read the student data file and store it in a Pandas DataFrame.
student_data_df = pd.read_csv(student_data_to_load)
student_data_df.head()
44/329:
# Determine if there are any missing values in the school data.
school_data_df.count()
44/330:
# Determine if there are any missing values in the student data.
student_data_df.count()
44/331: school_data_df.isnull()
44/332: student_data_df.isnull().sum()
44/333: student_data_df.notnull().sum()
44/334:
#Determin data types for the student DataFrame
school_data_df.dtypes
44/335:
# Determine data types for the student DataFrame.
student_data_df.dtypes
44/336:
# Read the school data file and store it in a Pandas DataFrame.
school_data_df= pd.read_csv(school_data_to_load)
school_data_df
44/337:
# Read the student data file and store it in a Pandas DataFrame.
student_data_df = pd.read_csv(student_data_to_load)
student_data_df.head()
44/338:
# Add each prefix and suffix to remove to a list.
prefixes_suffixes = ["Dr. ", "Mr. ","Ms. ", "Mrs. ", "Miss ", " MD", " DDS", " DVM", " PhD"]
44/339:
# Iterate through the words in the "prefixes_suffixes" list and replace them with an empty space, "".
for word in prefixes_suffixes:
    student_data_df["student_name"]= student_data_df["student_name"].str.replace(word,"",regex =True )
    print(student_data_df.head())
44/340:
# Combine the data into a single dataset.
school_data_complete_df = pd.merge(student_data_df, school_data_df, on=["school_name", "school_name"])
school_data_complete_df.head()
44/341:
#Get the total number of students
#student_count = school_data_complete_df.count()
student_count =school_data_complete_df["Student ID"].count()
student_count
44/342:
#Calculate the total number of schools
school_count=school_data_df["school_name"].count()
school_count
44/343:
# Calculate the total number of schools
school_count_2 = school_data_complete_df["school_name"].unique()
school_count_2
44/344:
#Running the code: 
#len(school_data_complete_df["school_name"].unique())
44/345:
# Calculate the total budget.
total_budget = school_data_df["budget"].sum()
total_budget
44/346:
#Calculate the average reading score
average_reading_score = school_data_complete_df["reading_score"].mean()
average_reading_score
44/347:
# Calculate the average math score.
average_math_score = school_data_complete_df["math_score"].mean()
average_math_score
44/348:
#Determine the passing grade
passing_math = school_data_complete_df["math_score"] >= 70
passing_math.head()
44/349:
passing_reading = school_data_complete_df["reading_score"] >= 70
passing_reading
44/350:
passing_math = school_data_complete_df[school_data_complete_df["math_score"] >= 70]
passing_math.head()
44/351:
# Get all the students that are passing reading in a new DataFrame.
passing_reading = school_data_complete_df[school_data_complete_df["reading_score"] >= 70]
passing_reading.head()
44/352:
# Calculate the number of students passing math.
passing_math_count = passing_math["student_name"].count()
print(passing_math_count)
# Calculate the number of students passing reading.
passing_reading_count = passing_reading["student_name"].count()
print(passing_reading_count)
44/353:
# Calculate the percent that passed math.
passing_math_percentage=passing_math_count / float(student_count) * 100
# Calculate the percent that passed reading.
passing_reading_percentage=passing_reading_count / float(student_count) * 100
print(passing_math_percentage)
print(passing_reading_percentage)
44/354:
# Calculate the students who passed both math and reading.
passing_math_reading = school_data_complete_df[(school_data_complete_df["math_score"] >= 70) & (school_data_complete_df["reading_score"] >= 70)]

passing_math_reading.head()
44/355:
# Calculate the number of students who passed both math and reading.
overall_passing_math_reading_count = passing_math_reading["student_name"].count()
44/356:
# Calculate the overall passing percentage.
overall_passing_percentage = overall_passing_math_reading_count / student_count * 100
overall_passing_percentage
44/357:
# Adding a list of values with keys to create a new DataFrame.
district_summary_df = pd.DataFrame(
          [{"Total Schools": school_count,
          "Total Students": student_count,
          "Total Budget": total_budget,
          "Average Math Score": average_math_score,
          "Average Reading Score": average_reading_score,
          "% Passing Math": passing_math_percentage,
         "% Passing Reading": passing_reading_percentage,
        "% Overall Passing": overall_passing_percentage}])
district_summary_df
44/358:
# Define a function that calculates the percentage of students that passed both 
# math and reading and returns the passing percentage when the function is called.

def passing_math_percent(pass_math_count, student_count):
    return pass_math_count / float(student_count) * 100
44/359:
passing_math_count = 29370
total_student_count = 39170
44/360: passing_math_percent(passing_math_count, total_student_count)
44/361:
# Format the "Total Students" to have the comma for a thousands separator.
district_summary_df["Total Students"] = district_summary_df["Total Students"].map("{:,}".format)

district_summary_df["Total Students"]
44/362:
district_summary_df["Total Budget"] = district_summary_df["Total Budget"].map("${:,2f}".format)

district_summary_df["Total Budget"]
44/363:
district_summary_df["Total Budget"] = district_summary_df["Total Budget"].map("${:,.2f}".format)

district_summary_df["Total Budget"]
44/364: district_summary_df["Average Reading Score"] = district_summary_df["Average Reading Score"].map("{:,.1f}".format)
44/365:
# Format the columns.

district_summary_df["Average Math Score"] = district_summary_df["Average Math Score"].map("{:.1f}".format)

district_summary_df["Average Reading Score"] = district_summary_df["Average Reading Score"].map("{:,.1f}".format)]

district_summary_df["% Passing Math"] = district_summary_df["% Passing Math"].map("{:.0f}".format)

district_summary_df["% Passing Reading"] = district_summary_df["% Passing Reading"].map("{:.0f}".format)

district_summary_df["% Overall Passing"] = district_summary_df["% Overall Passing"].map("{:.0f}".format)
44/366:
# Format the columns.

district_summary_df["Average Math Score"] = district_summary_df["Average Math Score"].map("{:.1f}".format)

district_summary_df["Average Reading Score"] = district_summary_df["Average Reading Score"].map("{:,.1f}".format)

district_summary_df["% Passing Math"] = district_summary_df["% Passing Math"].map("{:.0f}".format)

district_summary_df["% Passing Reading"] = district_summary_df["% Passing Reading"].map("{:.0f}".format)

district_summary_df["% Overall Passing"] = district_summary_df["% Overall Passing"].map("{:.0f}".format)
44/367:
district_summary_df["Total Budget"] = district_summary_df["Total Budget"].map("${:,.2f}".format)

district_summary_df["Total Budget"]
44/368:
# Format the columns.

district_summary_df["Average Math Score"] = district_summary_df["Average Math Score"].map("{:.1f}".format)

district_summary_df["Average Reading Score"] = district_summary_df["Average Reading Score"].map("{:,.1f}".format)

district_summary_df["% Passing Math"] = district_summary_df["% Passing Math"].map("{:.0f}".format)

district_summary_df["% Passing Reading"] = district_summary_df["% Passing Reading"].map("{:.0f}".format)

district_summary_df["% Overall Passing"] = district_summary_df["% Overall Passing"].map("{:.0f}".format)
44/369:
# Add the Pandas dependency.
import pandas as pd
44/370:
school_data_to_load = "Resources/schools_complete.csv"
student_data_to_load = "Resources/students_complete.csv"
44/371:
# Read the school data file and store it in a Pandas DataFrame.
school_data_df = pd.read_csv(school_data_to_load)
school_data_df
44/372:
# Read the student data file and store it in a Pandas DataFrame.
student_data_df = pd.read_csv(student_data_to_load)
student_data_df.head()
44/373:
# Determine if there are any missing values in the school data.
school_data_df.count()
44/374:
# Determine if there are any missing values in the student data.
student_data_df.count()
44/375: school_data_df.isnull()
44/376: student_data_df.isnull().sum()
44/377: student_data_df.notnull().sum()
44/378:
#Determin data types for the student DataFrame
school_data_df.dtypes
44/379:
# Determine data types for the student DataFrame.
student_data_df.dtypes
44/380:
# Read the school data file and store it in a Pandas DataFrame.
school_data_df= pd.read_csv(school_data_to_load)
school_data_df
44/381:
# Read the student data file and store it in a Pandas DataFrame.
student_data_df = pd.read_csv(student_data_to_load)
student_data_df.head()
44/382:
# Add each prefix and suffix to remove to a list.
prefixes_suffixes = ["Dr. ", "Mr. ","Ms. ", "Mrs. ", "Miss ", " MD", " DDS", " DVM", " PhD"]
44/383:
# Iterate through the words in the "prefixes_suffixes" list and replace them with an empty space, "".
for word in prefixes_suffixes:
    student_data_df["student_name"]= student_data_df["student_name"].str.replace(word,"",regex =True )
    print(student_data_df.head())
44/384:
# Combine the data into a single dataset.
school_data_complete_df = pd.merge(student_data_df, school_data_df, on=["school_name", "school_name"])
school_data_complete_df.head()
44/385:
#Get the total number of students
#student_count = school_data_complete_df.count()
student_count =school_data_complete_df["Student ID"].count()
student_count
44/386:
#Calculate the total number of schools
school_count=school_data_df["school_name"].count()
school_count
44/387:
# Calculate the total number of schools
school_count_2 = school_data_complete_df["school_name"].unique()
school_count_2
44/388:
#Running the code: 
#len(school_data_complete_df["school_name"].unique())
44/389:
# Calculate the total budget.
total_budget = school_data_df["budget"].sum()
total_budget
44/390:
#Calculate the average reading score
average_reading_score = school_data_complete_df["reading_score"].mean()
average_reading_score
44/391:
# Calculate the average math score.
average_math_score = school_data_complete_df["math_score"].mean()
average_math_score
44/392:
#Determine the passing grade
passing_math = school_data_complete_df["math_score"] >= 70
passing_math.head()
44/393:
passing_reading = school_data_complete_df["reading_score"] >= 70
passing_reading
44/394:
passing_math = school_data_complete_df[school_data_complete_df["math_score"] >= 70]
passing_math.head()
44/395:
# Get all the students that are passing reading in a new DataFrame.
passing_reading = school_data_complete_df[school_data_complete_df["reading_score"] >= 70]
passing_reading.head()
44/396:
# Calculate the number of students passing math.
passing_math_count = passing_math["student_name"].count()
print(passing_math_count)
# Calculate the number of students passing reading.
passing_reading_count = passing_reading["student_name"].count()
print(passing_reading_count)
44/397:
# Calculate the percent that passed math.
passing_math_percentage=passing_math_count / float(student_count) * 100
# Calculate the percent that passed reading.
passing_reading_percentage=passing_reading_count / float(student_count) * 100
print(passing_math_percentage)
print(passing_reading_percentage)
44/398:
# Calculate the students who passed both math and reading.
passing_math_reading = school_data_complete_df[(school_data_complete_df["math_score"] >= 70) & (school_data_complete_df["reading_score"] >= 70)]

passing_math_reading.head()
44/399:
# Calculate the number of students who passed both math and reading.
overall_passing_math_reading_count = passing_math_reading["student_name"].count()
44/400:
# Calculate the overall passing percentage.
overall_passing_percentage = overall_passing_math_reading_count / student_count * 100
overall_passing_percentage
44/401:
# Adding a list of values with keys to create a new DataFrame.
district_summary_df = pd.DataFrame(
          [{"Total Schools": school_count,
          "Total Students": student_count,
          "Total Budget": total_budget,
          "Average Math Score": average_math_score,
          "Average Reading Score": average_reading_score,
          "% Passing Math": passing_math_percentage,
         "% Passing Reading": passing_reading_percentage,
        "% Overall Passing": overall_passing_percentage}])
district_summary_df
44/402:
# Define a function that calculates the percentage of students that passed both 
# math and reading and returns the passing percentage when the function is called.

def passing_math_percent(pass_math_count, student_count):
    return pass_math_count / float(student_count) * 100
44/403:
passing_math_count = 29370
total_student_count = 39170
44/404: passing_math_percent(passing_math_count, total_student_count)
44/405:
# Format the "Total Students" to have the comma for a thousands separator.
district_summary_df["Total Students"] = district_summary_df["Total Students"].map("{:,}".format)

district_summary_df["Total Students"]
44/406:
district_summary_df["Total Budget"] = district_summary_df["Total Budget"].map("${:,.2f}".format)

district_summary_df["Total Budget"]
44/407:
# Format the columns.

district_summary_df["Average Math Score"] = district_summary_df["Average Math Score"].map("{:.1f}".format)

district_summary_df["Average Reading Score"] = district_summary_df["Average Reading Score"].map("{:,.1f}".format)

district_summary_df["% Passing Math"] = district_summary_df["% Passing Math"].map("{:.0f}".format)

district_summary_df["% Passing Reading"] = district_summary_df["% Passing Reading"].map("{:.0f}".format)

district_summary_df["% Overall Passing"] = district_summary_df["% Overall Passing"].map("{:.0f}".format)
44/408:
# Format the columns.

district_summary_df["Average Math Score"] = district_summary_df["Average Math Score"].map("{:.1f}".format)
district_summary_df["Average Math Score"] 

district_summary_df["Average Reading Score"] = district_summary_df["Average Reading Score"].map("{:,.1f}".format)
district_summary_df["Average Reading Score"]

district_summary_df["% Passing Math"] = district_summary_df["% Passing Math"].map("{:.0f}".format)
district_summary_df["% Passing Math"]

district_summary_df["% Passing Reading"] = district_summary_df["% Passing Reading"].map("{:.0f}".format)
district_summary_df["% Passing Reading"] 

district_summary_df["% Overall Passing"] = district_summary_df["% Overall Passing"].map("{:.0f}".format)
district_summary_df["% Overall Passing"]
44/409:
# Add the Pandas dependency.
import pandas as pd
44/410:
school_data_to_load = "Resources/schools_complete.csv"
student_data_to_load = "Resources/students_complete.csv"
44/411:
# Read the school data file and store it in a Pandas DataFrame.
school_data_df = pd.read_csv(school_data_to_load)
school_data_df
44/412:
# Read the student data file and store it in a Pandas DataFrame.
student_data_df = pd.read_csv(student_data_to_load)
student_data_df.head()
44/413:
# Determine if there are any missing values in the school data.
school_data_df.count()
44/414:
# Determine if there are any missing values in the student data.
student_data_df.count()
44/415: school_data_df.isnull()
44/416: student_data_df.isnull().sum()
44/417: student_data_df.notnull().sum()
44/418:
#Determin data types for the student DataFrame
school_data_df.dtypes
44/419:
# Determine data types for the student DataFrame.
student_data_df.dtypes
44/420:
# Read the school data file and store it in a Pandas DataFrame.
school_data_df= pd.read_csv(school_data_to_load)
school_data_df
44/421:
# Read the student data file and store it in a Pandas DataFrame.
student_data_df = pd.read_csv(student_data_to_load)
student_data_df.head()
44/422:
# Add each prefix and suffix to remove to a list.
prefixes_suffixes = ["Dr. ", "Mr. ","Ms. ", "Mrs. ", "Miss ", " MD", " DDS", " DVM", " PhD"]
44/423:
# Iterate through the words in the "prefixes_suffixes" list and replace them with an empty space, "".
for word in prefixes_suffixes:
    student_data_df["student_name"]= student_data_df["student_name"].str.replace(word,"",regex =True )
    print(student_data_df.head())
44/424:
# Combine the data into a single dataset.
school_data_complete_df = pd.merge(student_data_df, school_data_df, on=["school_name", "school_name"])
school_data_complete_df.head()
44/425:
#Get the total number of students
#student_count = school_data_complete_df.count()
student_count =school_data_complete_df["Student ID"].count()
student_count
44/426:
#Calculate the total number of schools
school_count=school_data_df["school_name"].count()
school_count
44/427:
# Calculate the total number of schools
school_count_2 = school_data_complete_df["school_name"].unique()
school_count_2
44/428:
#Running the code: 
#len(school_data_complete_df["school_name"].unique())
44/429:
# Calculate the total budget.
total_budget = school_data_df["budget"].sum()
total_budget
44/430:
#Calculate the average reading score
average_reading_score = school_data_complete_df["reading_score"].mean()
average_reading_score
44/431:
# Calculate the average math score.
average_math_score = school_data_complete_df["math_score"].mean()
average_math_score
44/432:
#Determine the passing grade
passing_math = school_data_complete_df["math_score"] >= 70
passing_math.head()
44/433:
passing_reading = school_data_complete_df["reading_score"] >= 70
passing_reading
44/434:
passing_math = school_data_complete_df[school_data_complete_df["math_score"] >= 70]
passing_math.head()
44/435:
# Get all the students that are passing reading in a new DataFrame.
passing_reading = school_data_complete_df[school_data_complete_df["reading_score"] >= 70]
passing_reading.head()
44/436:
# Calculate the number of students passing math.
passing_math_count = passing_math["student_name"].count()
print(passing_math_count)
# Calculate the number of students passing reading.
passing_reading_count = passing_reading["student_name"].count()
print(passing_reading_count)
44/437:
# Calculate the percent that passed math.
passing_math_percentage=passing_math_count / float(student_count) * 100
# Calculate the percent that passed reading.
passing_reading_percentage=passing_reading_count / float(student_count) * 100
print(passing_math_percentage)
print(passing_reading_percentage)
44/438:
# Calculate the students who passed both math and reading.
passing_math_reading = school_data_complete_df[(school_data_complete_df["math_score"] >= 70) & (school_data_complete_df["reading_score"] >= 70)]

passing_math_reading.head()
44/439:
# Calculate the number of students who passed both math and reading.
overall_passing_math_reading_count = passing_math_reading["student_name"].count()
44/440:
# Calculate the overall passing percentage.
overall_passing_percentage = overall_passing_math_reading_count / student_count * 100
overall_passing_percentage
44/441:
# Adding a list of values with keys to create a new DataFrame.
district_summary_df = pd.DataFrame(
          [{"Total Schools": school_count,
          "Total Students": student_count,
          "Total Budget": total_budget,
          "Average Math Score": average_math_score,
          "Average Reading Score": average_reading_score,
          "% Passing Math": passing_math_percentage,
         "% Passing Reading": passing_reading_percentage,
        "% Overall Passing": overall_passing_percentage}])
district_summary_df
44/442:
# Define a function that calculates the percentage of students that passed both 
# math and reading and returns the passing percentage when the function is called.

def passing_math_percent(pass_math_count, student_count):
    return pass_math_count / float(student_count) * 100
44/443:
passing_math_count = 29370
total_student_count = 39170
44/444: passing_math_percent(passing_math_count, total_student_count)
44/445:
# Format the "Total Students" to have the comma for a thousands separator.
district_summary_df["Total Students"] = district_summary_df["Total Students"].map("{:,}".format)

district_summary_df["Total Students"]
44/446:
district_summary_df["Total Budget"] = district_summary_df["Total Budget"].map("${:,.2f}".format)

district_summary_df["Total Budget"]
44/447:
# Format the columns.

district_summary_df["Average Math Score"] = district_summary_df["Average Math Score"].map("{:.1f}".format)
district_summary_df["Average Math Score"] 

district_summary_df["Average Reading Score"] = district_summary_df["Average Reading Score"].map("{:,.1f}".format)
district_summary_df["Average Reading Score"]

district_summary_df["% Passing Math"] = district_summary_df["% Passing Math"].map("{:.0f}".format)
district_summary_df["% Passing Math"]

district_summary_df["% Passing Reading"] = district_summary_df["% Passing Reading"].map("{:.0f}".format)
district_summary_df["% Passing Reading"] 

district_summary_df["% Overall Passing"] = district_summary_df["% Overall Passing"].map("{:.0f}".format)
district_summary_df["% Overall Passing"]
44/448:
#Display the DataFrame
district_summary_df
44/449:
# Determine the school type.
per_school_types = school_data_df.set_index(["school_name"])["type"]
per_school_types
44/450:
# Add the per_school_types into a DataFrame for testing.
df = pd.DataFrame(per_school_types)
df
44/451:
# Calculate the total student count.
per_school_counts = school_data_df["size"]
per_school_counts
44/452:
# Calculate the total student count.
per_school_counts = school_data_df.set_index(["school_name"])["size"]
per_school_counts
44/453:
# Calculate the total student count.
per_school_counts = school_data_complete_df["school_name"].value_counts()
per_school_counts
44/454:
# Calculate the total school budget.
per_school_budget = school_data_df.set_index(["school_name"])["budget"]
per_school_budget
44/455:
# Calculate the per capita spending.
per_school_capita = per_school_budget / per_school_counts
per_school_capit
44/456:
# Calculate the per capita spending.
per_school_capita = per_school_budget / per_school_counts
per_school_capita
44/457:
# Calculate the math scores.
student_school_math = student_data_df.set_index(["school_name"])["math_score"]
44/458:
# Calculate the math scores.
student_school_math = student_data_df.set_index(["school_name"])["math_score"]
student_school_math
44/459:
# Calculate the average math scores.
per_school_averages = school_data_complete_df.groupby(["school_name"]).mean()
per_school_averages
44/460:
# Calculate the average test scores.
per_school_math = school_data_complete_df.groupby(["school_name"]).mean()["math_score"]

per_school_reading = school_data_complete_df.groupby(["school_name"]).mean()["reading_score"]
44/461:
#Print the average test scores
per_school_math
per_school_reading
44/462:
#Print the average test scores
per_school_math
44/463: per_school_reading
44/464:
# Calculate the passing scores by creating a filtered DataFrame.
per_school_passing_math = school_data_complete_df[(school_data_complete_df["math_score"] >= 70)]

per_school_passing_reading = school_data_complete_df[(school_data_complete_df["reading_score"] >= 70)]
44/465: per_school_passing_math.head()
44/466: per_school_passing_reading
44/467: per_school_passing_reading.head()
44/468:
per_school_passing_math.head()
per_school_passing_reading.head()
44/469: per_school_passing_math.head()
44/470:
# Calculate the number of students passing math and passing reading by school.
per_school_passing_math = per_school_passing_math.groupby(["school_name"]).count()["student_name"]

per_school_passing_reading = per_school_passing_reading.groupby(["school_name"]).count()["student_name"]
44/471: per_school_passing_math
44/472: per_school_passing_reading
44/473:
# Calculate the number of students passing math and passing reading by school.
per_school_passing_math = per_school_passing_math.groupby(["school_name"]).count()["student_name"]

per_school_passing_reading = per_school_passing_reading.groupby(["school_name"]).count()["student_name"]
44/474:
# Add the Pandas dependency.
import pandas as pd
44/475:
school_data_to_load = "Resources/schools_complete.csv"
student_data_to_load = "Resources/students_complete.csv"
44/476:
# Read the school data file and store it in a Pandas DataFrame.
school_data_df = pd.read_csv(school_data_to_load)
school_data_df
44/477:
# Read the student data file and store it in a Pandas DataFrame.
student_data_df = pd.read_csv(student_data_to_load)
student_data_df.head()
44/478:
# Determine if there are any missing values in the school data.
school_data_df.count()
44/479:
# Determine if there are any missing values in the student data.
student_data_df.count()
44/480: school_data_df.isnull()
44/481: student_data_df.isnull().sum()
44/482: student_data_df.notnull().sum()
44/483:
#Determin data types for the student DataFrame
school_data_df.dtypes
44/484:
# Determine data types for the student DataFrame.
student_data_df.dtypes
44/485:
# Read the school data file and store it in a Pandas DataFrame.
school_data_df= pd.read_csv(school_data_to_load)
school_data_df
44/486:
# Read the student data file and store it in a Pandas DataFrame.
student_data_df = pd.read_csv(student_data_to_load)
student_data_df.head()
44/487:
# Add each prefix and suffix to remove to a list.
prefixes_suffixes = ["Dr. ", "Mr. ","Ms. ", "Mrs. ", "Miss ", " MD", " DDS", " DVM", " PhD"]
44/488:
# Iterate through the words in the "prefixes_suffixes" list and replace them with an empty space, "".
for word in prefixes_suffixes:
    student_data_df["student_name"]= student_data_df["student_name"].str.replace(word,"",regex =True )
    print(student_data_df.head())
44/489:
# Combine the data into a single dataset.
school_data_complete_df = pd.merge(student_data_df, school_data_df, on=["school_name", "school_name"])
school_data_complete_df.head()
44/490:
#Get the total number of students
#student_count = school_data_complete_df.count()
student_count =school_data_complete_df["Student ID"].count()
student_count
44/491:
#Calculate the total number of schools
school_count=school_data_df["school_name"].count()
school_count
44/492:
# Calculate the total number of schools
school_count_2 = school_data_complete_df["school_name"].unique()
school_count_2
44/493:
#Running the code: 
#len(school_data_complete_df["school_name"].unique())
44/494:
# Calculate the total budget.
total_budget = school_data_df["budget"].sum()
total_budget
44/495:
#Calculate the average reading score
average_reading_score = school_data_complete_df["reading_score"].mean()
average_reading_score
44/496:
# Calculate the average math score.
average_math_score = school_data_complete_df["math_score"].mean()
average_math_score
44/497:
#Determine the passing grade
passing_math = school_data_complete_df["math_score"] >= 70
passing_math.head()
44/498:
passing_reading = school_data_complete_df["reading_score"] >= 70
passing_reading
44/499:
passing_math = school_data_complete_df[school_data_complete_df["math_score"] >= 70]
passing_math.head()
44/500:
# Get all the students that are passing reading in a new DataFrame.
passing_reading = school_data_complete_df[school_data_complete_df["reading_score"] >= 70]
passing_reading.head()
44/501:
# Calculate the number of students passing math.
passing_math_count = passing_math["student_name"].count()
print(passing_math_count)
# Calculate the number of students passing reading.
passing_reading_count = passing_reading["student_name"].count()
print(passing_reading_count)
44/502:
# Calculate the percent that passed math.
passing_math_percentage=passing_math_count / float(student_count) * 100
# Calculate the percent that passed reading.
passing_reading_percentage=passing_reading_count / float(student_count) * 100
print(passing_math_percentage)
print(passing_reading_percentage)
44/503:
# Calculate the students who passed both math and reading.
passing_math_reading = school_data_complete_df[(school_data_complete_df["math_score"] >= 70) & (school_data_complete_df["reading_score"] >= 70)]

passing_math_reading.head()
44/504:
# Calculate the number of students who passed both math and reading.
overall_passing_math_reading_count = passing_math_reading["student_name"].count()
44/505:
# Calculate the overall passing percentage.
overall_passing_percentage = overall_passing_math_reading_count / student_count * 100
overall_passing_percentage
44/506:
# Adding a list of values with keys to create a new DataFrame.
district_summary_df = pd.DataFrame(
          [{"Total Schools": school_count,
          "Total Students": student_count,
          "Total Budget": total_budget,
          "Average Math Score": average_math_score,
          "Average Reading Score": average_reading_score,
          "% Passing Math": passing_math_percentage,
         "% Passing Reading": passing_reading_percentage,
        "% Overall Passing": overall_passing_percentage}])
district_summary_df
44/507:
# Define a function that calculates the percentage of students that passed both 
# math and reading and returns the passing percentage when the function is called.

def passing_math_percent(pass_math_count, student_count):
    return pass_math_count / float(student_count) * 100
44/508:
passing_math_count = 29370
total_student_count = 39170
44/509: passing_math_percent(passing_math_count, total_student_count)
44/510:
# Format the "Total Students" to have the comma for a thousands separator.
district_summary_df["Total Students"] = district_summary_df["Total Students"].map("{:,}".format)

district_summary_df["Total Students"]
44/511:
district_summary_df["Total Budget"] = district_summary_df["Total Budget"].map("${:,.2f}".format)

district_summary_df["Total Budget"]
44/512:
# Format the columns.

district_summary_df["Average Math Score"] = district_summary_df["Average Math Score"].map("{:.1f}".format)

district_summary_df["Average Reading Score"] = district_summary_df["Average Reading Score"].map("{:,.1f}".format)

district_summary_df["% Passing Math"] = district_summary_df["% Passing Math"].map("{:.0f}".format)

district_summary_df["% Passing Reading"] = district_summary_df["% Passing Reading"].map("{:.0f}".format)

district_summary_df["% Overall Passing"] = district_summary_df["% Overall Passing"].map("{:.0f}".format)
44/513:
#Display the DataFrame
district_summary_df
44/514:
# Determine the school type.
per_school_types = school_data_df.set_index(["school_name"])["type"]
per_school_types
44/515:
# Add the per_school_types into a DataFrame for testing.
df = pd.DataFrame(per_school_types)
df
44/516:
# Calculate the total student count.
per_school_counts = school_data_df["size"]
per_school_counts
44/517:
# Calculate the total student count.
per_school_counts = school_data_df.set_index(["school_name"])["size"]
per_school_counts
44/518:
# Calculate the total student count.
per_school_counts = school_data_complete_df["school_name"].value_counts()
per_school_counts
44/519:
# Calculate the total school budget.
per_school_budget = school_data_df.set_index(["school_name"])["budget"]
per_school_budget
44/520:
# Calculate the per capita spending.
per_school_capita = per_school_budget / per_school_counts
per_school_capita
44/521:
# Calculate the math scores.
student_school_math = student_data_df.set_index(["school_name"])["math_score"]
student_school_math
44/522:
# Calculate the average math scores.
per_school_averages = school_data_complete_df.groupby(["school_name"]).mean()
per_school_averages
44/523:
# Calculate the average test scores.
per_school_math = school_data_complete_df.groupby(["school_name"]).mean()["math_score"]

per_school_reading = school_data_complete_df.groupby(["school_name"]).mean()["reading_score"]
44/524:
#Print the average test scores
per_school_math
44/525: per_school_reading
44/526:
# Calculate the passing scores by creating a filtered DataFrame.
per_school_passing_math = school_data_complete_df[(school_data_complete_df["math_score"] >= 70)]

per_school_passing_reading = school_data_complete_df[(school_data_complete_df["reading_score"] >= 70)]
44/527: per_school_passing_math.head()
44/528: per_school_passing_reading.head()
44/529:
# Calculate the number of students passing math and passing reading by school.
per_school_passing_math = per_school_passing_math.groupby(["school_name"]).count()["student_name"]

per_school_passing_reading = per_school_passing_reading.groupby(["school_name"]).count()["student_name"]
44/530: per_school_passing_math
44/531: per_school_passing_reading
44/532:
# Calculate the number of students passing math and passing reading by school.
per_school_passing_math = per_school_passing_math.groupby(["school_name"]).count()["student_name"]

per_school_passing_reading = per_school_passing_reading.groupby(["school_name"]).count()["student_name"]
44/533:
# Calculate the number of students passing math and passing reading by school.
per_school_passing_math = per_school_passing_math.groupby(["school_name"]).count()["student_name"]
per_school_passing_math
44/534:
# Calculate the number of students passing math and passing reading by school.
per_school_passing_math = per_school_passing_math.groupby(["school_name"]).count()

per_school_passing_reading = per_school_passing_reading.groupby(["school_name"]).count()
44/535:
# Calculate the percentage of passing math and reading scores per school.
per_school_passing_math = per_school_passing_math / per_school_counts * 100

per_school_passing_reading = per_school_passing_reading / per_school_counts * 100
44/536: per_school_passing_math
44/537: per_school_passing_reading
44/538:
# Calculate the percentage of passing math and reading scores per school.
per_school_passing_math = per_school_passing_math / per_school_counts * 100

per_school_passing_math
44/539:
per_school_passing_reading = per_school_passing_reading / per_school_counts * 100
per_school_passing_reading
44/540:
# Add the Pandas dependency.
import pandas as pd
44/541:
school_data_to_load = "Resources/schools_complete.csv"
student_data_to_load = "Resources/students_complete.csv"
44/542:
# Read the school data file and store it in a Pandas DataFrame.
school_data_df = pd.read_csv(school_data_to_load)
school_data_df
44/543:
# Read the student data file and store it in a Pandas DataFrame.
student_data_df = pd.read_csv(student_data_to_load)
student_data_df.head()
44/544:
# Determine if there are any missing values in the school data.
school_data_df.count()
44/545:
# Determine if there are any missing values in the student data.
student_data_df.count()
44/546: school_data_df.isnull()
44/547: student_data_df.isnull().sum()
44/548: student_data_df.notnull().sum()
44/549:
#Determin data types for the student DataFrame
school_data_df.dtypes
44/550:
# Determine data types for the student DataFrame.
student_data_df.dtypes
44/551:
# Read the school data file and store it in a Pandas DataFrame.
school_data_df= pd.read_csv(school_data_to_load)
school_data_df
44/552:
# Read the student data file and store it in a Pandas DataFrame.
student_data_df = pd.read_csv(student_data_to_load)
student_data_df.head()
44/553:
# Add each prefix and suffix to remove to a list.
prefixes_suffixes = ["Dr. ", "Mr. ","Ms. ", "Mrs. ", "Miss ", " MD", " DDS", " DVM", " PhD"]
44/554:
# Iterate through the words in the "prefixes_suffixes" list and replace them with an empty space, "".
for word in prefixes_suffixes:
    student_data_df["student_name"]= student_data_df["student_name"].str.replace(word,"",regex =True )
    print(student_data_df.head())
44/555:
# Combine the data into a single dataset.
school_data_complete_df = pd.merge(student_data_df, school_data_df, on=["school_name", "school_name"])
school_data_complete_df.head()
44/556:
#Get the total number of students
#student_count = school_data_complete_df.count()
student_count =school_data_complete_df["Student ID"].count()
student_count
44/557:
#Calculate the total number of schools
school_count=school_data_df["school_name"].count()
school_count
44/558:
# Calculate the total number of schools
school_count_2 = school_data_complete_df["school_name"].unique()
school_count_2
44/559:
#Running the code: 
#len(school_data_complete_df["school_name"].unique())
44/560:
# Calculate the total budget.
total_budget = school_data_df["budget"].sum()
total_budget
44/561:
#Calculate the average reading score
average_reading_score = school_data_complete_df["reading_score"].mean()
average_reading_score
44/562:
# Calculate the average math score.
average_math_score = school_data_complete_df["math_score"].mean()
average_math_score
44/563:
#Determine the passing grade
passing_math = school_data_complete_df["math_score"] >= 70
passing_math.head()
44/564:
passing_reading = school_data_complete_df["reading_score"] >= 70
passing_reading
44/565:
passing_math = school_data_complete_df[school_data_complete_df["math_score"] >= 70]
passing_math.head()
44/566:
# Get all the students that are passing reading in a new DataFrame.
passing_reading = school_data_complete_df[school_data_complete_df["reading_score"] >= 70]
passing_reading.head()
44/567:
# Calculate the number of students passing math.
passing_math_count = passing_math["student_name"].count()
print(passing_math_count)
# Calculate the number of students passing reading.
passing_reading_count = passing_reading["student_name"].count()
print(passing_reading_count)
44/568:
# Calculate the percent that passed math.
passing_math_percentage=passing_math_count / float(student_count) * 100
# Calculate the percent that passed reading.
passing_reading_percentage=passing_reading_count / float(student_count) * 100
print(passing_math_percentage)
print(passing_reading_percentage)
44/569:
# Calculate the students who passed both math and reading.
passing_math_reading = school_data_complete_df[(school_data_complete_df["math_score"] >= 70) & (school_data_complete_df["reading_score"] >= 70)]

passing_math_reading.head()
44/570:
# Calculate the number of students who passed both math and reading.
overall_passing_math_reading_count = passing_math_reading["student_name"].count()
44/571:
# Calculate the overall passing percentage.
overall_passing_percentage = overall_passing_math_reading_count / student_count * 100
overall_passing_percentage
44/572:
# Adding a list of values with keys to create a new DataFrame.
district_summary_df = pd.DataFrame(
          [{"Total Schools": school_count,
          "Total Students": student_count,
          "Total Budget": total_budget,
          "Average Math Score": average_math_score,
          "Average Reading Score": average_reading_score,
          "% Passing Math": passing_math_percentage,
         "% Passing Reading": passing_reading_percentage,
        "% Overall Passing": overall_passing_percentage}])
district_summary_df
44/573:
# Define a function that calculates the percentage of students that passed both 
# math and reading and returns the passing percentage when the function is called.

def passing_math_percent(pass_math_count, student_count):
    return pass_math_count / float(student_count) * 100
44/574:
passing_math_count = 29370
total_student_count = 39170
44/575: passing_math_percent(passing_math_count, total_student_count)
44/576:
# Format the "Total Students" to have the comma for a thousands separator.
district_summary_df["Total Students"] = district_summary_df["Total Students"].map("{:,}".format)

district_summary_df["Total Students"]
44/577:
district_summary_df["Total Budget"] = district_summary_df["Total Budget"].map("${:,.2f}".format)

district_summary_df["Total Budget"]
44/578:
# Format the columns.

district_summary_df["Average Math Score"] = district_summary_df["Average Math Score"].map("{:.1f}".format)

district_summary_df["Average Reading Score"] = district_summary_df["Average Reading Score"].map("{:,.1f}".format)

district_summary_df["% Passing Math"] = district_summary_df["% Passing Math"].map("{:.0f}".format)

district_summary_df["% Passing Reading"] = district_summary_df["% Passing Reading"].map("{:.0f}".format)

district_summary_df["% Overall Passing"] = district_summary_df["% Overall Passing"].map("{:.0f}".format)
44/579:
#Display the DataFrame
district_summary_df
44/580:
# Determine the school type.
per_school_types = school_data_df.set_index(["school_name"])["type"]
per_school_types
44/581:
# Add the per_school_types into a DataFrame for testing.
df = pd.DataFrame(per_school_types)
df
44/582:
# Calculate the total student count.
per_school_counts = school_data_df["size"]
per_school_counts
44/583:
# Calculate the total student count.
per_school_counts = school_data_df.set_index(["school_name"])["size"]
per_school_counts
44/584:
# Calculate the total student count.
per_school_counts = school_data_complete_df["school_name"].value_counts()
per_school_counts
44/585:
# Calculate the total school budget.
per_school_budget = school_data_df.set_index(["school_name"])["budget"]
per_school_budget
44/586:
# Calculate the per capita spending.
per_school_capita = per_school_budget / per_school_counts
per_school_capita
44/587:
# Calculate the math scores.
student_school_math = student_data_df.set_index(["school_name"])["math_score"]
student_school_math
44/588:
# Calculate the average math scores.
per_school_averages = school_data_complete_df.groupby(["school_name"]).mean()
per_school_averages
44/589:
# Calculate the average test scores.
per_school_math = school_data_complete_df.groupby(["school_name"]).mean()["math_score"]

per_school_reading = school_data_complete_df.groupby(["school_name"]).mean()["reading_score"]
44/590:
#Print the average test scores
per_school_math
44/591: per_school_reading
44/592:
# Calculate the passing scores by creating a filtered DataFrame.
per_school_passing_math = school_data_complete_df[(school_data_complete_df["math_score"] >= 70)]

per_school_passing_reading = school_data_complete_df[(school_data_complete_df["reading_score"] >= 70)]
44/593: per_school_passing_math.head()
44/594: per_school_passing_reading.head()
44/595:
# Calculate the number of students passing math and passing reading by school.
per_school_passing_math = per_school_passing_math.groupby(["school_name"]).count()["student_name"]

per_school_passing_reading = per_school_passing_reading.groupby(["school_name"]).count()["student_name"]
44/596: per_school_passing_math
44/597: per_school_passing_reading
44/598:
# Calculate the percentage of passing math and reading scores per school.
per_school_passing_math = per_school_passing_math / per_school_counts * 100

per_school_passing_reading = per_school_passing_reading / per_school_counts * 100
44/599: per_school_passing_math
44/600:

per_school_passing_reading
44/601:
# Calculate the students who passed both math and reading.
per_passing_math_reading = school_data_complete_df[(school_data_complete_df["math_score"] >= 70) & (school_data_complete_df["reading_score"] >= 70)]

per_passing_math_reading.head()
44/602:
# Calculate the number of students who passed both math and reading.
per_passing_math_reading = per_passing_math_reading.groupby(["school_name"]).count()["student_name"]
44/603:
# Calculate the overall passing percentage.
per_overall_passing_percentage = per_passing_math_reading / per_school_counts * 100
44/604: per_overall_passing_percentage
44/605:
# Adding a list of values with keys to create a new DataFrame.

per_school_summary_df = pd.DataFrame({
             "School Type": per_school_types,
             "Total Students": per_school_counts,
             "Total School Budget": per_school_budget,
             "Per Student Budget": per_school_capita,
             "Average Math Score": per_school_math,
           "Average Reading Score": per_school_reading,
           "% Passing Math": per_school_passing_math,
           "% Passing Reading": per_school_passing_reading,
           "% Overall Passing": per_overall_passing_percentage})
per_school_summary_df.head()
44/606:
# Format the Total School Budget and the Per Student Budget columns.
per_school_summary_df["Total School Budget"] = per_school_summary_df["Total School Budget"].map("${:,.2f}".format)

per_school_summary_df["Per Student Budget"] = per_school_summary_df["Per Student Budget"].map("${:,.2f}".format)


# Display the data frame
per_school_summary_df.head()
44/607:
# Reorder the columns in the order you want them to appear.
new_column_order = ["School Type", "Total Students", "Total School Budget", "Per Student Budget", "Average Math Score", "Average Reading Score", "% Passing Math", "% Passing Reading", "% Overall Passing"]

# Assign district summary df the new column order.
per_school_summary_df = per_school_summary_df[new_column_order]

per_school_summary_df.head()
44/608:
# Sort and show top five schools.
top_schools = per_school_summary_df.sort_values(["% Overall Passing"], ascending=False)

top_schools.head()
44/609:
# Sort and show top five schools.
bottom_schools = per_school_summary_df.sort_values(["% Overall Passing"], ascending=True)

bottom_schools.head()
47/80:
class Cat:
    def __init__(self, name):
        self.name = name
47/81:
first_cat = Cat('Felix')
print(first_cat.name)
47/82:
second_cat = Cat('Felix')
print(second_cat.name)
47/83:
second_cat = Cat('Fofo')
print(second_cat.name)
47/84:
# Create a grade level DataFrames.
ninth_graders = school_data_complete_df[(school_data_complete_df["grade"] == "9th")]

tenth_graders = school_data_complete_df[(school_data_complete_df["grade"] == "10th")]

eleventh_graders = school_data_complete_df[(school_data_complete_df["grade"] == "11th")]

twelfth_graders = school_data_complete_df[(school_data_complete_df["grade"] == "12th")]
44/610:
# Create a grade level DataFrames.
ninth_graders = school_data_complete_df[(school_data_complete_df["grade"] == "9th")]

tenth_graders = school_data_complete_df[(school_data_complete_df["grade"] == "10th")]

eleventh_graders = school_data_complete_df[(school_data_complete_df["grade"] == "11th")]

twelfth_graders = school_data_complete_df[(school_data_complete_df["grade"] == "12th")]
44/611: ninth_graders
44/612: ninth_graders.head()
44/613: tenth_graders
44/614: tenth_graders.head
44/615: tenth_graders.head()
44/616:
# Group each grade level DataFrame by the school name for the average math score.
ninth_grade_math_scores = ninth_graders.groupby(["school_name"]).mean()["math_score"]

tenth_grade_math_scores = tenth_graders.groupby(["school_name"]).mean()["math_score"]

eleventh_grade_math_scores = eleventh_graders.groupby(["school_name"]).mean()["math_score"]

twelfth_grade_math_scores = twelfth_graders.groupby(["school_name"]).mean()["math_score"]
44/617: ninth_grade_math_scores
44/618: eleventh_grade_math_scores
44/619:
# Group each grade level DataFrame by the school name for the average reading score.
ninth_grade_reading_scores = ninth_graders.groupby(["school_name"]).mean()["reading_score"]

tenth_grade_reading_scores = tenth_graders.groupby(["school_name"]).mean()["reading_score"]

eleventh_grade_reading_scores = eleventh_graders.groupby(["school_name"]).mean()["reading_score"]

twelfth_grade_reading_scores = twelfth_graders.groupby(["school_name"]).mean()["reading_score"]
44/620: ninth_grade_reading_scores
44/621: twelfth_grade_reading_scores
44/622:
# Combine each grade level Series for average math scores by school into a single DataFrame.
math_scores_by_grade = pd.DataFrame({
               "9th": ninth_grade_math_scores,
               "10th": tenth_grade_math_scores,
               "11th": eleventh_grade_math_scores,
               "12th": twelfth_grade_math_scores})

math_scores_by_grade.head()
44/623:
# Combine each grade level Series for average reading scores by school into a single DataFrame.
reading_scores_by_grade = pd.DataFrame({
              "9th": ninth_grade_reading_scores,
              "10th": tenth_grade_reading_scores,
              "11th": eleventh_grade_reading_scores,
              "12th": twelfth_grade_reading_scores})

reading_scores_by_grade.head()
44/624:
# Format each grade column.
  math_scores_by_grade["9th"] = math_scores_by_grade["9th"].map("{:.1f}".format)

  math_scores_by_grade["10th"] = math_scores_by_grade["10th"].map("{:.1f}".format)

  math_scores_by_grade["11th"] = math_scores_by_grade["11th"].map("{:.1f}".format)

  math_scores_by_grade["12th"] = math_scores_by_grade["12th"].map("{:.1f}".format)

  # Make sure the columns are in the correct order.
  math_scores_by_grade = math_scores_by_grade[
                 ["9th", "10th", "11th", "12th"]]

  # Remove the index name.
  math_scores_by_grade.index.name = None
  # Display the DataFrame.
  math_scores_by_grade.head()
44/625:
# Combine each grade level Series for average reading scores by school into a single DataFrame.
reading_scores_by_grade = pd.DataFrame({
              "9th": ninth_grade_reading_scores,
              "10th": tenth_grade_reading_scores,
              "11th": eleventh_grade_reading_scores,
              "12th": twelfth_grade_reading_scores})

reading_scores_by_grade.head()
44/626:
# Combine each grade level Series for average reading scores by school into a single DataFrame.
reading_scores_by_grade = pd.DataFrame({
              "9th": ninth_grade_reading_scores,
              "10th": tenth_grade_reading_scores,
              "11th": eleventh_grade_reading_scores,
              "12th": twelfth_grade_reading_scores})

reading_scores_by_grade.head()
44/627:
# Format each grade column.
  math_scores_by_grade["9th"] = math_scores_by_grade["9th"].map("{:.1f}".format)

  math_scores_by_grade["10th"] = math_scores_by_grade["10th"].map("{:.1f}".format)

  math_scores_by_grade["11th"] = math_scores_by_grade["11th"].map("{:.1f}".format)

  math_scores_by_grade["12th"] = math_scores_by_grade["12th"].map("{:.1f}".format)

  # Make sure the columns are in the correct order.
  math_scores_by_grade = math_scores_by_grade[
                 ["9th", "10th", "11th", "12th"]]

  # Remove the index name.
  math_scores_by_grade.index.name = None
  # Display the DataFrame.
  math_scores_by_grade.head()
44/628:
# Add the Pandas dependency.
import pandas as pd
44/629:
school_data_to_load = "Resources/schools_complete.csv"
student_data_to_load = "Resources/students_complete.csv"
44/630:
# Read the school data file and store it in a Pandas DataFrame.
school_data_df = pd.read_csv(school_data_to_load)
school_data_df
44/631:
# Read the student data file and store it in a Pandas DataFrame.
student_data_df = pd.read_csv(student_data_to_load)
student_data_df.head()
44/632:
# Determine if there are any missing values in the school data.
school_data_df.count()
44/633:
# Determine if there are any missing values in the student data.
student_data_df.count()
44/634: school_data_df.isnull()
44/635: student_data_df.isnull().sum()
44/636: student_data_df.notnull().sum()
44/637:
#Determin data types for the student DataFrame
school_data_df.dtypes
44/638:
# Determine data types for the student DataFrame.
student_data_df.dtypes
44/639:
# Read the school data file and store it in a Pandas DataFrame.
school_data_df= pd.read_csv(school_data_to_load)
school_data_df
44/640:
# Read the student data file and store it in a Pandas DataFrame.
student_data_df = pd.read_csv(student_data_to_load)
student_data_df.head()
44/641:
# Add each prefix and suffix to remove to a list.
prefixes_suffixes = ["Dr. ", "Mr. ","Ms. ", "Mrs. ", "Miss ", " MD", " DDS", " DVM", " PhD"]
44/642:
# Iterate through the words in the "prefixes_suffixes" list and replace them with an empty space, "".
for word in prefixes_suffixes:
    student_data_df["student_name"]= student_data_df["student_name"].str.replace(word,"",regex =True )
    print(student_data_df.head())
44/643:
# Combine the data into a single dataset.
school_data_complete_df = pd.merge(student_data_df, school_data_df, on=["school_name", "school_name"])
school_data_complete_df.head()
44/644:
#Get the total number of students
#student_count = school_data_complete_df.count()
student_count =school_data_complete_df["Student ID"].count()
student_count
44/645:
#Calculate the total number of schools
school_count=school_data_df["school_name"].count()
school_count
44/646:
# Calculate the total number of schools
school_count_2 = school_data_complete_df["school_name"].unique()
school_count_2
44/647:
#Running the code: 
#len(school_data_complete_df["school_name"].unique())
44/648:
# Calculate the total budget.
total_budget = school_data_df["budget"].sum()
total_budget
44/649:
#Calculate the average reading score
average_reading_score = school_data_complete_df["reading_score"].mean()
average_reading_score
44/650:
# Calculate the average math score.
average_math_score = school_data_complete_df["math_score"].mean()
average_math_score
44/651:
#Determine the passing grade
passing_math = school_data_complete_df["math_score"] >= 70
passing_math.head()
44/652:
passing_reading = school_data_complete_df["reading_score"] >= 70
passing_reading
44/653:
passing_math = school_data_complete_df[school_data_complete_df["math_score"] >= 70]
passing_math.head()
44/654:
# Get all the students that are passing reading in a new DataFrame.
passing_reading = school_data_complete_df[school_data_complete_df["reading_score"] >= 70]
passing_reading.head()
44/655:
# Calculate the number of students passing math.
passing_math_count = passing_math["student_name"].count()
print(passing_math_count)
# Calculate the number of students passing reading.
passing_reading_count = passing_reading["student_name"].count()
print(passing_reading_count)
44/656:
# Calculate the percent that passed math.
passing_math_percentage=passing_math_count / float(student_count) * 100
# Calculate the percent that passed reading.
passing_reading_percentage=passing_reading_count / float(student_count) * 100
print(passing_math_percentage)
print(passing_reading_percentage)
44/657:
# Calculate the students who passed both math and reading.
passing_math_reading = school_data_complete_df[(school_data_complete_df["math_score"] >= 70) & (school_data_complete_df["reading_score"] >= 70)]

passing_math_reading.head()
44/658:
# Calculate the number of students who passed both math and reading.
overall_passing_math_reading_count = passing_math_reading["student_name"].count()
44/659:
# Calculate the overall passing percentage.
overall_passing_percentage = overall_passing_math_reading_count / student_count * 100
overall_passing_percentage
44/660:
# Adding a list of values with keys to create a new DataFrame.
district_summary_df = pd.DataFrame(
          [{"Total Schools": school_count,
          "Total Students": student_count,
          "Total Budget": total_budget,
          "Average Math Score": average_math_score,
          "Average Reading Score": average_reading_score,
          "% Passing Math": passing_math_percentage,
         "% Passing Reading": passing_reading_percentage,
        "% Overall Passing": overall_passing_percentage}])
district_summary_df
44/661:
# Define a function that calculates the percentage of students that passed both 
# math and reading and returns the passing percentage when the function is called.

def passing_math_percent(pass_math_count, student_count):
    return pass_math_count / float(student_count) * 100
44/662:
passing_math_count = 29370
total_student_count = 39170
44/663: passing_math_percent(passing_math_count, total_student_count)
44/664:
# Format the "Total Students" to have the comma for a thousands separator.
district_summary_df["Total Students"] = district_summary_df["Total Students"].map("{:,}".format)

district_summary_df["Total Students"]
44/665:
district_summary_df["Total Budget"] = district_summary_df["Total Budget"].map("${:,.2f}".format)

district_summary_df["Total Budget"]
44/666:
# Format the columns.

district_summary_df["Average Math Score"] = district_summary_df["Average Math Score"].map("{:.1f}".format)

district_summary_df["Average Reading Score"] = district_summary_df["Average Reading Score"].map("{:,.1f}".format)

district_summary_df["% Passing Math"] = district_summary_df["% Passing Math"].map("{:.0f}".format)

district_summary_df["% Passing Reading"] = district_summary_df["% Passing Reading"].map("{:.0f}".format)

district_summary_df["% Overall Passing"] = district_summary_df["% Overall Passing"].map("{:.0f}".format)
44/667:
#Display the DataFrame
district_summary_df
44/668:
# Determine the school type.
per_school_types = school_data_df.set_index(["school_name"])["type"]
per_school_types
44/669:
# Add the per_school_types into a DataFrame for testing.
df = pd.DataFrame(per_school_types)
df
44/670:
# Calculate the total student count.
per_school_counts = school_data_df["size"]
per_school_counts
44/671:
# Calculate the total student count.
per_school_counts = school_data_df.set_index(["school_name"])["size"]
per_school_counts
44/672:
# Calculate the total student count.
per_school_counts = school_data_complete_df["school_name"].value_counts()
per_school_counts
44/673:
# Calculate the total school budget.
per_school_budget = school_data_df.set_index(["school_name"])["budget"]
per_school_budget
44/674:
# Calculate the per capita spending.
per_school_capita = per_school_budget / per_school_counts
per_school_capita
44/675:
# Calculate the math scores.
student_school_math = student_data_df.set_index(["school_name"])["math_score"]
student_school_math
44/676:
# Calculate the average math scores.
per_school_averages = school_data_complete_df.groupby(["school_name"]).mean()
per_school_averages
44/677:
# Calculate the average test scores.
per_school_math = school_data_complete_df.groupby(["school_name"]).mean()["math_score"]

per_school_reading = school_data_complete_df.groupby(["school_name"]).mean()["reading_score"]
44/678:
#Print the average test scores
per_school_math
44/679: per_school_reading
44/680:
# Calculate the passing scores by creating a filtered DataFrame.
per_school_passing_math = school_data_complete_df[(school_data_complete_df["math_score"] >= 70)]

per_school_passing_reading = school_data_complete_df[(school_data_complete_df["reading_score"] >= 70)]
44/681: per_school_passing_math.head()
44/682: per_school_passing_reading.head()
44/683:
# Calculate the number of students passing math and passing reading by school.
per_school_passing_math = per_school_passing_math.groupby(["school_name"]).count()["student_name"]

per_school_passing_reading = per_school_passing_reading.groupby(["school_name"]).count()["student_name"]
44/684: per_school_passing_math
44/685: per_school_passing_reading
44/686:
# Calculate the percentage of passing math and reading scores per school.
per_school_passing_math = per_school_passing_math / per_school_counts * 100

per_school_passing_reading = per_school_passing_reading / per_school_counts * 100
44/687: per_school_passing_math
44/688: per_school_passing_reading
44/689:
# Calculate the students who passed both math and reading.
per_passing_math_reading = school_data_complete_df[(school_data_complete_df["math_score"] >= 70) & (school_data_complete_df["reading_score"] >= 70)]

per_passing_math_reading.head()
44/690:
# Calculate the number of students who passed both math and reading.
per_passing_math_reading = per_passing_math_reading.groupby(["school_name"]).count()["student_name"]
44/691:
# Calculate the overall passing percentage.
per_overall_passing_percentage = per_passing_math_reading / per_school_counts * 100
44/692: per_overall_passing_percentage
44/693:
# Adding a list of values with keys to create a new DataFrame.

per_school_summary_df = pd.DataFrame({
             "School Type": per_school_types,
             "Total Students": per_school_counts,
             "Total School Budget": per_school_budget,
             "Per Student Budget": per_school_capita,
             "Average Math Score": per_school_math,
           "Average Reading Score": per_school_reading,
           "% Passing Math": per_school_passing_math,
           "% Passing Reading": per_school_passing_reading,
           "% Overall Passing": per_overall_passing_percentage})
per_school_summary_df.head()
44/694:
# Format the Total School Budget and the Per Student Budget columns.
per_school_summary_df["Total School Budget"] = per_school_summary_df["Total School Budget"].map("${:,.2f}".format)

per_school_summary_df["Per Student Budget"] = per_school_summary_df["Per Student Budget"].map("${:,.2f}".format)


# Display the data frame
per_school_summary_df.head()
44/695:
# Reorder the columns in the order you want them to appear.
new_column_order = ["School Type", "Total Students", "Total School Budget", "Per Student Budget", "Average Math Score", "Average Reading Score", "% Passing Math", "% Passing Reading", "% Overall Passing"]

# Assign district summary df the new column order.
per_school_summary_df = per_school_summary_df[new_column_order]

per_school_summary_df.head()
44/696:
# Sort and show top five schools.
top_schools = per_school_summary_df.sort_values(["% Overall Passing"], ascending=False)

top_schools.head()
44/697:
# Sort and show top five schools.
bottom_schools = per_school_summary_df.sort_values(["% Overall Passing"], ascending=True)

bottom_schools.head()
44/698:
# Create a grade level DataFrames.
ninth_graders = school_data_complete_df[(school_data_complete_df["grade"] == "9th")]

tenth_graders = school_data_complete_df[(school_data_complete_df["grade"] == "10th")]

eleventh_graders = school_data_complete_df[(school_data_complete_df["grade"] == "11th")]

twelfth_graders = school_data_complete_df[(school_data_complete_df["grade"] == "12th")]
44/699: ninth_graders.head()
44/700: tenth_graders.head()
44/701:
# Group each grade level DataFrame by the school name for the average math score.
ninth_grade_math_scores = ninth_graders.groupby(["school_name"]).mean()["math_score"]

tenth_grade_math_scores = tenth_graders.groupby(["school_name"]).mean()["math_score"]

eleventh_grade_math_scores = eleventh_graders.groupby(["school_name"]).mean()["math_score"]

twelfth_grade_math_scores = twelfth_graders.groupby(["school_name"]).mean()["math_score"]
44/702: ninth_grade_math_scores
44/703: eleventh_grade_math_scores
44/704:
# Group each grade level DataFrame by the school name for the average reading score.
ninth_grade_reading_scores = ninth_graders.groupby(["school_name"]).mean()["reading_score"]

tenth_grade_reading_scores = tenth_graders.groupby(["school_name"]).mean()["reading_score"]

eleventh_grade_reading_scores = eleventh_graders.groupby(["school_name"]).mean()["reading_score"]

twelfth_grade_reading_scores = twelfth_graders.groupby(["school_name"]).mean()["reading_score"]
44/705: ninth_grade_reading_scores
44/706: twelfth_grade_reading_scores
44/707:
# Combine each grade level Series for average math scores by school into a single DataFrame.
math_scores_by_grade = pd.DataFrame({
               "9th": ninth_grade_math_scores,
               "10th": tenth_grade_math_scores,
               "11th": eleventh_grade_math_scores,
               "12th": twelfth_grade_math_scores})

math_scores_by_grade.head()
44/708:
# Combine each grade level Series for average reading scores by school into a single DataFrame.
reading_scores_by_grade = pd.DataFrame({
              "9th": ninth_grade_reading_scores,
              "10th": tenth_grade_reading_scores,
              "11th": eleventh_grade_reading_scores,
              "12th": twelfth_grade_reading_scores})

reading_scores_by_grade.head()
44/709:
# Format each grade column.
  math_scores_by_grade["9th"] = math_scores_by_grade["9th"].map("{:.1f}".format)

  math_scores_by_grade["10th"] = math_scores_by_grade["10th"].map("{:.1f}".format)

  math_scores_by_grade["11th"] = math_scores_by_grade["11th"].map("{:.1f}".format)

  math_scores_by_grade["12th"] = math_scores_by_grade["12th"].map("{:.1f}".format)

  # Make sure the columns are in the correct order.
  math_scores_by_grade = math_scores_by_grade[
                 ["9th", "10th", "11th", "12th"]]

  # Remove the index name.
  math_scores_by_grade.index.name = None
  # Display the DataFrame.
  math_scores_by_grade.head()
44/710:
# Format each grade column.
  math_scores_by_grade["9th"] = math_scores_by_grade["9th"].map("{:.1f}".format)

  math_scores_by_grade["10th"] = math_scores_by_grade["10th"].map("{:.1f}".format)

  math_scores_by_grade["11th"] = math_scores_by_grade["11th"].map("{:.1f}".format)

  math_scores_by_grade["12th"] = math_scores_by_grade["12th"].map("{:.1f}".format)
44/711:
# Format each grade column.

math_scores_by_grade["9th"] = math_scores_by_grade["9th"].map("{:.1f}".format)

math_scores_by_grade["10th"] = math_scores_by_grade["10th"].map("{:.1f}".format)

math_scores_by_grade["11th"] = math_scores_by_grade["11th"].map("{:.1f}".format)

math_scores_by_grade["12th"] = math_scores_by_grade["12th"].map("{:.1f}".format)
44/712:
# Format each grade column.

math_scores_by_grade["9th"] = math_scores_by_grade["9th"].map("{:.1f}".format)

math_scores_by_grade["10th"] = math_scores_by_grade["10th"].map("{:.1f}".format)

math_scores_by_grade["11th"] = math_scores_by_grade["11th"].map("{:.1f}".format)

math_scores_by_grade["12th"] = math_scores_by_grade["12th"].map("{:.1f}".format)

# Make sure the columns are in the correct order.
math_scores_by_grade = math_scores_by_grade[
                 ["9th", "10th", "11th", "12th"]]

# Remove the index name.
math_scores_by_grade.index.name = None
# Display the DataFrame.
math_scores_by_grade.head()
44/713:
# Format each grade column.

math_scores_by_grade["9th"] = math_scores_by_grade["9th"].map("{:.1f}".format)

math_scores_by_grade["10th"] = math_scores_by_grade["10th"].map("{:.1f}".format)

math_scores_by_grade["11th"] = math_scores_by_grade["11th"].map("{:.1f}".format)

math_scores_by_grade["12th"] = math_scores_by_grade["12th"].map("{:.1f}".format)

# Make sure the columns are in the correct order.
math_scores_by_grade = math_scores_by_grade[
    ["9th", "10th", "11th", "12th"]]

# Remove the index name.
math_scores_by_grade.index.name = None
# Display the DataFrame.
math_scores_by_grade.head()
44/714:
# Format each grade column.

math_scores_by_grade["9th"] = math_scores_by_grade["9th"].map("{:.1f}".format)

math_scores_by_grade["10th"] = math_scores_by_grade["10th"].map("{:.1f}".format)

math_scores_by_grade["11th"] = math_scores_by_grade["11th"].map("{:.1f}".format)

math_scores_by_grade["12th"] = math_scores_by_grade["12th"].map("{:.1f}".format)

# Make sure the columns are in the correct order.
math_scores_by_grade = math_scores_by_grade[["9th", "10th", "11th", "12th"]]

# Remove the index name.
math_scores_by_grade.index.name = None
# Display the DataFrame.
math_scores_by_grade.head()
44/715:
# Format each grade column.

math_scores_by_grade["9th"] = math_scores_by_grade["9th"].map("{:.1f}".format)

math_scores_by_grade["10th"] = math_scores_by_grade["10th"].map("{:.1f}".format)

math_scores_by_grade["11th"] = math_scores_by_grade["11th"].map("{:.1f}".format)

math_scores_by_grade["12th"] = math_scores_by_grade["12th"].map("{:.1f}".format)
44/716:
# Combine each grade level Series for average reading scores by school into a single DataFrame.
reading_scores_by_grade = pd.DataFrame({
              "9th": ninth_grade_reading_scores,
              "10th": tenth_grade_reading_scores,
              "11th": eleventh_grade_reading_scores,
              "12th": twelfth_grade_reading_scores})

reading_scores_by_grade.head()
44/717:
# Format each grade column.

math_scores_by_grade["9th"] = math_scores_by_grade["9th"].map("{:.1f}".format)

math_scores_by_grade["10th"] = math_scores_by_grade["10th"].map("{:.1f}".format)

math_scores_by_grade["11th"] = math_scores_by_grade["11th"].map("{:.1f}".format)

math_scores_by_grade["12th"] = math_scores_by_grade["12th"].map("{:.1f}".format)
44/718:
# Add the Pandas dependency.
import pandas as pd
44/719:
school_data_to_load = "Resources/schools_complete.csv"
student_data_to_load = "Resources/students_complete.csv"
44/720:
# Read the school data file and store it in a Pandas DataFrame.
school_data_df = pd.read_csv(school_data_to_load)
school_data_df
44/721:
# Read the student data file and store it in a Pandas DataFrame.
student_data_df = pd.read_csv(student_data_to_load)
student_data_df.head()
44/722:
# Determine if there are any missing values in the school data.
school_data_df.count()
44/723:
# Determine if there are any missing values in the student data.
student_data_df.count()
44/724: school_data_df.isnull()
44/725: student_data_df.isnull().sum()
44/726: student_data_df.notnull().sum()
44/727:
#Determin data types for the student DataFrame
school_data_df.dtypes
44/728:
# Determine data types for the student DataFrame.
student_data_df.dtypes
44/729:
# Read the school data file and store it in a Pandas DataFrame.
school_data_df= pd.read_csv(school_data_to_load)
school_data_df
44/730:
# Read the student data file and store it in a Pandas DataFrame.
student_data_df = pd.read_csv(student_data_to_load)
student_data_df.head()
44/731:
# Add each prefix and suffix to remove to a list.
prefixes_suffixes = ["Dr. ", "Mr. ","Ms. ", "Mrs. ", "Miss ", " MD", " DDS", " DVM", " PhD"]
44/732:
# Iterate through the words in the "prefixes_suffixes" list and replace them with an empty space, "".
for word in prefixes_suffixes:
    student_data_df["student_name"]= student_data_df["student_name"].str.replace(word,"",regex =True )
    print(student_data_df.head())
44/733:
# Combine the data into a single dataset.
school_data_complete_df = pd.merge(student_data_df, school_data_df, on=["school_name", "school_name"])
school_data_complete_df.head()
44/734:
#Get the total number of students
#student_count = school_data_complete_df.count()
student_count =school_data_complete_df["Student ID"].count()
student_count
44/735:
#Calculate the total number of schools
school_count=school_data_df["school_name"].count()
school_count
44/736:
# Calculate the total number of schools
school_count_2 = school_data_complete_df["school_name"].unique()
school_count_2
44/737:
#Running the code: 
#len(school_data_complete_df["school_name"].unique())
44/738:
# Calculate the total budget.
total_budget = school_data_df["budget"].sum()
total_budget
44/739:
#Calculate the average reading score
average_reading_score = school_data_complete_df["reading_score"].mean()
average_reading_score
44/740:
# Calculate the average math score.
average_math_score = school_data_complete_df["math_score"].mean()
average_math_score
44/741:
#Determine the passing grade
passing_math = school_data_complete_df["math_score"] >= 70
passing_math.head()
44/742:
passing_reading = school_data_complete_df["reading_score"] >= 70
passing_reading
44/743:
passing_math = school_data_complete_df[school_data_complete_df["math_score"] >= 70]
passing_math.head()
44/744:
# Get all the students that are passing reading in a new DataFrame.
passing_reading = school_data_complete_df[school_data_complete_df["reading_score"] >= 70]
passing_reading.head()
44/745:
# Calculate the number of students passing math.
passing_math_count = passing_math["student_name"].count()
print(passing_math_count)
# Calculate the number of students passing reading.
passing_reading_count = passing_reading["student_name"].count()
print(passing_reading_count)
44/746:
# Calculate the percent that passed math.
passing_math_percentage=passing_math_count / float(student_count) * 100
# Calculate the percent that passed reading.
passing_reading_percentage=passing_reading_count / float(student_count) * 100
print(passing_math_percentage)
print(passing_reading_percentage)
44/747:
# Calculate the students who passed both math and reading.
passing_math_reading = school_data_complete_df[(school_data_complete_df["math_score"] >= 70) & (school_data_complete_df["reading_score"] >= 70)]

passing_math_reading.head()
44/748:
# Calculate the number of students who passed both math and reading.
overall_passing_math_reading_count = passing_math_reading["student_name"].count()
44/749:
# Calculate the overall passing percentage.
overall_passing_percentage = overall_passing_math_reading_count / student_count * 100
overall_passing_percentage
44/750:
# Adding a list of values with keys to create a new DataFrame.
district_summary_df = pd.DataFrame(
          [{"Total Schools": school_count,
          "Total Students": student_count,
          "Total Budget": total_budget,
          "Average Math Score": average_math_score,
          "Average Reading Score": average_reading_score,
          "% Passing Math": passing_math_percentage,
         "% Passing Reading": passing_reading_percentage,
        "% Overall Passing": overall_passing_percentage}])
district_summary_df
44/751:
# Define a function that calculates the percentage of students that passed both 
# math and reading and returns the passing percentage when the function is called.

def passing_math_percent(pass_math_count, student_count):
    return pass_math_count / float(student_count) * 100
44/752:
passing_math_count = 29370
total_student_count = 39170
44/753: passing_math_percent(passing_math_count, total_student_count)
44/754:
# Format the "Total Students" to have the comma for a thousands separator.
district_summary_df["Total Students"] = district_summary_df["Total Students"].map("{:,}".format)

district_summary_df["Total Students"]
44/755:
district_summary_df["Total Budget"] = district_summary_df["Total Budget"].map("${:,.2f}".format)

district_summary_df["Total Budget"]
44/756:
# Format the columns.

district_summary_df["Average Math Score"] = district_summary_df["Average Math Score"].map("{:.1f}".format)

district_summary_df["Average Reading Score"] = district_summary_df["Average Reading Score"].map("{:,.1f}".format)

district_summary_df["% Passing Math"] = district_summary_df["% Passing Math"].map("{:.0f}".format)

district_summary_df["% Passing Reading"] = district_summary_df["% Passing Reading"].map("{:.0f}".format)

district_summary_df["% Overall Passing"] = district_summary_df["% Overall Passing"].map("{:.0f}".format)
44/757:
#Display the DataFrame
district_summary_df
44/758:
# Determine the school type.
per_school_types = school_data_df.set_index(["school_name"])["type"]
per_school_types
44/759:
# Add the per_school_types into a DataFrame for testing.
df = pd.DataFrame(per_school_types)
df
44/760:
# Calculate the total student count.
per_school_counts = school_data_df["size"]
per_school_counts
44/761:
# Calculate the total student count.
per_school_counts = school_data_df.set_index(["school_name"])["size"]
per_school_counts
44/762:
# Calculate the total student count.
per_school_counts = school_data_complete_df["school_name"].value_counts()
per_school_counts
44/763:
# Calculate the total school budget.
per_school_budget = school_data_df.set_index(["school_name"])["budget"]
per_school_budget
44/764:
# Calculate the per capita spending.
per_school_capita = per_school_budget / per_school_counts
per_school_capita
44/765:
# Calculate the math scores.
student_school_math = student_data_df.set_index(["school_name"])["math_score"]
student_school_math
44/766:
# Calculate the average math scores.
per_school_averages = school_data_complete_df.groupby(["school_name"]).mean()
per_school_averages
44/767:
# Calculate the average test scores.
per_school_math = school_data_complete_df.groupby(["school_name"]).mean()["math_score"]

per_school_reading = school_data_complete_df.groupby(["school_name"]).mean()["reading_score"]
44/768:
#Print the average test scores
per_school_math
44/769: per_school_reading
44/770:
# Calculate the passing scores by creating a filtered DataFrame.
per_school_passing_math = school_data_complete_df[(school_data_complete_df["math_score"] >= 70)]

per_school_passing_reading = school_data_complete_df[(school_data_complete_df["reading_score"] >= 70)]
44/771: per_school_passing_math.head()
44/772: per_school_passing_reading.head()
44/773:
# Calculate the number of students passing math and passing reading by school.
per_school_passing_math = per_school_passing_math.groupby(["school_name"]).count()["student_name"]

per_school_passing_reading = per_school_passing_reading.groupby(["school_name"]).count()["student_name"]
44/774: per_school_passing_math
44/775: per_school_passing_reading
44/776:
# Calculate the percentage of passing math and reading scores per school.
per_school_passing_math = per_school_passing_math / per_school_counts * 100

per_school_passing_reading = per_school_passing_reading / per_school_counts * 100
44/777: per_school_passing_math
44/778: per_school_passing_reading
44/779:
# Calculate the students who passed both math and reading.
per_passing_math_reading = school_data_complete_df[(school_data_complete_df["math_score"] >= 70) & (school_data_complete_df["reading_score"] >= 70)]

per_passing_math_reading.head()
44/780:
# Calculate the number of students who passed both math and reading.
per_passing_math_reading = per_passing_math_reading.groupby(["school_name"]).count()["student_name"]
44/781:
# Calculate the overall passing percentage.
per_overall_passing_percentage = per_passing_math_reading / per_school_counts * 100
44/782: per_overall_passing_percentage
44/783:
# Adding a list of values with keys to create a new DataFrame.

per_school_summary_df = pd.DataFrame({
             "School Type": per_school_types,
             "Total Students": per_school_counts,
             "Total School Budget": per_school_budget,
             "Per Student Budget": per_school_capita,
             "Average Math Score": per_school_math,
           "Average Reading Score": per_school_reading,
           "% Passing Math": per_school_passing_math,
           "% Passing Reading": per_school_passing_reading,
           "% Overall Passing": per_overall_passing_percentage})
per_school_summary_df.head()
44/784:
# Format the Total School Budget and the Per Student Budget columns.
per_school_summary_df["Total School Budget"] = per_school_summary_df["Total School Budget"].map("${:,.2f}".format)

per_school_summary_df["Per Student Budget"] = per_school_summary_df["Per Student Budget"].map("${:,.2f}".format)


# Display the data frame
per_school_summary_df.head()
44/785:
# Reorder the columns in the order you want them to appear.
new_column_order = ["School Type", "Total Students", "Total School Budget", "Per Student Budget", "Average Math Score", "Average Reading Score", "% Passing Math", "% Passing Reading", "% Overall Passing"]

# Assign district summary df the new column order.
per_school_summary_df = per_school_summary_df[new_column_order]

per_school_summary_df.head()
44/786:
# Sort and show top five schools.
top_schools = per_school_summary_df.sort_values(["% Overall Passing"], ascending=False)

top_schools.head()
44/787:
# Sort and show top five schools.
bottom_schools = per_school_summary_df.sort_values(["% Overall Passing"], ascending=True)

bottom_schools.head()
44/788:
# Create a grade level DataFrames.
ninth_graders = school_data_complete_df[(school_data_complete_df["grade"] == "9th")]

tenth_graders = school_data_complete_df[(school_data_complete_df["grade"] == "10th")]

eleventh_graders = school_data_complete_df[(school_data_complete_df["grade"] == "11th")]

twelfth_graders = school_data_complete_df[(school_data_complete_df["grade"] == "12th")]
44/789: ninth_graders.head()
44/790: tenth_graders.head()
44/791:
# Group each grade level DataFrame by the school name for the average math score.
ninth_grade_math_scores = ninth_graders.groupby(["school_name"]).mean()["math_score"]

tenth_grade_math_scores = tenth_graders.groupby(["school_name"]).mean()["math_score"]

eleventh_grade_math_scores = eleventh_graders.groupby(["school_name"]).mean()["math_score"]

twelfth_grade_math_scores = twelfth_graders.groupby(["school_name"]).mean()["math_score"]
44/792: ninth_grade_math_scores
44/793: eleventh_grade_math_scores
44/794:
# Group each grade level DataFrame by the school name for the average reading score.
ninth_grade_reading_scores = ninth_graders.groupby(["school_name"]).mean()["reading_score"]

tenth_grade_reading_scores = tenth_graders.groupby(["school_name"]).mean()["reading_score"]

eleventh_grade_reading_scores = eleventh_graders.groupby(["school_name"]).mean()["reading_score"]

twelfth_grade_reading_scores = twelfth_graders.groupby(["school_name"]).mean()["reading_score"]
44/795: ninth_grade_reading_scores
44/796: twelfth_grade_reading_scores
44/797:
# Combine each grade level Series for average math scores by school into a single DataFrame.
math_scores_by_grade = pd.DataFrame({
               "9th": ninth_grade_math_scores,
               "10th": tenth_grade_math_scores,
               "11th": eleventh_grade_math_scores,
               "12th": twelfth_grade_math_scores})

math_scores_by_grade.head()
44/798:
# Combine each grade level Series for average reading scores by school into a single DataFrame.
reading_scores_by_grade = pd.DataFrame({
              "9th": ninth_grade_reading_scores,
              "10th": tenth_grade_reading_scores,
              "11th": eleventh_grade_reading_scores,
              "12th": twelfth_grade_reading_scores})

reading_scores_by_grade.head()
44/799:
# Format each grade column.

math_scores_by_grade["9th"] = math_scores_by_grade["9th"].map("{:.1f}".format)

math_scores_by_grade["10th"] = math_scores_by_grade["10th"].map("{:.1f}".format)

math_scores_by_grade["11th"] = math_scores_by_grade["11th"].map("{:.1f}".format)

math_scores_by_grade["12th"] = math_scores_by_grade["12th"].map("{:.1f}".format)

# Make sure the columns are in the correct order.
math_scores_by_grade = math_scores_by_grade[["9th", "10th", "11th", "12th"]]

# Remove the index name.
math_scores_by_grade.index.name = None
# Display the DataFrame.
math_scores_by_grade.head()
44/800:
# Format each grade column.
reading_scores_by_grade["9th"] = reading_scores_by_grade["9th"].map("{:,.1f}".format)

reading_scores_by_grade["10th"] = reading_scores_by_grade["10th"].map("{:,.1f}".format)

reading_scores_by_grade["11th"] = reading_scores_by_grade["11th"].map("{:,.1f}".format)

reading_scores_by_grade["12th"] = reading_scores_by_grade["12th"].map("{:,.1f}".format)

# Make sure the columns are in the correct order.
reading_scores_by_grade = reading_scores_by_grade[
        ["9th", "10th", "11th", "12th"]]
# Remove the index name.
reading_scores_by_grade.index.name = None
# Display the data frame.
reading_scores_by_grade.head()
44/801:
# Get the descriptive statistics for the per_school_capita.
per_school_capita.describe()
44/802:
# Cut the per_school_capita into the spending ranges.
spending_bins = [0, 585, 615, 645, 675]
pd.cut(per_school_capita, spending_bins)
44/803:
# Cut the per_school_capita into the spending ranges.
spending_bins = [585, 615, 645, 675]
pd.cut(per_school_capita, spending_bins)
44/804:
# Cut the per_school_capita into the spending ranges.
spending_bins = [0, 585, 615, 645, 675]
per_school_capita.groupby(pd.cut(per_school_capita, spending_bins)).count()
44/805:
# Cut the per_school_capita into the spending ranges.
spending_bins = [0, 585, 630, 645, 675]
per_school_capita.groupby(pd.cut(per_school_capita, spending_bins)).count()
44/806:
# Establish the spending bins and group names.
spending_bins = [0, 585, 630, 645, 675]
group_names = ["<$586", "$586-630", "$631-645", "$646-675"]
44/807: group_names
44/808:
# Establish the spending bins and group names.
spending_bins = [0, 585, 630, 645, 675]
group_names = ["<$586", "$586-630", "$631-645", "$646-675"]
47/85:
second_cat = Cat('Fofo')
print(second_cat.name)
44/809:
# Establish the spending bins and group names.
spending_bins = [0, 585, 630, 645, 675]
group_names = ["<$586", "$586-630", "$631-645", "$646-675"]
44/810: group_names
44/811:
spending_bins
group_names
44/812:
# Establish the spending bins and group names.
spending_bins = [0, 585, 630, 645, 675]
group_names = ["<$586", "$586-630", "$631-645", "$646-675"]
44/813:
# Categorize spending based on the bins.
per_school_summary_df["Spending Ranges (Per Student)"] = pd.cut(per_school_capita, spending_bins, labels=group_names)

per_school_summary_df
44/814:
# Calculate averages for the desired columns.
spending_math_scores = per_school_summary_df.groupby(["Spending Ranges (Per Student)"]).mean()["Average Math Score"]

spending_reading_scores = per_school_summary_df.groupby(["Spending Ranges (Per Student)"]).mean()["Average Reading Score"]

spending_passing_math = per_school_summary_df.groupby(["Spending Ranges (Per Student)"]).mean()["% Passing Math"]

spending_passing_reading = per_school_summary_df.groupby(["Spending Ranges (Per Student)"]).mean()["% Passing Reading"]

overall_passing_spending = per_school_summary_df.groupby(["Spending Ranges (Per Student)"]).mean()["% Overall Passing"]
44/815: overall_passing_spending
44/816: df = pd.DataFrame({"column name": column values})
44/817:
# Assemble into DataFrame.
spending_summary_df = pd.DataFrame({
          "Average Math Score" : spending_math_scores,
          "Average Reading Score": spending_reading_scores,
          "% Passing Math": spending_passing_math,
          "% Passing Reading": spending_passing_reading,
          "% Overall Passing": overall_passing_spending})

spending_summary_df
44/818:
# Formatting
spending_summary_df["Average Math Score"] = spending_summary_df["Average Math Score"].map("{:.1f}".format)

spending_summary_df["Average Reading Score"] = spending_summary_df["Average Reading Score"].map("{:.1f}".format)

spending_summary_df["% Passing Math"] = spending_summary_df["% Passing Math"].map("{:.0f}".format)

spending_summary_df["% Passing Reading"] = spending_summary_df["% Passing Reading"].map("{:.0f}".format)

spending_summary_df["% Overall Passing"] = spending_summary_df["% Overall Passing"].map("{:.0f}".format)

spending_summary_df
44/819:
# Establish the bins.
size_bins = [0, 999, 1999, 5000]
group_names = ["Small (<1000)", "Medium (1000-1999)", "Large (2000-5000)"]
44/820:
# Categorize spending based on the bins.
per_school_summary_df["School Size"] = pd.cut(per_school_summary_df["Total Students"], size_bins, labels=group_names)

per_school_summary_df.head()
44/821:
# Calculate averages for the desired columns.
size_math_scores = per_school_summary_df.groupby(["School Size"]).mean()["Average Math Score"]

size_reading_scores = per_school_summary_df.groupby(["School Size"]).mean()["Average Reading Score"]

size_passing_math = per_school_summary_df.groupby(["School Size"]).mean()["% Passing Math"]

size_passing_reading = per_school_summary_df.groupby(["School Size"]).mean()["% Passing Reading"]

size_overall_passing = per_school_summary_df.groupby(["School Size"]).mean()["% Overall Passing"]
44/822: size_math_scores
44/823:
# Assemble into DataFrame.
size_summary_df = pd.DataFrame({
          "Average Math Score" : size_math_scores,
          "Average Reading Score": size_reading_scores,
          "% Passing Math": size_passing_math,
          "% Passing Reading": size_passing_reading,
          "% Overall Passing": size_overall_passing})

size_summary_df
44/824:
# Formatting.
size_summary_df["Average Math Score"] = size_summary_df["Average Math Score"].map("{:.1f}".format)

size_summary_df["Average Reading Score"] = size_summary_df["Average Reading Score"].map("{:.1f}".format)

size_summary_df["% Passing Math"] = size_summary_df["% Passing Math"].map("{:.0f}".format)

size_summary_df["% Passing Reading"] = size_summary_df["% Passing Reading"].map("{:.0f}".format)

size_summary_df["% Overall Passing"] = size_summary_df["% Overall Passing"].map("{:.0f}".format)

size_summary_df
44/825:
# Calculate averages for the desired columns.
type_math_scores = per_school_summary_df.groupby(["School Type"]).mean()["Average Math Score"]

type_reading_scores = per_school_summary_df.groupby(["School Type"]).mean()["Average Reading Score"]

type_passing_math = per_school_summary_df.groupby(["School Type"]).mean()["% Passing Math"]

type_passing_reading = per_school_summary_df.groupby(["School Type"]).mean()["% Passing Reading"]

type_overall_passing = per_school_summary_df.groupby(["School Type"]).mean()["% Overall Passing"]
44/826:
# Assemble into DataFrame.
type_summary_df = pd.DataFrame({
          "Average Math Score" : type_math_scores,
          "Average Reading Score": type_reading_scores,
          "% Passing Math": type_passing_math,
          "% Passing Reading": type_passing_reading,
          "% Overall Passing": type_overall_passing})

type_summary_df
44/827:
# Formatting
type_summary_df["Average Math Score"] = type_summary_df["Average Math Score"].map("{:.1f}".format)

type_summary_df["Average Reading Score"] = type_summary_df["Average Reading Score"].map("{:.1f}".format)

type_summary_df["% Passing Math"] = type_summary_df["% Passing Math"].map("{:.0f}".format)

type_summary_df["% Passing Reading"] = type_summary_df["% Passing Reading"].map("{:.0f}".format)

type_summary_df["% Overall Passing"] = type_summary_df["% Overall Passing"].map("{:.0f}".format)

type_summary_df
49/1:
# Install numpy using conda install numpy or pip install numpy. 
# Step 1. Import numpy as np.
import numpy as np
49/2:
# Step 2. Use the loc method on the student_data_df to select all the reading scores from the 9th grade at Thomas High School and replace them with NaN.
student_data_df.loc[(student_data_df["school_name"] == "Thomas High School") & (student_data_df["grade"] == "9th"), "reading_score"] = np.nan
49/3:
# Step 2. Use the loc method on the student_data_df to select all the reading scores from the 9th grade at Thomas High School and replace them with NaN.
student_data_df.loc[(student_data_df["school_name"] == "Thomas High School") & (student_data_df["grade"] == "9th"), "reading_score"] = np.nan]
49/4:
# Install numpy using conda install numpy or pip install numpy. 
# Step 1. Import numpy as np.
import numpy as np
49/5:
# Step 2. Use the loc method on the student_data_df to select all the reading scores from the 9th grade at Thomas High School and replace them with NaN.
student_data_df.loc[(student_data_df["school_name"] == "Thomas High School") & (student_data_df["grade"] == "9th"), "reading_score"] = np.nan]
49/6:
# Dependencies and Setup
import pandas as pd

# File to Load (Remember to change the path if needed.)
school_data_to_load = "Resources/schools_complete.csv"
student_data_to_load = "Resources/students_complete.csv"

# Read the School Data and Student Data and store into a Pandas DataFrame
school_data_df = pd.read_csv(school_data_to_load)
student_data_df = pd.read_csv(student_data_to_load)

# Cleaning Student Names and Replacing Substrings in a Python String
# Add each prefix and suffix to remove to a list.
prefixes_suffixes = ["Dr. ", "Mr. ","Ms. ", "Mrs. ", "Miss ", " MD", " DDS", " DVM", " PhD"]

# Iterate through the words in the "prefixes_suffixes" list and replace them with an empty space, "".
for word in prefixes_suffixes:
    student_data_df["student_name"] = student_data_df["student_name"].str.replace(word,"")

# Check names.
student_data_df.head(10)
49/7:
# Install numpy using conda install numpy or pip install numpy. 
# Step 1. Import numpy as np.
import numpy as np
49/8:
# Step 2. Use the loc method on the student_data_df to select all the reading scores from the 9th grade at Thomas High School and replace them with NaN.
student_data_df.loc[(student_data_df["school_name"] == "Thomas High School") & (student_data_df["grade"] == "9th"), "reading_score"] = np.nan]
49/9:
# Step 2. Use the loc method on the student_data_df to select all the reading scores from the 9th grade at Thomas High School and replace them with NaN.
student_data_df.loc[(student_data_df["school_name"] == "Thomas High School") & (student_data_df["grade"] == "9th"), "reading_score"] = np.nan
49/10:
#  Step 3. Refactor the code in Step 2 to replace the math scores with NaN.
student_data_df.loc[(student_data_df["school_name"] == "Thomas High School") & (student_data_df["grade"] == "9th"), "reading_score"] = np.nan
49/11:
# Step 2. Use the loc method on the student_data_df to select all the reading scores from the 9th grade at Thomas High School and replace them with NaN.
student_data_df.loc[(student_data_df["school_name"] == "Thomas High School") & (student_data_df["grade"] == "9th"), "reading_score"] = np.nan
49/12:
#  Step 3. Refactor the code in Step 2 to replace the math scores with NaN.
student_data_df.loc[(student_data_df["school_name"] == "Thomas High School") & (student_data_df["grade"] == "9th"), "reading_score"] = np.nan
49/13:
#  Step 4. Check the student data for NaN's. 

student_data_df.tail(10)
49/14:
#  Step 3. Refactor the code in Step 2 to replace the math scores with NaN.
student_data_df.loc[(student_data_df["school_name"] == "Thomas High School") & (student_data_df["grade"] == "9th"), "math_score"] = np.nan
49/15:
#  Step 4. Check the student data for NaN's. 

student_data_df.tail(10)
49/16:
# Step 1. Get the number of students that are in ninth grade at Thomas High School.
# These students have no grades. 

ninth_grades_student_count = student_data_df.loc[(student_data_df["school_name"] == "Thomas High School") & (student_data_df["grade"] == "9th").count


# Get the total student count 
student_count = school_data_complete_df["Student ID"].count()


# Step 2. Subtract the number of students that are in ninth grade at 
# Thomas High School from the total student count to get the new total student count.
 new_total_student_count = student_count - new_total_student_count
49/17:
# Calculate the Average Scores using the "clean_student_data".
average_reading_score = school_data_complete_df["reading_score"].mean()
average_math_score = school_data_complete_df["math_score"].mean()
49/18:
# Calculate the Totals (Schools and Students)
school_count = len(school_data_complete_df["school_name"].unique())
student_count = school_data_complete_df["Student ID"].count()

# Calculate the Total Budget
total_budget = school_data_df["budget"].sum()
49/19:
# Combine the data into a single dataset
school_data_complete_df = pd.merge(student_data_df, school_data_df, how="left", on=["school_name", "school_name"])
school_data_complete_df.head()
49/20:
# Calculate the Totals (Schools and Students)
school_count = len(school_data_complete_df["school_name"].unique())
student_count = school_data_complete_df["Student ID"].count()

# Calculate the Total Budget
total_budget = school_data_df["budget"].sum()
49/21:
# Calculate the Average Scores using the "clean_student_data".
average_reading_score = school_data_complete_df["reading_score"].mean()
average_math_score = school_data_complete_df["math_score"].mean()
49/22:
# Step 1. Get the number of students that are in ninth grade at Thomas High School.
# These students have no grades. 

ninth_grades_student_count = student_data_df.loc[(student_data_df["school_name"] == "Thomas High School") & (student_data_df["grade"] == "9th")].count


# Get the total student count 
student_count = school_data_complete_df["Student ID"].count()


# Step 2. Subtract the number of students that are in ninth grade at 
# Thomas High School from the total student count to get the new total student count.
new_total_student_count = (student_count - new_total_student_count)
49/23:
# Step 1. Get the number of students that are in ninth grade at Thomas High School.
# These students have no grades. 

ninth_grades_student_count = student_data_df.loc[(student_data_df["school_name"] == "Thomas High School") & (student_data_df["grade"] == "9th")].count()


# Get the total student count 
student_count = school_data_complete_df["Student ID"].count()


# Step 2. Subtract the number of students that are in ninth grade at 
# Thomas High School from the total student count to get the new total student count.
new_total_student_count = (student_count - new_total_student_count)
49/24:
# Calculate the Average Scores using the "clean_student_data".
average_reading_score = school_data_complete_df["reading_score"].mean()
average_math_score = school_data_complete_df["math_score"].mean()
49/25:
# Step 1. Get the number of students that are in ninth grade at Thomas High School.
# These students have no grades. 

ninth_grades_student_count = student_data_df.loc[(student_data_df["school_name"] == "Thomas High School") & (student_data_df["grade"] == "9th")].count()


# Get the total student count 
student_count = school_data_complete_df["Student ID"].count()


# Step 2. Subtract the number of students that are in ninth grade at 
# Thomas High School from the total student count to get the new total student count.
new_total_student_count = (student_count - new_total_student_count)
49/26:
# Step 1. Get the number of students that are in ninth grade at Thomas High School.
# These students have no grades. 

ninth_grades_student_count = student_data_df.loc[(student_data_df["school_name"] == "Thomas High School") & (student_data_df["grade"] == "9th")].count()


# Get the total student count 
student_count = school_data_complete_df["Student ID"].count()


# Step 2. Subtract the number of students that are in ninth grade at 
# Thomas High School from the total student count to get the new total student count.
new_total_student_count = (student_count - ninth_grades_student_count)
49/27:
# Step 1. Get the number of students that are in ninth grade at Thomas High School.
# These students have no grades. 

ninth_grades_student_count = student_data_df.loc[(student_data_df["school_name"] == "Thomas High School") & (student_data_df["grade"] == "9th")].count()


# Get the total student count 
student_count = school_data_complete_df["Student ID"].count()


# Step 2. Subtract the number of students that are in ninth grade at 
# Thomas High School from the total student count to get the new total student count.
new_total_student_count = (student_count - ninth_grades_student_count)
49/28:
# Step 3. Calculate the passing percentages with the new total student count.
passing_math_percentage = passing_math_count/new_total_student_count*100
49/29:
# Calculate the passing rates using the "clean_student_data".
passing_math_count = school_data_complete_df[(school_data_complete_df["math_score"] >= 70)].count()["student_name"]
passing_reading_count = school_data_complete_df[(school_data_complete_df["reading_score"] >= 70)].count()["student_name"]
49/30:
# Step 3. Calculate the passing percentages with the new total student count.
passing_math_percentage = passing_math_count/new_total_student_count*100
49/31: passing_math_percentage
49/32: passing_math_percentage
49/33:
# Calculate the students who passed both reading and math.
passing_math_reading = school_data_complete_df[(school_data_complete_df["math_score"] >= 70)
                                               & (school_data_complete_df["reading_score"] >= 70)]

# Calculate the number of students that passed both reading and math.
overall_passing_math_reading_count = passing_math_reading["student_name"].count()


# Step 4.Calculate the overall passing percentage with new total student count.
overall_passing_percentage= overall_passing_math_reading_count/new_total_student_count*100
49/34:
# Calculate the students who passed both reading and math.
passing_math_reading = school_data_complete_df[(school_data_complete_df["math_score"] >= 70)
                                               & (school_data_complete_df["reading_score"] >= 70)]

# Calculate the number of students that passed both reading and math.
overall_passing_math_reading_count = passing_math_reading["student_name"].count()


# Step 4.Calculate the overall passing percentage with new total student count.
overall_passing_percentage= overall_passing_math_reading_count/new_total_student_count*100
overall_passing_percentage
49/35:
# Step 5.  Get the number of 10th-12th graders from Thomas High School (THS).
tenth_grades_student_count = student_data_df.loc[(student_data_df["school_name"] == "Thomas High School") & (student_data_df["grade"] == "10th")].count()
49/36:
# Step 5.  Get the number of 10th-12th graders from Thomas High School (THS).
tenth_grades_student_count = student_data_df.loc[(student_data_df["school_name"] == "Thomas High School") & (student_data_df["grade"] == "10th")].count()
tenth_grades_student_count
49/37:
# Step 5.  Get the number of 10th-12th graders from Thomas High School (THS).
tenth_grades_student_count = student_data_df.loc[(student_data_df["school_name"] == "Thomas High School") & (student_data_df["grade"] == "10th")].count() ["Student_id"]
tenth_grades_student_count
49/38:
# Step 5.  Get the number of 10th-12th graders from Thomas High School (THS).
tenth_grades_student_count = student_data_df.loc[(student_data_df["school_name"] == "Thomas High School") & (student_data_df["grade"] == "10th")].count()["Student_id"]
tenth_grades_student_count
49/39:
# Format the Total School Budget and the Per Student Budget
per_school_summary_df["Total School Budget"] = per_school_summary_df["Total School Budget"].map("${:,.2f}".format)
per_school_summary_df["Per Student Budget"] = per_school_summary_df["Per Student Budget"].map("${:,.2f}".format)

# Display the data frame
per_school_summary_df
49/40:
# Step 5.  Get the number of 10th-12th graders from Thomas High School (THS).
tenth_grades_student_count = student_data_df.loc[(student_data_df["school_name"] == "Thomas High School") & (student_data_df["grade"] == "10th")].count()["Student_id"]
tenth_grades_student_count
49/41:
# Step 5.  Get the number of 10th-12th graders from Thomas High School (THS).
tenth_grades_student_count = student_data_df.loc[(student_data_df["school_name"] == "Thomas High School") & (student_data_df["grade"] == "10th")].count()
tenth_grades_student_count
49/42:
# Step 5.  Get the number of 10th-12th graders from Thomas High School (THS).
tenth_grades_student_count = student_data_df.loc[(student_data_df["school_name"] == "Thomas High School") & (student_data_df["grade"] == "10th")]["Student_id"].count()
tenth_grades_student_count
49/43:
# Step 5.  Get the number of 10th-12th graders from Thomas High School (THS).
tenth_grades_student_count = student_data_df.loc[(student_data_df["school_name"] == "Thomas High School") & (student_data_df["grade"] == "10th") "Student_id".]count()
tenth_grades_student_count
49/44:
# Step 5.  Get the number of 10th-12th graders from Thomas High School (THS).
tenth_grades_student_count = student_data_df.loc[(student_data_df["school_name"] == "Thomas High School") & (student_data_df["grade"] == "10th")].count() ["Student_id"].
tenth_grades_student_count
49/45:
# Step 5.  Get the number of 10th-12th graders from Thomas High School (THS).

tenth_grades_student_count = student_data_df.loc[(student_data_df["school_name"] == "Thomas High School") & (student_data_df["grade"] == "10th")].count() ["Student_id"].
#er_school_passing_math = per_school_passing_math.groupby(["school_name"]).count()["student_name"]
tenth_grades_student_count
49/46:
# Format the Total School Budget and the Per Student Budget
per_school_summary_df["Total School Budget"] = per_school_summary_df["Total School Budget"].map("${:,.2f}".format)
per_school_summary_df["Per Student Budget"] = per_school_summary_df["Per Student Budget"].map("${:,.2f}".format)

# Display the data frame
per_school_summary_df
49/47:
# Create the DataFrame
per_school_summary_df = pd.DataFrame({
    "School Type": per_school_types,
    "Total Students": per_school_counts,
    "Total School Budget": per_school_budget,
    "Per Student Budget": per_school_capita,
    "Average Math Score": per_school_math,
    "Average Reading Score": per_school_reading,
    "% Passing Math": per_school_passing_math,
    "% Passing Reading": per_school_passing_reading,
    "% Overall Passing": per_overall_passing_percentage})


# per_school_summary_df.head()
49/48:
# Format the Total School Budget and the Per Student Budget
per_school_summary_df["Total School Budget"] = per_school_summary_df["Total School Budget"].map("${:,.2f}".format)
per_school_summary_df["Per Student Budget"] = per_school_summary_df["Per Student Budget"].map("${:,.2f}".format)

# Display the data frame
per_school_summary_df
49/49:
# Step 5.  Get the number of 10th-12th graders from Thomas High School (THS).

tenth_grades_student_count = student_data_df.loc[(student_data_df["school_name"] == "Thomas High School") & (student_data_df["grade"] == "10th")].count() ["Student_id"]
#er_school_passing_math = per_school_passing_math.groupby(["school_name"]).count()["student_name"]
tenth_grades_student_count
49/50: # Step 6. Get all the students passing math from THS
49/51:
# Step 5.  Get the number of 10th-12th graders from Thomas High School (THS).

tenth_grades_student_count = student_data_df.loc[(student_data_df["school_name"] == "Thomas High School") & (student_data_df["grade"] == "10th")].count() ["Student_ID"]
#er_school_passing_math = per_school_passing_math.groupby(["school_name"]).count()["student_name"]
tenth_grades_student_count
49/52:
# Step 5.  Get the number of 10th-12th graders from Thomas High School (THS).

tenth_grades_student_count = student_data_df.loc[(student_data_df["school_name"] == "Thomas High School") & (student_data_df["grade"] == "10th")].count() ["Student_Budget"]
#er_school_passing_math = per_school_passing_math.groupby(["school_name"]).count()["student_name"]
tenth_grades_student_count
49/53:
# Step 5.  Get the number of 10th-12th graders from Thomas High School (THS).

tenth_grades_student_count = student_data_df.loc[(student_data_df["school_name"] == "Thomas High School") & (student_data_df["grade"] == "10th")].count() 
#er_school_passing_math = per_school_passing_math.groupby(["school_name"]).count()["student_name"]
tenth_grades_student_count
49/54:
# Step 5.  Get the number of 10th-12th graders from Thomas High School (THS).

tenth_grades_student_count = student_data_df.loc[(student_data_df["school_name"] == "Thomas High School") & (student_data_df["grade"] == "10th")].count()["Student ID"]
#er_school_passing_math = per_school_passing_math.groupby(["school_name"]).count()["student_name"]
tenth_grades_student_count
49/55:
# Step 5.  Get the number of 10th-12th graders from Thomas High School (THS).

tenth_grades_student_count = student_data_df.loc[(student_data_df["school_name"] == "Thomas High School") & (student_data_df["grade"] == "10th")].count()["Student ID"]
twelveth_grade_student_count =  student_data_df.loc[(student_data_df["school_name"] == "Thomas High School") & (student_data_df["grade"] == "12th")].count()["Student ID"]
49/56:
# Format the Total School Budget and the Per Student Budget
per_school_summary_df["Total School Budget"] = per_school_summary_df["Total School Budget"].map("${:,.2f}".format)
per_school_summary_df["Per Student Budget"] = per_school_summary_df["Per Student Budget"].map("${:,.2f}".format)

# Display the data frame
per_school_summary_df
49/57:
# Step 5.  Get the number of 10th-12th graders from Thomas High School (THS).

tenth_grades_student_count = student_data_df.loc[(student_data_df["school_name"] == "Thomas High School") & (student_data_df["grade"] == "10th")].count()["Student ID"]
twelveth_grade_student_count =  student_data_df.loc[(student_data_df["school_name"] == "Thomas High School") & (student_data_df["grade"] == "12th")].count()["Student ID"]
eleventh_grade_student_count =  student_data_df.loc[(student_data_df["school_name"] == "Thomas High School") & (student_data_df["grade"] == "11th")].count()["Student ID"]
total_number_10th-12th_graders= tenth_grades_student_count + twelveth_grade_student_count + eleventh_grade_student_count
total_number_10th-12th_graders
49/58:
# Step 5.  Get the number of 10th-12th graders from Thomas High School (THS).

tenth_grades_student_count = student_data_df.loc[(student_data_df["school_name"] == "Thomas High School") & (student_data_df["grade"] == "10th")].count()["Student ID"]
twelveth_grade_student_count =  student_data_df.loc[(student_data_df["school_name"] == "Thomas High School") & (student_data_df["grade"] == "12th")].count()["Student ID"]
eleventh_grade_student_count =  student_data_df.loc[(student_data_df["school_name"] == "Thomas High School") & (student_data_df["grade"] == "11th")].count()["Student ID"]
total_number_10th-12th_graders= (tenth_grades_student_count + twelveth_grade_student_count + eleventh_grade_student_count)
total_number_10th-12th_graders
49/59:
# Step 5.  Get the number of 10th-12th graders from Thomas High School (THS).

tenth_grades_student_count = student_data_df.loc[(student_data_df["school_name"] == "Thomas High School") & (student_data_df["grade"] == "10th")].count()["Student ID"]
twelveth_grade_student_count =  student_data_df.loc[(student_data_df["school_name"] == "Thomas High School") & (student_data_df["grade"] == "12th")].count()["Student ID"]
eleventh_grade_student_count =  student_data_df.loc[(student_data_df["school_name"] == "Thomas High School") & (student_data_df["grade"] == "11th")].count()["Student ID"]
total_number_10th12th_graders= tenth_grades_student_count + twelveth_grade_student_count + eleventh_grade_student_count
total_number_10th12th_graders
49/60:
# Dependencies and Setup
import pandas as pd

# File to Load (Remember to change the path if needed.)
school_data_to_load = "Resources/schools_complete.csv"
student_data_to_load = "Resources/students_complete.csv"

# Read the School Data and Student Data and store into a Pandas DataFrame
school_data_df = pd.read_csv(school_data_to_load)
student_data_df = pd.read_csv(student_data_to_load)

# Cleaning Student Names and Replacing Substrings in a Python String
# Add each prefix and suffix to remove to a list.
prefixes_suffixes = ["Dr. ", "Mr. ","Ms. ", "Mrs. ", "Miss ", " MD", " DDS", " DVM", " PhD"]

# Iterate through the words in the "prefixes_suffixes" list and replace them with an empty space, "".
for word in prefixes_suffixes:
    student_data_df["student_name"] = student_data_df["student_name"].str.replace(word,"")

# Check names.
student_data_df.head(10)
49/61:
# Install numpy using conda install numpy or pip install numpy. 
# Step 1. Import numpy as np.
import numpy as np
49/62:
# Step 2. Use the loc method on the student_data_df to select all the reading scores from the 9th grade at Thomas High School and replace them with NaN.
student_data_df.loc[(student_data_df["school_name"] == "Thomas High School") & (student_data_df["grade"] == "9th"), "reading_score"] = np.nan
49/63:
#  Step 3. Refactor the code in Step 2 to replace the math scores with NaN.
student_data_df.loc[(student_data_df["school_name"] == "Thomas High School") & (student_data_df["grade"] == "9th"), "math_score"] = np.nan
49/64:
# Create the DataFrame
per_school_summary_df = pd.DataFrame({
    "School Type": per_school_types,
    "Total Students": per_school_counts,
    "Total School Budget": per_school_budget,
    "Per Student Budget": per_school_capita,
    "Average Math Score": per_school_math,
    "Average Reading Score": per_school_reading,
    "% Passing Math": per_school_passing_math,
    "% Passing Reading": per_school_passing_reading,
    "% Overall Passing": per_overall_passing_percentage})


# per_school_summary_df.head()
49/65:
# Step 3. Calculate the passing percentages with the new total student count.
passing_math_percentage = passing_math_count/new_total_student_count*100
49/66: passing_math_percentage
49/67:
# Step 3. Calculate the passing percentages with the new total student count.
passing_math_percentage = passing_math_count/float(new_total_student_count) *100
49/68: passing_math_percentage
49/69:
# Calculate the passing rates using the "clean_student_data".
passing_math_count = school_data_complete_df[(school_data_complete_df["math_score"] >= 70)].count()["student_name"]
passing_reading_count = school_data_complete_df[(school_data_complete_df["reading_score"] >= 70)].count()["student_name"]
49/70:
# Step 3. Calculate the passing percentages with the new total student count.
passing_math_percentage = passing_math_count/float(new_total_student_count) *100
49/71: passing_math_percentage
49/72:
# Step 3. Calculate the passing percentages with the new total student count.
passing_math_percentage = passing_math_count/ float(new_total_student_count) *100
49/73: passing_math_percentage
49/74:
# Step 3. Calculate the passing percentages with the new total student count.
passing_math_percentage = passing_math_count/new_total_student_count*100
49/75:
# Step 3. Calculate the passing percentages with the new total student count.
passing_math_percentage = passing_math_count/ float(new_total_student_count*100)
49/76:
# Step 3. Calculate the passing percentages with the new total student count.
passing_math_percentage = passing_math_count/ float(new_total_student_count)*100
49/77:
# Calculate the passing rates using the "clean_student_data".
passing_math_count = school_data_complete_df[(school_data_complete_df["math_score"] >= 70)].count()["student_name"]
passing_reading_count = school_data_complete_df[(school_data_complete_df["reading_score"] >= 70)].count()["student_name"]
49/78:
# Step 3. Calculate the passing percentages with the new total student count.
passing_math_percentage = passing_math_count/ float(new_total_student_count)*100
49/79: passing_math_percentage
49/80:
# Step 3. Calculate the passing percentages with the new total student count.
passing_math_percentage = passing_math_count/ float(new_total_student_count) *100
49/81:
# Step 1. Get the number of students that are in ninth grade at Thomas High School.
# These students have no grades. 

ninth_grades_student_count = student_data_df.loc[(student_data_df["school_name"] == "Thomas High School") & (student_data_df["grade"] == "9th")].count()


# Get the total student count 
student_count = school_data_complete_df["Student ID"].count()


# Step 2. Subtract the number of students that are in ninth grade at 
# Thomas High School from the total student count to get the new total student count.
new_total_student_count = (student_count - ninth_grades_student_count)
49/82:
# Calculate the passing rates using the "clean_student_data".
passing_math_count = school_data_complete_df[(school_data_complete_df["math_score"] >= 70)].count()["student_name"]
passing_reading_count = school_data_complete_df[(school_data_complete_df["reading_score"] >= 70)].count()["student_name"]
49/83:
# Step 3. Calculate the passing percentages with the new total student count.
passing_math_percentage = passing_math_count/ float(new_total_student_count) *100
49/84:
# Calculate the Totals (Schools and Students)
school_count = len(school_data_complete_df["school_name"].unique())
student_count = school_data_complete_df["Student ID"].count()

# Calculate the Total Budget
total_budget = school_data_df["budget"].sum()
49/85:
# Calculate the Average Scores using the "clean_student_data".
average_reading_score = school_data_complete_df["reading_score"].mean()
average_math_score = school_data_complete_df["math_score"].mean()
49/86:
# Step 1. Get the number of students that are in ninth grade at Thomas High School.
# These students have no grades. 

ninth_grades_student_count = student_data_df.loc[(student_data_df["school_name"] == "Thomas High School") & (student_data_df["grade"] == "9th")].count()


# Get the total student count 
student_count = school_data_complete_df["Student ID"].count()


# Step 2. Subtract the number of students that are in ninth grade at 
# Thomas High School from the total student count to get the new total student count.
new_total_student_count = (student_count - ninth_grades_student_count)
49/87:
# Calculate the passing rates using the "clean_student_data".
passing_math_count = school_data_complete_df[(school_data_complete_df["math_score"] >= 70)].count()["student_name"]
passing_reading_count = school_data_complete_df[(school_data_complete_df["reading_score"] >= 70)].count()["student_name"]
49/88:
# Step 3. Calculate the passing percentages with the new total student count.
passing_math_percentage = passing_math_count / float(new_total_student_count) *100
49/89:
# Create the DataFrame
per_school_summary_df = pd.DataFrame({
    "School Type": per_school_types,
    "Total Students": per_school_counts,
    "Total School Budget": per_school_budget,
    "Per Student Budget": per_school_capita,
    "Average Math Score": per_school_math,
    "Average Reading Score": per_school_reading,
    "% Passing Math": per_school_passing_math,
    "% Passing Reading": per_school_passing_reading,
    "% Overall Passing": per_overall_passing_percentage})


# per_school_summary_df.head()
49/90:
# Step 3. Calculate the passing percentages with the new total student count.
passing_math_percentage = passing_math_count/float(new_total_student_count) *100
49/91:
# Calculate the passing rates using the "clean_student_data".
passing_math_count = school_data_complete_df[(school_data_complete_df["math_score"] >= 70)].count()["student_name"]
passing_reading_count = school_data_complete_df[(school_data_complete_df["reading_score"] >= 70)].count()["student_name"]
49/92:
# Step 3. Calculate the passing percentages with the new total student count.
passing_math_percentage = passing_math_count/float(new_total_student_count) *100
49/93:
# Dependencies and Setup
import pandas as pd

# File to Load (Remember to change the path if needed.)
school_data_to_load = "Resources/schools_complete.csv"
student_data_to_load = "Resources/students_complete.csv"

# Read the School Data and Student Data and store into a Pandas DataFrame
school_data_df = pd.read_csv(school_data_to_load)
student_data_df = pd.read_csv(student_data_to_load)

# Cleaning Student Names and Replacing Substrings in a Python String
# Add each prefix and suffix to remove to a list.
prefixes_suffixes = ["Dr. ", "Mr. ","Ms. ", "Mrs. ", "Miss ", " MD", " DDS", " DVM", " PhD"]

# Iterate through the words in the "prefixes_suffixes" list and replace them with an empty space, "".
for word in prefixes_suffixes:
    student_data_df["student_name"] = student_data_df["student_name"].str.replace(word,"")

# Check names.
student_data_df.head(10)
49/94:
# Install numpy using conda install numpy or pip install numpy. 
# Step 1. Import numpy as np.
import numpy as np
49/95:
# Step 2. Use the loc method on the student_data_df to select all the reading scores from the 9th grade at Thomas High School and replace them with NaN.
student_data_df.loc[(student_data_df["school_name"] == "Thomas High School") & (student_data_df["grade"] == "9th"), "reading_score"] = np.nan
49/96:
#  Step 3. Refactor the code in Step 2 to replace the math scores with NaN.
student_data_df.loc[(student_data_df["school_name"] == "Thomas High School") & (student_data_df["grade"] == "9th"), "math_score"] = np.nan
49/97:
#  Step 4. Check the student data for NaN's. 

student_data_df.tail(10)
49/98:
# Combine the data into a single dataset
school_data_complete_df = pd.merge(student_data_df, school_data_df, how="left", on=["school_name", "school_name"])
school_data_complete_df.head()
49/99:
# Calculate the Totals (Schools and Students)
school_count = len(school_data_complete_df["school_name"].unique())
student_count = school_data_complete_df["Student ID"].count()

# Calculate the Total Budget
total_budget = school_data_df["budget"].sum()
49/100:
# Calculate the Average Scores using the "clean_student_data".
average_reading_score = school_data_complete_df["reading_score"].mean()
average_math_score = school_data_complete_df["math_score"].mean()
49/101:
# Step 1. Get the number of students that are in ninth grade at Thomas High School.
# These students have no grades. 

ninth_grades_student_count = student_data_df.loc[(student_data_df["school_name"] == "Thomas High School") & (student_data_df["grade"] == "9th")].count()


# Get the total student count 
student_count = school_data_complete_df["Student ID"].count()


# Step 2. Subtract the number of students that are in ninth grade at 
# Thomas High School from the total student count to get the new total student count.
new_total_student_count = (student_count - ninth_grades_student_count)
49/102:
# Calculate the passing rates using the "clean_student_data".
passing_math_count = school_data_complete_df[(school_data_complete_df["math_score"] >= 70)].count()["student_name"]
passing_reading_count = school_data_complete_df[(school_data_complete_df["reading_score"] >= 70)].count()["student_name"]
49/103:
# Step 3. Calculate the passing percentages with the new total student count.
passing_math_percentage = passing_math_count/float(new_total_student_count) *100
49/104:
# Step 1. Get the number of students that are in ninth grade at Thomas High School.
# These students have no grades. 

ninth_grades_student_count = len(student_data_df.loc[(student_data_df["school_name"] == "Thomas High School") & (student_data_df["grade"] == "9th")])


# Get the total student count 
student_count = school_data_complete_df["Student ID"].count()


# Step 2. Subtract the number of students that are in ninth grade at 
# Thomas High School from the total student count to get the new total student count.
new_total_student_count = (student_count - ninth_grades_student_count)
49/105:
# Calculate the passing rates using the "clean_student_data".
passing_math_count = school_data_complete_df[(school_data_complete_df["math_score"] >= 70)].count()["student_name"]
passing_reading_count = school_data_complete_df[(school_data_complete_df["reading_score"] >= 70)].count()["student_name"]
49/106:
# Step 3. Calculate the passing percentages with the new total student count.
passing_math_percentage = passing_math_count/float(new_total_student_count) *100
49/107:
# Step 3. Calculate the passing percentages with the new total student count.
passing_math_percentage = passing_math_count/float(new_total_student_count) *100
49/108:
# Step 3. Calculate the passing percentages with the new total student count.
passing_math_percentage = passing_math_count/float(new_total_student_count) *100
passing_reading_percentage = passing_reading_count/float(new_total_student_count) *100
49/109:
# Calculate the students who passed both reading and math.
passing_math_reading = school_data_complete_df[(school_data_complete_df["math_score"] >= 70)
                                               & (school_data_complete_df["reading_score"] >= 70)]

# Calculate the number of students that passed both reading and math.
overall_passing_math_reading_count = passing_math_reading["student_name"].count()


# Step 4.Calculate the overall passing percentage with new total student count.
overall_passing_percentage= overall_passing_math_reading_count/new_total_student_count*100
overall_passing_percentage
49/110:
# Create a DataFrame
district_summary_df = pd.DataFrame(
          [{"Total Schools": school_count, 
          "Total Students": student_count, 
          "Total Budget": total_budget,
          "Average Math Score": average_math_score, 
          "Average Reading Score": average_reading_score,
          "% Passing Math": passing_math_percentage,
         "% Passing Reading": passing_reading_percentage,
        "% Overall Passing": overall_passing_percentage}])



# Format the "Total Students" to have the comma for a thousands separator.
district_summary_df["Total Students"] = district_summary_df["Total Students"].map("{:,}".format)
# Format the "Total Budget" to have the comma for a thousands separator, a decimal separator and a "$".
district_summary_df["Total Budget"] = district_summary_df["Total Budget"].map("${:,.2f}".format)
# Format the columns.
district_summary_df["Average Math Score"] = district_summary_df["Average Math Score"].map("{:.1f}".format)
district_summary_df["Average Reading Score"] = district_summary_df["Average Reading Score"].map("{:.1f}".format)
district_summary_df["% Passing Math"] = district_summary_df["% Passing Math"].map("{:.1f}".format)
district_summary_df["% Passing Reading"] = district_summary_df["% Passing Reading"].map("{:.1f}".format)
district_summary_df["% Overall Passing"] = district_summary_df["% Overall Passing"].map("{:.1f}".format)

# Display the data frame
district_summary_df
49/111:
# Determine the School Type
per_school_types = school_data_df.set_index(["school_name"])["type"]

# Calculate the total student count.
per_school_counts = school_data_complete_df["school_name"].value_counts()

# Calculate the total school budget and per capita spending
per_school_budget = school_data_complete_df.groupby(["school_name"]).mean()["budget"]
# Calculate the per capita spending.
per_school_capita = per_school_budget / per_school_counts

# Calculate the average test scores.
per_school_math = school_data_complete_df.groupby(["school_name"]).mean()["math_score"]
per_school_reading = school_data_complete_df.groupby(["school_name"]).mean()["reading_score"]

# Calculate the passing scores by creating a filtered DataFrame.
per_school_passing_math = school_data_complete_df[(school_data_complete_df["math_score"] >= 70)]
per_school_passing_reading = school_data_complete_df[(school_data_complete_df["reading_score"] >= 70)]

# Calculate the number of students passing math and passing reading by school.
per_school_passing_math = per_school_passing_math.groupby(["school_name"]).count()["student_name"]
per_school_passing_reading = per_school_passing_reading.groupby(["school_name"]).count()["student_name"]

# Calculate the percentage of passing math and reading scores per school.
per_school_passing_math = per_school_passing_math / per_school_counts * 100
per_school_passing_reading = per_school_passing_reading / per_school_counts * 100

# Calculate the students who passed both reading and math.
per_passing_math_reading = school_data_complete_df[(school_data_complete_df["reading_score"] >= 70)
                                               & (school_data_complete_df["math_score"] >= 70)]

# Calculate the number of students passing math and passing reading by school.
per_passing_math_reading = per_passing_math_reading.groupby(["school_name"]).count()["student_name"]

# Calculate the percentage of passing math and reading scores per school.
per_overall_passing_percentage = per_passing_math_reading / per_school_counts * 100
51/1:
# Create the DataFrame
per_school_summary_df = pd.DataFrame({
    "School Type": per_school_types,
    "Total Students": per_school_counts,
    "Total School Budget": per_school_budget,
    "Per Student Budget": per_school_capita,
    "Average Math Score": per_school_math,
    "Average Reading Score": per_school_reading,
    "% Passing Math": per_school_passing_math,
    "% Passing Reading": per_school_passing_reading,
    "% Overall Passing": per_overall_passing_percentage})


# per_school_summary_df.head()
51/2:
# Format the Total School Budget and the Per Student Budget
per_school_summary_df["Total School Budget"] = per_school_summary_df["Total School Budget"].map("${:,.2f}".format)
per_school_summary_df["Per Student Budget"] = per_school_summary_df["Per Student Budget"].map("${:,.2f}".format)

# Display the data frame
per_school_summary_df
51/3:
# Determine the School Type
per_school_types = school_data_df.set_index(["school_name"])["type"]

# Calculate the total student count.
per_school_counts = school_data_complete_df["school_name"].value_counts()

# Calculate the total school budget and per capita spending
per_school_budget = school_data_complete_df.groupby(["school_name"]).mean()["budget"]
# Calculate the per capita spending.
per_school_capita = per_school_budget / per_school_counts

# Calculate the average test scores.
per_school_math = school_data_complete_df.groupby(["school_name"]).mean()["math_score"]
per_school_reading = school_data_complete_df.groupby(["school_name"]).mean()["reading_score"]

# Calculate the passing scores by creating a filtered DataFrame.
per_school_passing_math = school_data_complete_df[(school_data_complete_df["math_score"] >= 70)]
per_school_passing_reading = school_data_complete_df[(school_data_complete_df["reading_score"] >= 70)]

# Calculate the number of students passing math and passing reading by school.
per_school_passing_math = per_school_passing_math.groupby(["school_name"]).count()["student_name"]
per_school_passing_reading = per_school_passing_reading.groupby(["school_name"]).count()["student_name"]

# Calculate the percentage of passing math and reading scores per school.
per_school_passing_math = per_school_passing_math / per_school_counts * 100
per_school_passing_reading = per_school_passing_reading / per_school_counts * 100

# Calculate the students who passed both reading and math.
per_passing_math_reading = school_data_complete_df[(school_data_complete_df["reading_score"] >= 70)
                                               & (school_data_complete_df["math_score"] >= 70)]

# Calculate the number of students passing math and passing reading by school.
per_passing_math_reading = per_passing_math_reading.groupby(["school_name"]).count()["student_name"]

# Calculate the percentage of passing math and reading scores per school.
per_overall_passing_percentage = per_passing_math_reading / per_school_counts * 100
49/112:
# Create the DataFrame
per_school_summary_df = pd.DataFrame({
    "School Type": per_school_types,
    "Total Students": per_school_counts,
    "Total School Budget": per_school_budget,
    "Per Student Budget": per_school_capita,
    "Average Math Score": per_school_math,
    "Average Reading Score": per_school_reading,
    "% Passing Math": per_school_passing_math,
    "% Passing Reading": per_school_passing_reading,
    "% Overall Passing": per_overall_passing_percentage})


per_school_summary_df.head()
49/113:
# Format the Total School Budget and the Per Student Budget
per_school_summary_df["Total School Budget"] = per_school_summary_df["Total School Budget"].map("${:,.2f}".format)
per_school_summary_df["Per Student Budget"] = per_school_summary_df["Per Student Budget"].map("${:,.2f}".format)

# Display the data frame
per_school_summary_df
49/114:
# Step 5.  Get the number of 10th-12th graders from Thomas High School (THS).

tenth_grades_student_count = student_data_df.loc[(student_data_df["school_name"] == "Thomas High School") & (student_data_df["grade"] == "10th")]
twelveth_grade_student_count =  student_data_df.loc[(student_data_df["school_name"] == "Thomas High School") & (student_data_df["grade"] == "12th")]
eleventh_grade_student_count =  student_data_df.loc[(student_data_df["school_name"] == "Thomas High School") & (student_data_df["grade"] == "11th")]
total_number_10th12th_graders= tenth_grades_student_count + twelveth_grade_student_count + eleventh_grade_student_count
total_number_10th12th_graders
49/115:
# Step 5.  Get the number of 10th-12th graders from Thomas High School (THS).

tenth_grades_student_count = student_data_df.loc[(student_data_df["school_name"] == "Thomas High School") & (student_data_df["grade"] == "10th")]
twelveth_grade_student_count =  student_data_df.loc[(student_data_df["school_name"] == "Thomas High School") & (student_data_df["grade"] == "12th")]
eleventh_grade_student_count =  student_data_df.loc[(student_data_df["school_name"] == "Thomas High School") & (student_data_df["grade"] == "11th")]
total_number_10th12th_graders= (len(tenth_grades_student_count)+ len(twelveth_grade_student_count) + len(eleventh_grade_student_count)
total_number_10th12th_graders
49/116:
# Step 5.  Get the number of 10th-12th graders from Thomas High School (THS).

tenth_grades_student_count = student_data_df.loc[(student_data_df["school_name"] == "Thomas High School") & (student_data_df["grade"] == "10th")]
twelveth_grade_student_count =  student_data_df.loc[(student_data_df["school_name"] == "Thomas High School") & (student_data_df["grade"] == "12th")]
eleventh_grade_student_count =  student_data_df.loc[(student_data_df["school_name"] == "Thomas High School") & (student_data_df["grade"] == "11th")]
total_number_10th12th_graders= (len(tenth_grades_student_count)+ len(twelveth_grade_student_count) + len(eleventh_grade_student_count))
total_number_10th12th_graders
49/117:
# Step 6. Get all the students passing math from THS
student_passing_math_ths = school_data_complete_df.loc[(student_data_df["school_name"]=="Thomas High School")&(student_data_df["math_score"] >=70)]
49/118:
# Step 8. Get all the students passing math and reading from THS
student_passing_math_reading_ths = school_data_complete_df.loc[(student_data_df["school_name"]=="Thomas High School")
                                                               &(student_data_df["math_score"] >=70)
                                                               & (student_data_df["reading_score"] >= 70)]
student_passing_math_reading_ths
49/119:
# Step 9. Calculate the percentage of 10th-12th grade students passing math from Thomas High School. 
student_passing_math_ths_count = len(student_passing_math_ths)
student_passing_math_ths_percentage = student_passing_math_ths/total_number_10thto12th_graders*100
49/120:
# Step 5.  Get the number of 10th-12th graders from Thomas High School (THS).

tenth_grades_student_count = student_data_df.loc[(student_data_df["school_name"] == "Thomas High School") & (student_data_df["grade"] == "10th")]
twelveth_grade_student_count =  student_data_df.loc[(student_data_df["school_name"] == "Thomas High School") & (student_data_df["grade"] == "12th")]
eleventh_grade_student_count =  student_data_df.loc[(student_data_df["school_name"] == "Thomas High School") & (student_data_df["grade"] == "11th")]
total_number_10thto12th_graders_count= (len(tenth_grades_student_count)+ len(twelveth_grade_student_count) + len(eleventh_grade_student_count))
total_number_10thto12th_graders
49/121:
# Step 5.  Get the number of 10th-12th graders from Thomas High School (THS).

tenth_grades_student_count = student_data_df.loc[(student_data_df["school_name"] == "Thomas High School") & (student_data_df["grade"] == "10th")]
twelveth_grade_student_count =  student_data_df.loc[(student_data_df["school_name"] == "Thomas High School") & (student_data_df["grade"] == "12th")]
eleventh_grade_student_count =  student_data_df.loc[(student_data_df["school_name"] == "Thomas High School") & (student_data_df["grade"] == "11th")]
total_number_10thto12th_graders_count= (len(tenth_grades_student_count)+ len(twelveth_grade_student_count) + len(eleventh_grade_student_count))
total_number_10thto12th_graders
49/122:
# Format the Total School Budget and the Per Student Budget
per_school_summary_df["Total School Budget"] = per_school_summary_df["Total School Budget"].map("${:,.2f}".format)
per_school_summary_df["Per Student Budget"] = per_school_summary_df["Per Student Budget"].map("${:,.2f}".format)

# Display the data frame
per_school_summary_df
49/123:
# Create the DataFrame
per_school_summary_df = pd.DataFrame({
    "School Type": per_school_types,
    "Total Students": per_school_counts,
    "Total School Budget": per_school_budget,
    "Per Student Budget": per_school_capita,
    "Average Math Score": per_school_math,
    "Average Reading Score": per_school_reading,
    "% Passing Math": per_school_passing_math,
    "% Passing Reading": per_school_passing_reading,
    "% Overall Passing": per_overall_passing_percentage})


per_school_summary_df.head()
49/124:
# Format the Total School Budget and the Per Student Budget
per_school_summary_df["Total School Budget"] = per_school_summary_df["Total School Budget"].map("${:,.2f}".format)
per_school_summary_df["Per Student Budget"] = per_school_summary_df["Per Student Budget"].map("${:,.2f}".format)

# Display the data frame
per_school_summary_df
49/125:
# Step 5.  Get the number of 10th-12th graders from Thomas High School (THS).

tenth_grades_student_count = student_data_df.loc[(student_data_df["school_name"] == "Thomas High School") & (student_data_df["grade"] == "10th")]
twelveth_grade_student_count =  student_data_df.loc[(student_data_df["school_name"] == "Thomas High School") & (student_data_df["grade"] == "12th")]
eleventh_grade_student_count =  student_data_df.loc[(student_data_df["school_name"] == "Thomas High School") & (student_data_df["grade"] == "11th")]
total_number_10thto12th_graders_count= (len(tenth_grades_student_count)+ len(twelveth_grade_student_count) + len(eleventh_grade_student_count))
total_number_10thto12th_graders
49/126:
# Step 5.  Get the number of 10th-12th graders from Thomas High School (THS).

tenth_grades_student_count = student_data_df.loc[(student_data_df["school_name"] == "Thomas High School") & (student_data_df["grade"] == "10th")]
twelveth_grade_student_count =  student_data_df.loc[(student_data_df["school_name"] == "Thomas High School") & (student_data_df["grade"] == "12th")]
eleventh_grade_student_count =  student_data_df.loc[(student_data_df["school_name"] == "Thomas High School") & (student_data_df["grade"] == "11th")]
total_number_10thto12th_graders_count= (len(tenth_grades_student_count)+ len(twelveth_grade_student_count) + len(eleventh_grade_student_count))
total_number_10thto12th_graders_count
49/127:
# Step 9. Calculate the percentage of 10th-12th grade students passing math from Thomas High School. 
student_passing_math_ths_count = len(student_passing_math_ths)
student_passing_math_ths_percentage = student_passing_math_ths_count /total_number_10thto12th_graders_count*100
49/128:
# Step 10. Calculate the percentage of 10th-12th grade students passing reading from Thomas High School.
student_passing_reading_ths_count = len(student_passing_reading_ths)
student_passing_reading_ths_percentage = student_passing_reading_ths_count /total_number_10thto12th_graders_count*100
49/129:
# Step 9. Calculate the percentage of 10th-12th grade students passing math from Thomas High School. 
student_passing_math_ths_count = len(student_passing_math_ths)
student_passing_math_ths_percentage = student_passing_math_ths_count /total_number_10thto12th_graders_count*100
49/130:
# Step 10. Calculate the percentage of 10th-12th grade students passing reading from Thomas High School.
student_passing_reading_ths_count = len(student_passing_reading_ths)
student_passing_reading_ths_percentage = student_passing_reading_ths_count /total_number_10thto12th_graders_count*100
49/131:
# Step 8. Get all the students passing math and reading from THS
student_passing_math_reading_ths = school_data_complete_df.loc[(student_data_df["school_name"]=="Thomas High School")
                                                               &(student_data_df["math_score"] >=70)
                                                               & (student_data_df["reading_score"] >= 70)]
student_passing_math_reading_ths
49/132:
# Step 9. Calculate the percentage of 10th-12th grade students passing math from Thomas High School. 
student_passing_math_ths_count = len(student_passing_math_ths)
student_passing_math_ths_percentage = student_passing_math_ths_count /total_number_10thto12th_graders_count*100
49/133:
# Step 10. Calculate the percentage of 10th-12th grade students passing reading from Thomas High School.
student_passing_reading_ths_count = len(student_passing_reading_ths)
student_passing_reading_ths_percentage = student_passing_reading_ths_count /total_number_10thto12th_graders_count*100
49/134:
# Dependencies and Setup
import pandas as pd

# File to Load (Remember to change the path if needed.)
school_data_to_load = "Resources/schools_complete.csv"
student_data_to_load = "Resources/students_complete.csv"

# Read the School Data and Student Data and store into a Pandas DataFrame
school_data_df = pd.read_csv(school_data_to_load)
student_data_df = pd.read_csv(student_data_to_load)

# Cleaning Student Names and Replacing Substrings in a Python String
# Add each prefix and suffix to remove to a list.
prefixes_suffixes = ["Dr. ", "Mr. ","Ms. ", "Mrs. ", "Miss ", " MD", " DDS", " DVM", " PhD"]

# Iterate through the words in the "prefixes_suffixes" list and replace them with an empty space, "".
for word in prefixes_suffixes:
    student_data_df["student_name"] = student_data_df["student_name"].str.replace(word,"")

# Check names.
student_data_df.head(10)
49/135:
# Install numpy using conda install numpy or pip install numpy. 
# Step 1. Import numpy as np.
import numpy as np
49/136:
# Step 2. Use the loc method on the student_data_df to select all the reading scores from the 9th grade at Thomas High School and replace them with NaN.
student_data_df.loc[(student_data_df["school_name"] == "Thomas High School") & (student_data_df["grade"] == "9th"), "reading_score"] = np.nan
49/137:
#  Step 3. Refactor the code in Step 2 to replace the math scores with NaN.
student_data_df.loc[(student_data_df["school_name"] == "Thomas High School") & (student_data_df["grade"] == "9th"), "math_score"] = np.nan
49/138:
#  Step 4. Check the student data for NaN's. 

student_data_df.tail(10)
49/139:
# Combine the data into a single dataset
school_data_complete_df = pd.merge(student_data_df, school_data_df, how="left", on=["school_name", "school_name"])
school_data_complete_df.head()
49/140:
# Calculate the Totals (Schools and Students)
school_count = len(school_data_complete_df["school_name"].unique())
student_count = school_data_complete_df["Student ID"].count()

# Calculate the Total Budget
total_budget = school_data_df["budget"].sum()
49/141:
# Calculate the Average Scores using the "clean_student_data".
average_reading_score = school_data_complete_df["reading_score"].mean()
average_math_score = school_data_complete_df["math_score"].mean()
49/142:
# Step 1. Get the number of students that are in ninth grade at Thomas High School.
# These students have no grades. 

ninth_grades_student_count = len(student_data_df.loc[(student_data_df["school_name"] == "Thomas High School") & (student_data_df["grade"] == "9th")])


# Get the total student count 
student_count = school_data_complete_df["Student ID"].count()


# Step 2. Subtract the number of students that are in ninth grade at 
# Thomas High School from the total student count to get the new total student count.
new_total_student_count = (student_count - ninth_grades_student_count)
49/143:
# Calculate the passing rates using the "clean_student_data".
passing_math_count = school_data_complete_df[(school_data_complete_df["math_score"] >= 70)].count()["student_name"]
passing_reading_count = school_data_complete_df[(school_data_complete_df["reading_score"] >= 70)].count()["student_name"]
49/144:
# Step 3. Calculate the passing percentages with the new total student count.
passing_math_percentage = passing_math_count/float(new_total_student_count) *100
passing_reading_percentage = passing_reading_count/float(new_total_student_count) *100
49/145:
# Calculate the students who passed both reading and math.
passing_math_reading = school_data_complete_df[(school_data_complete_df["math_score"] >= 70)
                                               & (school_data_complete_df["reading_score"] >= 70)]

# Calculate the number of students that passed both reading and math.
overall_passing_math_reading_count = passing_math_reading["student_name"].count()


# Step 4.Calculate the overall passing percentage with new total student count.
overall_passing_percentage= overall_passing_math_reading_count/new_total_student_count*100
overall_passing_percentage
49/146:
# Create a DataFrame
district_summary_df = pd.DataFrame(
          [{"Total Schools": school_count, 
          "Total Students": student_count, 
          "Total Budget": total_budget,
          "Average Math Score": average_math_score, 
          "Average Reading Score": average_reading_score,
          "% Passing Math": passing_math_percentage,
         "% Passing Reading": passing_reading_percentage,
        "% Overall Passing": overall_passing_percentage}])



# Format the "Total Students" to have the comma for a thousands separator.
district_summary_df["Total Students"] = district_summary_df["Total Students"].map("{:,}".format)
# Format the "Total Budget" to have the comma for a thousands separator, a decimal separator and a "$".
district_summary_df["Total Budget"] = district_summary_df["Total Budget"].map("${:,.2f}".format)
# Format the columns.
district_summary_df["Average Math Score"] = district_summary_df["Average Math Score"].map("{:.1f}".format)
district_summary_df["Average Reading Score"] = district_summary_df["Average Reading Score"].map("{:.1f}".format)
district_summary_df["% Passing Math"] = district_summary_df["% Passing Math"].map("{:.1f}".format)
district_summary_df["% Passing Reading"] = district_summary_df["% Passing Reading"].map("{:.1f}".format)
district_summary_df["% Overall Passing"] = district_summary_df["% Overall Passing"].map("{:.1f}".format)

# Display the data frame
district_summary_df
49/147:
# Determine the School Type
per_school_types = school_data_df.set_index(["school_name"])["type"]

# Calculate the total student count.
per_school_counts = school_data_complete_df["school_name"].value_counts()

# Calculate the total school budget and per capita spending
per_school_budget = school_data_complete_df.groupby(["school_name"]).mean()["budget"]
# Calculate the per capita spending.
per_school_capita = per_school_budget / per_school_counts

# Calculate the average test scores.
per_school_math = school_data_complete_df.groupby(["school_name"]).mean()["math_score"]
per_school_reading = school_data_complete_df.groupby(["school_name"]).mean()["reading_score"]

# Calculate the passing scores by creating a filtered DataFrame.
per_school_passing_math = school_data_complete_df[(school_data_complete_df["math_score"] >= 70)]
per_school_passing_reading = school_data_complete_df[(school_data_complete_df["reading_score"] >= 70)]

# Calculate the number of students passing math and passing reading by school.
per_school_passing_math = per_school_passing_math.groupby(["school_name"]).count()["student_name"]
per_school_passing_reading = per_school_passing_reading.groupby(["school_name"]).count()["student_name"]

# Calculate the percentage of passing math and reading scores per school.
per_school_passing_math = per_school_passing_math / per_school_counts * 100
per_school_passing_reading = per_school_passing_reading / per_school_counts * 100

# Calculate the students who passed both reading and math.
per_passing_math_reading = school_data_complete_df[(school_data_complete_df["reading_score"] >= 70)
                                               & (school_data_complete_df["math_score"] >= 70)]

# Calculate the number of students passing math and passing reading by school.
per_passing_math_reading = per_passing_math_reading.groupby(["school_name"]).count()["student_name"]

# Calculate the percentage of passing math and reading scores per school.
per_overall_passing_percentage = per_passing_math_reading / per_school_counts * 100
49/148:
# Create the DataFrame
per_school_summary_df = pd.DataFrame({
    "School Type": per_school_types,
    "Total Students": per_school_counts,
    "Total School Budget": per_school_budget,
    "Per Student Budget": per_school_capita,
    "Average Math Score": per_school_math,
    "Average Reading Score": per_school_reading,
    "% Passing Math": per_school_passing_math,
    "% Passing Reading": per_school_passing_reading,
    "% Overall Passing": per_overall_passing_percentage})


per_school_summary_df.head()
49/149:
# Format the Total School Budget and the Per Student Budget
per_school_summary_df["Total School Budget"] = per_school_summary_df["Total School Budget"].map("${:,.2f}".format)
per_school_summary_df["Per Student Budget"] = per_school_summary_df["Per Student Budget"].map("${:,.2f}".format)

# Display the data frame
per_school_summary_df
49/150:
# Step 5.  Get the number of 10th-12th graders from Thomas High School (THS).

tenth_grades_student_count = student_data_df.loc[(student_data_df["school_name"] == "Thomas High School") & (student_data_df["grade"] == "10th")]
twelveth_grade_student_count =  student_data_df.loc[(student_data_df["school_name"] == "Thomas High School") & (student_data_df["grade"] == "12th")]
eleventh_grade_student_count =  student_data_df.loc[(student_data_df["school_name"] == "Thomas High School") & (student_data_df["grade"] == "11th")]
total_number_10thto12th_graders_count= (len(tenth_grades_student_count)+ len(twelveth_grade_student_count) + len(eleventh_grade_student_count))
total_number_10thto12th_graders_count
49/151:
# Step 6. Get all the students passing math from THS
student_passing_math_ths = school_data_complete_df.loc[(student_data_df["school_name"]=="Thomas High School")&(student_data_df["math_score"] >=70)]
49/152:
# Step 7. Get all the students passing reading from THS
student_passing_reading_ths = school_data_complete_df.loc[(student_data_df["school_name"]=="Thomas High School")&(student_data_df["reading_score"] >=70)]
49/153:
# Step 8. Get all the students passing math and reading from THS
student_passing_math_reading_ths = school_data_complete_df.loc[(student_data_df["school_name"]=="Thomas High School")
                                                               &(student_data_df["math_score"] >=70)
                                                               & (student_data_df["reading_score"] >= 70)]
student_passing_math_reading_ths
49/154:
# Step 9. Calculate the percentage of 10th-12th grade students passing math from Thomas High School. 
student_passing_math_ths_count = len(student_passing_math_ths)
student_passing_math_ths_percentage = student_passing_math_ths_count /total_number_10thto12th_graders_count*100
49/155:
# Step 10. Calculate the percentage of 10th-12th grade students passing reading from Thomas High School.
student_passing_reading_ths_count = len(student_passing_reading_ths)
student_passing_reading_ths_percentage = student_passing_reading_ths_count /total_number_10thto12th_graders_count*100
49/156: # Step 11. Calculate the overall passing percentage of 10th-12th grade from Thomas High School.
49/157: # Step 12. Replace the passing math percent for Thomas High School in the per_school_summary_df.
49/158: # Step 13. Replace the passing reading percentage for Thomas High School in the per_school_summary_df.
49/159: # Step 14. Replace the overall passing percentage for Thomas High School in the per_school_summary_df.
49/160: # per_school_summary_df
49/161: # Sort and show top five schools.
49/162: # Sort and show top five schools.
49/163:
# Create a Series of scores by grade levels using conditionals.


# Group each school Series by the school name for the average math score.


# Group each school Series by the school name for the average reading score.
49/164: # Combine each Series for average math scores by school into single data frame.
49/165: # Combine each Series for average reading scores by school into single data frame.
49/166: # Format each grade column.
49/167:
# Remove the index.


# Display the data frame
49/168:
## Remove the index.


# Display the data frame
49/169:
# Establish the spending bins and group names.


# Categorize spending based on the bins.
49/170: # Calculate averages for the desired columns.
49/171: # Create the DataFrame
49/172: # Format the DataFrame
49/173:
# Establish the bins.

# Categorize spending based on the bins.
49/174: # Calculate averages for the desired columns.
49/175: # Assemble into DataFrame.
49/176: # Format the DataFrame
49/177: # Calculate averages for the desired columns.
49/178: # Assemble into DataFrame.
49/179: # # Format the DataFrame
49/180:
# Step 8. Get all the students passing math and reading from THS
student_passing_math_reading_ths = school_data_complete_df.loc[(student_data_df["school_name"]=="Thomas High School")
                                                               &(student_data_df["math_score"] >=70)
                                                               & (student_data_df["reading_score"] >= 70)]
student_passing_math_reading_ths.head()
49/181:
# Step 9. Calculate the percentage of 10th-12th grade students passing math from Thomas High School. 
student_passing_math_ths_count = len(student_passing_math_ths)
student_passing_math_ths_percentage = student_passing_math_ths_count /total_number_10thto12th_graders_count*100
49/182:
# Step 10. Calculate the percentage of 10th-12th grade students passing reading from Thomas High School.
student_passing_reading_ths_count = len(student_passing_reading_ths)
student_passing_reading_ths_percentage = student_passing_reading_ths_count /total_number_10thto12th_graders_count*100
49/183:
# Step 11. Calculate the overall passing percentage of 10th-12th grade from Thomas High School. 
student_passing_overall_ths_count = len(student_passing_math_reading_ths)
student_passing_overall_ths_percentage = student_passing_overall_ths_count /total_number_10thto12th_graders_count*100
49/184:
# Step 12. Replace the passing math percent for Thomas High School in the per_school_summary_df.
per_school_summary_df.loc["Thomas High School", "% Passing Math"] = student_passing_math_ths_percentage
49/185:
# Step 13. Replace the passing reading percentage for Thomas High School in the per_school_summary_df.
per_school_summary_df.loc["Thomas High School", "% Passing Reading"] = student_passing_reading_ths_percentage
49/186:
# Step 14. Replace the overall passing percentage for Thomas High School in the per_school_summary_df.
per_school_summary_df.loc["Thomas High School", "% Overall Passing"] = student_passing_overall_ths_percentage
49/187: per_school_summary_df
49/188:
# Sort and show top five schools.
# Sort and show top five schools.
top_schools = per_school_summary_df.sort_values(["% Overall Passing"], ascending=False)
top_schools.head()
49/189:
# Sort and show top five schools.
# Sort and show top five schools.
top_schools = per_school_summary_df.sort_values(["% Overall Passing"], ascending=True)
top_schools.head()
49/190:
# Sort and show top five schools.
# Sort and show top five schools.
top_schools = per_school_summary_df.sort_values(["% Overall Passing"], ascending=False)
top_schools.head()
49/191:
# Sort and show bottom five schools.
bottom_schools = per_school_summary_df.sort_values(["% Overall Passing"], ascending=False)
bottom_schools.head()
49/192:
# Sort and show bottom five schools.
bottom_schools = per_school_summary_df.sort_values(["% Overall Passing"], ascending=True)
bottom_schools.head()
49/193:
# Create a Series of scores by grade levels using conditionals.
ninth_grades = school_data_complete_df[(school_data_complete_df["grade"] =="9th")]
tenth_grades = school_data_complete_df[(school_data_complete_df["grade"] =="10th")]
eleventh_grades = school_data_complete_df[(school_data_complete_df["grade"] =="11th")]
twelfth_grades = school_data_complete_df[(school_data_complete_df["grade"] =="12th")]

# Group each school Series by the school name for the average math score.


# Group each school Series by the school name for the average reading score.
49/194:
# Create a Series of scores by grade levels using conditionals.
ninth_grades = school_data_complete_df[(school_data_complete_df["grade"] =="9th")]
tenth_grades = school_data_complete_df[(school_data_complete_df["grade"] =="10th")]
eleventh_grades = school_data_complete_df[(school_data_complete_df["grade"] =="11th")]
twelfth_grades = school_data_complete_df[(school_data_complete_df["grade"] =="12th")]

# Group each school Series by the school name for the average math score.
ninth_grade_math_scores = ninth_graders.groupby(["school_name"]).mean()["math_score"]
tenth_grade_math_scores = tenth_graders.groupby(["school_name"]).mean()["math_score"]
eleventh_grade_math_scores = eleventh_graders.groupby(["school_name"]).mean()["math_score"]
twelfth_grade_math_scores = twelfth_graders.groupby(["school_name"]).mean()["math_score"]

# Group each school Series by the school name for the average reading score.
ninth_grade_reading_scores = ninth_graders.groupby(["school_name"]).mean()["reading_score"]
tenth_grade_reading_scores = tenth_graders.groupby(["school_name"]).mean()["reading_score"]
eleventh_grade_reading_scores = eleventh_graders.groupby(["school_name"]).mean()["reading_score"]
twelfth_grade_reading_scores = twelfth_graders.groupby(["school_name"]).mean()["reading_score"]
49/195:
# Create a Series of scores by grade levels using conditionals.
ninth_grades = school_data_complete_df[(school_data_complete_df["grade"] =="9th")]
tenth_grades = school_data_complete_df[(school_data_complete_df["grade"] =="10th")]
eleventh_grades = school_data_complete_df[(school_data_complete_df["grade"] =="11th")]
twelfth_grades = school_data_complete_df[(school_data_complete_df["grade"] =="12th")]

# Group each school Series by the school name for the average math score.
ninth_grades_math_scores = ninth_graders.groupby(["school_name"]).mean()["math_score"]
tenth_grades_math_scores = tenth_graders.groupby(["school_name"]).mean()["math_score"]
eleventh_grades_math_scores = eleventh_graders.groupby(["school_name"]).mean()["math_score"]
twelfth_grades_math_scores = twelfth_graders.groupby(["school_name"]).mean()["math_score"]

# Group each school Series by the school name for the average reading score.
ninth_grades_reading_scores = ninth_grades.groupby(["school_name"]).mean()["reading_score"]
tenth_grades_reading_scores = tenth_grades.groupby(["school_name"]).mean()["reading_score"]
eleventh_grades_reading_scores = eleventh_grades.groupby(["school_name"]).mean()["reading_score"]
twelfth_grades_reading_scores = twelfth_grades.groupby(["school_name"]).mean()["reading_score"]
49/196:
# Create a Series of scores by grade levels using conditionals.
ninth_grades = school_data_complete_df[(school_data_complete_df["grade"] =="9th")]
tenth_grades = school_data_complete_df[(school_data_complete_df["grade"] =="10th")]
eleventh_grades = school_data_complete_df[(school_data_complete_df["grade"] =="11th")]
twelfth_grades = school_data_complete_df[(school_data_complete_df["grade"] =="12th")]

# Group each school Series by the school name for the average math score.
ninth_grades_math_scores = ninth_graders.groupby(["school_name"]).mean()["math_score"]
tenth_grades_math_scores = tenth_graders.groupby(["school_name"]).mean()["math_score"]
eleventh_grades_math_scores = eleventh_graders.groupby(["school_name"]).mean()["math_score"]
twelfth_grades_math_scores = twelfth_graders.groupby(["school_name"]).mean()["math_score"]

# Group each school Series by the school name for the average reading score.
49/197:
# Create a Series of scores by grade levels using conditionals.
ninth_grades = school_data_complete_df[(school_data_complete_df["grade"] =="9th")]
tenth_grades = school_data_complete_df[(school_data_complete_df["grade"] =="10th")]
eleventh_grades = school_data_complete_df[(school_data_complete_df["grade"] =="11th")]
twelfth_grades = school_data_complete_df[(school_data_complete_df["grade"] =="12th")]

# Group each school Series by the school name for the average math score.


# Group each school Series by the school name for the average reading score.
49/198:
# Create a Series of scores by grade levels using conditionals.
ninth_grades = school_data_complete_df[(school_data_complete_df["grade"] =="9th")]
tenth_grades = school_data_complete_df[(school_data_complete_df["grade"] =="10th")]
eleventh_grades = school_data_complete_df[(school_data_complete_df["grade"] =="11th")]
twelfth_grades = school_data_complete_df[(school_data_complete_df["grade"] =="12th")]

# Group each school Series by the school name for the average math score.
ninth_grade_math_scores = ninth_grades.groupby(["school_name"]).mean()["math_score"]
tenth_grade_math_scores = tenth_grades.groupby(["school_name"]).mean()["math_score"]
eleventh_grade_math_scores = eleventh_grades.groupby(["school_name"]).mean()["math_score"]
twelfth_grade_math_scores = twelfth_grades.groupby(["school_name"]).mean()["math_score"]

# Group each school Series by the school name for the average reading score.
49/199:
# Create a Series of scores by grade levels using conditionals.
ninth_grades_students = school_data_complete_df[(school_data_complete_df["grade"] =="9th")]
tenth_grades_students = school_data_complete_df[(school_data_complete_df["grade"] =="10th")]
eleventh_grades_students = school_data_complete_df[(school_data_complete_df["grade"] =="11th")]
twelfth_grades_students = school_data_complete_df[(school_data_complete_df["grade"] =="12th")]

# Group each school Series by the school name for the average math score.
ninth_grade_math_scores = ninth_grades_students.groupby(["school_name"]).mean()["math_score"]
tenth_grade_math_scores = tenth_grades_students.groupby(["school_name"]).mean()["math_score"]
eleventh_grade_math_scores = eleventh_grades_students.groupby(["school_name"]).mean()["math_score"]
twelfth_grade_math_scores = twelfth_grades_students.groupby(["school_name"]).mean()["math_score"]

# Group each school Series by the school name for the average reading score.
ninth_grade_reading_scores = ninth_grades_students.groupby(["school_name"]).mean()["reading_score"]
tenth_grade_reading_scores = tenth_grades_students.groupby(["school_name"]).mean()["reading_score"]
eleventh_grade_reading_scores = eleventh_grades_students.groupby(["school_name"]).mean()["reading_score"]
twelfth_grade_reading_scores = twelfth_grades_students.groupby(["school_name"]).mean()["reading_score"]
49/200:
# Combine each Series for average math scores by school into single data frame.
math_scores_by_grade = pd.DataFrame({
    "9th": ninth_grade_math_scores,
    "10th": tenth_grade_math_scores,
    "11th": eleventh_grade_math_scores,
    "12th": twelfth_grade_math_scores})
49/201:
# Combine each Series for average reading scores by school into single data frame.
reading_scores_by_grade = pd.DataFrame({
    "9th": ninth_grade_reading_scores,
    "10th": tenth_grade_reading_scores,
    "11th": eleventh_grade_reading_scores,
    "12th": twelfth_grade_reading_scores})
49/202:
# Format each grade column.
# Format each grade column for math
math_scores_by_grade["9th"] = math_scores_by_grade["9th"].map("{:.1f}".format)
math_scores_by_grade["10th"] = math_scores_by_grade["10th"].map("{:.1f}".format)
math_scores_by_grade["11th"] = math_scores_by_grade["11th"].map("{:.1f}".format)
math_scores_by_grade["12th"] = math_scores_by_grade["12th"].map("{:.1f}".format)
# Put in order
math_scores_by_grade = math_scores_by_grade[["9th", "10th", "11th", "12th"]]

# Format each grade column for reading.
reading_scores_by_grade["9th"] = reading_scores_by_grade["9th"].map("{:.1f}".format)
reading_scores_by_grade["10th"] = reading_scores_by_grade["10th"].map("{:.1f}".format)
reading_scores_by_grade["11th"] = reading_scores_by_grade["11th"].map("{:.1f}".format)
reading_scores_by_grade["12th"] = reading_scores_by_grade["12th"].map("{:.1f}".format)
# Put in order
reading_scores_by_grade = reading_scores_by_grade[["9th", "10th", "11th", "12th"]]
49/203:
# Remove the index.
math_scores_by_grade.index.name = None

# Display the data frame
math_scores_by_grade
49/204:
## Remove the index.
reading_scores_by_grade.index.name = None

# Display the data frame
49/205:
## Remove the index.
reading_scores_by_grade.index.name = None

# Display the data frame
reading_scores_by_grade
49/206:
# Establish the spending bins and group names.

per_school_capita.describe()
spending_bins=[0,585,630,645,675]
group_names=["<$584","$585-629", "$630-644", "$645-675"]
per_school_capita.groupby(pd.cut(per_school_capita, spending_bins)).count()

# Categorize spending based on the bins.
per_school_summary_df["Spending Ranges (Per Student)"]=pd.cut(per_school_capita, spending_bins, labels=group_names)
per_school_summary_df
49/207:
# Calculate averages for the desired columns. 
spending_math_scores = per_school_summary_df.groupby(["Spending Ranges (Per Student)"]).mean()["Average Math Score"]
spending_reading_scores = per_school_summary_df.groupby(["Spending Ranges (Per Student)"]).mean()["Average Reading Score"]
spending_passing_math = per_school_summary_df.groupby(["Spending Ranges (Per Student)"]).mean()["% Passing Math"]
spending_passing_reading = per_school_summary_df.groupby(["Spending Ranges (Per Student)"]).mean()["% Passing Reading"]
overall_passing_spending = per_school_summary_df.groupby(["Spending Ranges (Per Student)"]).mean()["% Overall Passing"]
49/208:
# Format the DataFrame 
spending_summary_df["Average Math Score"] = spending_summary_df["Average Math Score"].map("{:.1f}".format)
spending_summary_df["Average Reading Score"] = spending_summary_df["Average Reading Score"].map("{:.1f}".format)
spending_summary_df["% Passing Math"] = spending_summary_df["% Passing Math"].map("{:.0f}".format)
spending_summary_df["% Passing Reading"] = spending_summary_df["% Passing Reading"].map("{:.0f}".format)
spending_summary_df["% Overall Passing"] = spending_summary_df["% Overall Passing"].map("{:.1f}".format)
spending_summary_df
49/209:
# Create the DataFrame
spending_summary_df = pd.DataFrame({
    "Average Math Score": spending_math_scores,
    "Average Reading Score": spending_reading_scores,
    "% Passing Math": spending_passing_math,
    "% Passing Reading": spending_passing_reading,
    "% Overall Passing": overall_passing_spending})
49/210:
# Format the DataFrame 
spending_summary_df["Average Math Score"] = spending_summary_df["Average Math Score"].map("{:.1f}".format)
spending_summary_df["Average Reading Score"] = spending_summary_df["Average Reading Score"].map("{:.1f}".format)
spending_summary_df["% Passing Math"] = spending_summary_df["% Passing Math"].map("{:.0f}".format)
spending_summary_df["% Passing Reading"] = spending_summary_df["% Passing Reading"].map("{:.0f}".format)
spending_summary_df["% Overall Passing"] = spending_summary_df["% Overall Passing"].map("{:.1f}".format)
spending_summary_df
49/211: per_school_summary_df("Thomas High School")
49/212: per_school_summary_df
49/213:
# Step 14. Replace the overall passing percentage for Thomas High School in the per_school_summary_df.
per_school_summary_df.loc["Thomas High School", "% Overall Passing"] = student_passing_overall_ths_percentage
49/214: per_school_summary_df
49/215:
# Establish the bins.
size_bins = [0, 1000, 2000, 5000]
group_names = ["Small (<1000)", "Medium (1000-2000)", "Large(2000-5000)"]
# Categorize spending based on the bins.
per_school_summary_df["School Size"] = pd.cut(per_school_summary_df["Total Students"], size_bins, labels=group_names)
49/216:
# Calculate averages for the desired columns. 
size_math_scores = per_school_summary_df.groupby(["School Size"]).mean()["Average Math Score"]
size_reading_scores = per_school_summary_df.groupby(["School Size"]).mean()["Average Reading Score"]
size_passing_math = per_school_summary_df.groupby(["School Size"]).mean()["% Passing Math"]
size_passing_reading = per_school_summary_df.groupby(["School Size"]).mean()["% Passing Reading"]
size_overall_passing = per_school_summary_df.groupby(["School Size"]).mean()["% Overall Passing"]
49/217:
# Assemble into DataFrame. 
size_summary_df = pd.DataFrame({
    "Average Math Score": size_math_scores,
    "Average Reading Score": size_reading_scores,
    "% Passing Math": size_passing_math,
    "% Passing Reading": size_passing_reading,
    "% Overall Passing": size_overall_passing})
49/218:
# Format the DataFrame  
size_summary_df["Average Math Score"] = size_summary_df["Average Math Score"].map("{:.1f}".format)
size_summary_df["Average Reading Score"] = size_summary_df["Average Reading Score"].map("{:.1f}".format)
size_summary_df["% Passing Math"] = size_summary_df["% Passing Math"].map("{:.0f}".format)
size_summary_df["% Passing Reading"] = size_summary_df["% Passing Reading"].map("{:.0f}".format)
size_summary_df["% Overall Passing"] = size_summary_df["% Overall Passing"].map("{:.0f}".format)
size_summary_df
49/219:
# Calculate averages for the desired columns. 
type_math_scores = per_school_summary_df.groupby(["School Type"]).mean()["Average Math Score"]
type_reading_scores = per_school_summary_df.groupby(["School Type"]).mean()["Average Reading Score"]
type_passing_math = per_school_summary_df.groupby(["School Type"]).mean()["% Passing Math"]
type_passing_reading = per_school_summary_df.groupby(["School Type"]).mean()["% Passing Reading"]
type_overall_passing = per_school_summary_df.groupby(["School Type"]).mean()["% Overall Passing"]
49/220:
# # Format the DataFrame 
type_summary_df["Average Math Score"] = type_summary_df["Average Math Score"].map("{:.1f}".format)
type_summary_df["Average Reading Score"] = type_summary_df["Average Reading Score"].map("{:.1f}".format)
type_summary_df["% Passing Math"] = type_summary_df["% Passing Math"].map("{:.0f}".format)
type_summary_df["% Passing Reading"] = type_summary_df["% Passing Reading"].map("{:.0f}".format)
type_summary_df["% Overall Passing"] = type_summary_df["% Overall Passing"].map("{:.0f}".format)
type_summary_df
49/221:
# Calculate averages for the desired columns. 
type_math_scores = per_school_summary_df.groupby(["School Type"]).mean()["Average Math Score"]
type_reading_scores = per_school_summary_df.groupby(["School Type"]).mean()["Average Reading Score"]
type_passing_math = per_school_summary_df.groupby(["School Type"]).mean()["% Passing Math"]
type_passing_reading = per_school_summary_df.groupby(["School Type"]).mean()["% Passing Reading"]
type_overall_passing = per_school_summary_df.groupby(["School Type"]).mean()["% Overall Passing"]
49/222:
# Assemble into DataFrame. 
type_summary_df = pd.DataFrame({
    "Average Math Score": type_math_scores,
    "Average Reading Score": type_reading_scores,
    "% Passing Math": type_passing_math,
    "% Passing Reading": type_passing_reading,
    "% Overall Passing": type_overall_passing})
49/223:
# # Format the DataFrame 
type_summary_df["Average Math Score"] = type_summary_df["Average Math Score"].map("{:.1f}".format)
type_summary_df["Average Reading Score"] = type_summary_df["Average Reading Score"].map("{:.1f}".format)
type_summary_df["% Passing Math"] = type_summary_df["% Passing Math"].map("{:.0f}".format)
type_summary_df["% Passing Reading"] = type_summary_df["% Passing Reading"].map("{:.0f}".format)
type_summary_df["% Overall Passing"] = type_summary_df["% Overall Passing"].map("{:.0f}".format)
type_summary_df
49/224:
# Dependencies and Setup
import pandas as pd

# File to Load (Remember to change the path if needed.)
school_data_to_load = "Resources/schools_complete.csv"
student_data_to_load = "Resources/students_complete.csv"

# Read the School Data and Student Data and store into a Pandas DataFrame
school_data_df = pd.read_csv(school_data_to_load)
student_data_df = pd.read_csv(student_data_to_load)

# Cleaning Student Names and Replacing Substrings in a Python String
# Add each prefix and suffix to remove to a list.
prefixes_suffixes = ["Dr. ", "Mr. ","Ms. ", "Mrs. ", "Miss ", " MD", " DDS", " DVM", " PhD"]

# Iterate through the words in the "prefixes_suffixes" list and replace them with an empty space, "".
for word in prefixes_suffixes:
    student_data_df["student_name"] = student_data_df["student_name"].str.replace(word,"")

# Check names.
student_data_df.head(10)
49/225:
# Install numpy using conda install numpy or pip install numpy. 
# Step 1. Import numpy as np.
import numpy as np
49/226:
# Step 2. Use the loc method on the student_data_df to select all the reading scores from the 9th grade at Thomas High School and replace them with NaN.
student_data_df.loc[(student_data_df["school_name"] == "Thomas High School") & (student_data_df["grade"] == "9th"), "reading_score"] = np.nan
49/227:
#  Step 3. Refactor the code in Step 2 to replace the math scores with NaN.
student_data_df.loc[(student_data_df["school_name"] == "Thomas High School") & (student_data_df["grade"] == "9th"), "math_score"] = np.nan
49/228:
#  Step 4. Check the student data for NaN's. 

student_data_df.tail(10)
49/229:
# Combine the data into a single dataset
school_data_complete_df = pd.merge(student_data_df, school_data_df, how="left", on=["school_name", "school_name"])
school_data_complete_df.head()
49/230:
# Calculate the Totals (Schools and Students)
school_count = len(school_data_complete_df["school_name"].unique())
student_count = school_data_complete_df["Student ID"].count()

# Calculate the Total Budget
total_budget = school_data_df["budget"].sum()
49/231:
# Calculate the Average Scores using the "clean_student_data".
average_reading_score = school_data_complete_df["reading_score"].mean()
average_math_score = school_data_complete_df["math_score"].mean()
49/232:
# Step 1. Get the number of students that are in ninth grade at Thomas High School.
# These students have no grades. 

ninth_grades_student_count = len(student_data_df.loc[(student_data_df["school_name"] == "Thomas High School") & (student_data_df["grade"] == "9th")])


# Get the total student count 
student_count = school_data_complete_df["Student ID"].count()


# Step 2. Subtract the number of students that are in ninth grade at 
# Thomas High School from the total student count to get the new total student count.
new_total_student_count = (student_count - ninth_grades_student_count)
49/233:
# Calculate the passing rates using the "clean_student_data".
passing_math_count = school_data_complete_df[(school_data_complete_df["math_score"] >= 70)].count()["student_name"]
passing_reading_count = school_data_complete_df[(school_data_complete_df["reading_score"] >= 70)].count()["student_name"]
49/234:
# Step 3. Calculate the passing percentages with the new total student count.
passing_math_percentage = passing_math_count/float(new_total_student_count) *100
passing_reading_percentage = passing_reading_count/float(new_total_student_count) *100
49/235:
# Calculate the students who passed both reading and math.
passing_math_reading = school_data_complete_df[(school_data_complete_df["math_score"] >= 70)
                                               & (school_data_complete_df["reading_score"] >= 70)]

# Calculate the number of students that passed both reading and math.
overall_passing_math_reading_count = passing_math_reading["student_name"].count()


# Step 4.Calculate the overall passing percentage with new total student count.
overall_passing_percentage= overall_passing_math_reading_count/new_total_student_count*100
overall_passing_percentage
49/236:
# Create a DataFrame
district_summary_df = pd.DataFrame(
          [{"Total Schools": school_count, 
          "Total Students": student_count, 
          "Total Budget": total_budget,
          "Average Math Score": average_math_score, 
          "Average Reading Score": average_reading_score,
          "% Passing Math": passing_math_percentage,
         "% Passing Reading": passing_reading_percentage,
        "% Overall Passing": overall_passing_percentage}])



# Format the "Total Students" to have the comma for a thousands separator.
district_summary_df["Total Students"] = district_summary_df["Total Students"].map("{:,}".format)
# Format the "Total Budget" to have the comma for a thousands separator, a decimal separator and a "$".
district_summary_df["Total Budget"] = district_summary_df["Total Budget"].map("${:,.2f}".format)
# Format the columns.
district_summary_df["Average Math Score"] = district_summary_df["Average Math Score"].map("{:.1f}".format)
district_summary_df["Average Reading Score"] = district_summary_df["Average Reading Score"].map("{:.1f}".format)
district_summary_df["% Passing Math"] = district_summary_df["% Passing Math"].map("{:.1f}".format)
district_summary_df["% Passing Reading"] = district_summary_df["% Passing Reading"].map("{:.1f}".format)
district_summary_df["% Overall Passing"] = district_summary_df["% Overall Passing"].map("{:.1f}".format)

# Display the data frame
district_summary_df
49/237:
# Determine the School Type
per_school_types = school_data_df.set_index(["school_name"])["type"]

# Calculate the total student count.
per_school_counts = school_data_complete_df["school_name"].value_counts()

# Calculate the total school budget and per capita spending
per_school_budget = school_data_complete_df.groupby(["school_name"]).mean()["budget"]
# Calculate the per capita spending.
per_school_capita = per_school_budget / per_school_counts

# Calculate the average test scores.
per_school_math = school_data_complete_df.groupby(["school_name"]).mean()["math_score"]
per_school_reading = school_data_complete_df.groupby(["school_name"]).mean()["reading_score"]

# Calculate the passing scores by creating a filtered DataFrame.
per_school_passing_math = school_data_complete_df[(school_data_complete_df["math_score"] >= 70)]
per_school_passing_reading = school_data_complete_df[(school_data_complete_df["reading_score"] >= 70)]

# Calculate the number of students passing math and passing reading by school.
per_school_passing_math = per_school_passing_math.groupby(["school_name"]).count()["student_name"]
per_school_passing_reading = per_school_passing_reading.groupby(["school_name"]).count()["student_name"]

# Calculate the percentage of passing math and reading scores per school.
per_school_passing_math = per_school_passing_math / per_school_counts * 100
per_school_passing_reading = per_school_passing_reading / per_school_counts * 100

# Calculate the students who passed both reading and math.
per_passing_math_reading = school_data_complete_df[(school_data_complete_df["reading_score"] >= 70)
                                               & (school_data_complete_df["math_score"] >= 70)]

# Calculate the number of students passing math and passing reading by school.
per_passing_math_reading = per_passing_math_reading.groupby(["school_name"]).count()["student_name"]

# Calculate the percentage of passing math and reading scores per school.
per_overall_passing_percentage = per_passing_math_reading / per_school_counts * 100
49/238:
# Create the DataFrame
per_school_summary_df = pd.DataFrame({
    "School Type": per_school_types,
    "Total Students": per_school_counts,
    "Total School Budget": per_school_budget,
    "Per Student Budget": per_school_capita,
    "Average Math Score": per_school_math,
    "Average Reading Score": per_school_reading,
    "% Passing Math": per_school_passing_math,
    "% Passing Reading": per_school_passing_reading,
    "% Overall Passing": per_overall_passing_percentage})


per_school_summary_df.head()
49/239:
# Format the Total School Budget and the Per Student Budget
per_school_summary_df["Total School Budget"] = per_school_summary_df["Total School Budget"].map("${:,.2f}".format)
per_school_summary_df["Per Student Budget"] = per_school_summary_df["Per Student Budget"].map("${:,.2f}".format)

# Display the data frame
per_school_summary_df
49/240:
# Step 5.  Get the number of 10th-12th graders from Thomas High School (THS).

tenth_grades_student_count = student_data_df.loc[(student_data_df["school_name"] == "Thomas High School") & (student_data_df["grade"] == "10th")]
twelveth_grade_student_count =  student_data_df.loc[(student_data_df["school_name"] == "Thomas High School") & (student_data_df["grade"] == "12th")]
eleventh_grade_student_count =  student_data_df.loc[(student_data_df["school_name"] == "Thomas High School") & (student_data_df["grade"] == "11th")]
total_number_10thto12th_graders_count= (len(tenth_grades_student_count)+ len(twelveth_grade_student_count) + len(eleventh_grade_student_count))
total_number_10thto12th_graders_count
49/241:
# Step 6. Get all the students passing math from THS
student_passing_math_ths = school_data_complete_df.loc[(student_data_df["school_name"]=="Thomas High School")&(student_data_df["math_score"] >=70)]
49/242:
# Step 7. Get all the students passing reading from THS
student_passing_reading_ths = school_data_complete_df.loc[(student_data_df["school_name"]=="Thomas High School")&(student_data_df["reading_score"] >=70)]
49/243:
# Step 8. Get all the students passing math and reading from THS
student_passing_math_reading_ths = school_data_complete_df.loc[(student_data_df["school_name"]=="Thomas High School")
                                                               &(student_data_df["math_score"] >=70)
                                                               & (student_data_df["reading_score"] >= 70)]
student_passing_math_reading_ths.head()
49/244:
# Step 9. Calculate the percentage of 10th-12th grade students passing math from Thomas High School. 
student_passing_math_ths_count = len(student_passing_math_ths)
student_passing_math_ths_percentage = student_passing_math_ths_count /total_number_10thto12th_graders_count*100
49/245:
# Step 10. Calculate the percentage of 10th-12th grade students passing reading from Thomas High School.
student_passing_reading_ths_count = len(student_passing_reading_ths)
student_passing_reading_ths_percentage = student_passing_reading_ths_count /total_number_10thto12th_graders_count*100
49/246:
# Step 11. Calculate the overall passing percentage of 10th-12th grade from Thomas High School. 
student_passing_overall_ths_count = len(student_passing_math_reading_ths)
student_passing_overall_ths_percentage = student_passing_overall_ths_count /total_number_10thto12th_graders_count*100
49/247:
# Step 12. Replace the passing math percent for Thomas High School in the per_school_summary_df.
per_school_summary_df.loc["Thomas High School", "% Passing Math"] = student_passing_math_ths_percentage
49/248:
# Step 13. Replace the passing reading percentage for Thomas High School in the per_school_summary_df.
per_school_summary_df.loc["Thomas High School", "% Passing Reading"] = student_passing_reading_ths_percentage
49/249:
# Step 14. Replace the overall passing percentage for Thomas High School in the per_school_summary_df.
per_school_summary_df.loc["Thomas High School", "% Overall Passing"] = student_passing_overall_ths_percentage
49/250: per_school_summary_df
49/251:
# Sort and show top five schools.
# Sort and show top five schools.
top_schools = per_school_summary_df.sort_values(["% Overall Passing"], ascending=False)
top_schools.head()
49/252:
# Sort and show bottom five schools.
bottom_schools = per_school_summary_df.sort_values(["% Overall Passing"], ascending=True)
bottom_schools.head()
49/253:
# Create a Series of scores by grade levels using conditionals.
ninth_grades_students = school_data_complete_df[(school_data_complete_df["grade"] =="9th")]
tenth_grades_students = school_data_complete_df[(school_data_complete_df["grade"] =="10th")]
eleventh_grades_students = school_data_complete_df[(school_data_complete_df["grade"] =="11th")]
twelfth_grades_students = school_data_complete_df[(school_data_complete_df["grade"] =="12th")]

# Group each school Series by the school name for the average math score.
ninth_grade_math_scores = ninth_grades_students.groupby(["school_name"]).mean()["math_score"]
tenth_grade_math_scores = tenth_grades_students.groupby(["school_name"]).mean()["math_score"]
eleventh_grade_math_scores = eleventh_grades_students.groupby(["school_name"]).mean()["math_score"]
twelfth_grade_math_scores = twelfth_grades_students.groupby(["school_name"]).mean()["math_score"]

# Group each school Series by the school name for the average reading score.
ninth_grade_reading_scores = ninth_grades_students.groupby(["school_name"]).mean()["reading_score"]
tenth_grade_reading_scores = tenth_grades_students.groupby(["school_name"]).mean()["reading_score"]
eleventh_grade_reading_scores = eleventh_grades_students.groupby(["school_name"]).mean()["reading_score"]
twelfth_grade_reading_scores = twelfth_grades_students.groupby(["school_name"]).mean()["reading_score"]
49/254:
# Combine each Series for average math scores by school into single data frame.
math_scores_by_grade = pd.DataFrame({
    "9th": ninth_grade_math_scores,
    "10th": tenth_grade_math_scores,
    "11th": eleventh_grade_math_scores,
    "12th": twelfth_grade_math_scores})
49/255:
# Combine each Series for average reading scores by school into single data frame.
reading_scores_by_grade = pd.DataFrame({
    "9th": ninth_grade_reading_scores,
    "10th": tenth_grade_reading_scores,
    "11th": eleventh_grade_reading_scores,
    "12th": twelfth_grade_reading_scores})
49/256:
# Format each grade column.
# Format each grade column for math
math_scores_by_grade["9th"] = math_scores_by_grade["9th"].map("{:.1f}".format)
math_scores_by_grade["10th"] = math_scores_by_grade["10th"].map("{:.1f}".format)
math_scores_by_grade["11th"] = math_scores_by_grade["11th"].map("{:.1f}".format)
math_scores_by_grade["12th"] = math_scores_by_grade["12th"].map("{:.1f}".format)
# Put in order
math_scores_by_grade = math_scores_by_grade[["9th", "10th", "11th", "12th"]]

# Format each grade column for reading.
reading_scores_by_grade["9th"] = reading_scores_by_grade["9th"].map("{:.1f}".format)
reading_scores_by_grade["10th"] = reading_scores_by_grade["10th"].map("{:.1f}".format)
reading_scores_by_grade["11th"] = reading_scores_by_grade["11th"].map("{:.1f}".format)
reading_scores_by_grade["12th"] = reading_scores_by_grade["12th"].map("{:.1f}".format)
# Put in order
reading_scores_by_grade = reading_scores_by_grade[["9th", "10th", "11th", "12th"]]
49/257:
# Remove the index.for math score
math_scores_by_grade.index.name = None

# Display the data frame
math_scores_by_grade
49/258:
## Remove the index.
reading_scores_by_grade.index.name = None

# Display the data frame
reading_scores_by_grade
49/259:
# Establish the spending bins and group names.

per_school_capita.describe()
spending_bins=[0,585,630,645,675]
group_names=["<$584","$585-629", "$630-644", "$645-675"]
per_school_capita.groupby(pd.cut(per_school_capita, spending_bins)).count()

# Categorize spending based on the bins.
per_school_summary_df["Spending Ranges (Per Student)"]=pd.cut(per_school_capita, spending_bins, labels=group_names)
per_school_summary_df
49/260:
# Calculate averages for the desired columns. 
spending_math_scores = per_school_summary_df.groupby(["Spending Ranges (Per Student)"]).mean()["Average Math Score"]
spending_reading_scores = per_school_summary_df.groupby(["Spending Ranges (Per Student)"]).mean()["Average Reading Score"]
spending_passing_math = per_school_summary_df.groupby(["Spending Ranges (Per Student)"]).mean()["% Passing Math"]
spending_passing_reading = per_school_summary_df.groupby(["Spending Ranges (Per Student)"]).mean()["% Passing Reading"]
overall_passing_spending = per_school_summary_df.groupby(["Spending Ranges (Per Student)"]).mean()["% Overall Passing"]
49/261:
# Create the DataFrame
spending_summary_df = pd.DataFrame({
    "Average Math Score": spending_math_scores,
    "Average Reading Score": spending_reading_scores,
    "% Passing Math": spending_passing_math,
    "% Passing Reading": spending_passing_reading,
    "% Overall Passing": overall_passing_spending})
49/262:
# Format the DataFrame 
spending_summary_df["Average Math Score"] = spending_summary_df["Average Math Score"].map("{:.1f}".format)
spending_summary_df["Average Reading Score"] = spending_summary_df["Average Reading Score"].map("{:.1f}".format)
spending_summary_df["% Passing Math"] = spending_summary_df["% Passing Math"].map("{:.0f}".format)
spending_summary_df["% Passing Reading"] = spending_summary_df["% Passing Reading"].map("{:.0f}".format)
spending_summary_df["% Overall Passing"] = spending_summary_df["% Overall Passing"].map("{:.1f}".format)
spending_summary_df
49/263:
# Establish the bins.
size_bins = [0, 1000, 2000, 5000]
group_names = ["Small (<1000)", "Medium (1000-2000)", "Large(2000-5000)"]
# Categorize spending based on the bins.
per_school_summary_df["School Size"] = pd.cut(per_school_summary_df["Total Students"], size_bins, labels=group_names)
49/264:
# Calculate averages for the desired columns. 
size_math_scores = per_school_summary_df.groupby(["School Size"]).mean()["Average Math Score"]
size_reading_scores = per_school_summary_df.groupby(["School Size"]).mean()["Average Reading Score"]
size_passing_math = per_school_summary_df.groupby(["School Size"]).mean()["% Passing Math"]
size_passing_reading = per_school_summary_df.groupby(["School Size"]).mean()["% Passing Reading"]
size_overall_passing = per_school_summary_df.groupby(["School Size"]).mean()["% Overall Passing"]
49/265:
# Assemble into DataFrame. 
size_summary_df = pd.DataFrame({
    "Average Math Score": size_math_scores,
    "Average Reading Score": size_reading_scores,
    "% Passing Math": size_passing_math,
    "% Passing Reading": size_passing_reading,
    "% Overall Passing": size_overall_passing})
49/266:
# Format the DataFrame  
size_summary_df["Average Math Score"] = size_summary_df["Average Math Score"].map("{:.1f}".format)
size_summary_df["Average Reading Score"] = size_summary_df["Average Reading Score"].map("{:.1f}".format)
size_summary_df["% Passing Math"] = size_summary_df["% Passing Math"].map("{:.0f}".format)
size_summary_df["% Passing Reading"] = size_summary_df["% Passing Reading"].map("{:.0f}".format)
size_summary_df["% Overall Passing"] = size_summary_df["% Overall Passing"].map("{:.0f}".format)
size_summary_df
49/267:
# Calculate averages for the desired columns. 
type_math_scores = per_school_summary_df.groupby(["School Type"]).mean()["Average Math Score"]
type_reading_scores = per_school_summary_df.groupby(["School Type"]).mean()["Average Reading Score"]
type_passing_math = per_school_summary_df.groupby(["School Type"]).mean()["% Passing Math"]
type_passing_reading = per_school_summary_df.groupby(["School Type"]).mean()["% Passing Reading"]
type_overall_passing = per_school_summary_df.groupby(["School Type"]).mean()["% Overall Passing"]
49/268:
# Assemble into DataFrame. 
type_summary_df = pd.DataFrame({
    "Average Math Score": type_math_scores,
    "Average Reading Score": type_reading_scores,
    "% Passing Math": type_passing_math,
    "% Passing Reading": type_passing_reading,
    "% Overall Passing": type_overall_passing})
49/269:
# # Format the DataFrame 
type_summary_df["Average Math Score"] = type_summary_df["Average Math Score"].map("{:.1f}".format)
type_summary_df["Average Reading Score"] = type_summary_df["Average Reading Score"].map("{:.1f}".format)
type_summary_df["% Passing Math"] = type_summary_df["% Passing Math"].map("{:.0f}".format)
type_summary_df["% Passing Reading"] = type_summary_df["% Passing Reading"].map("{:.0f}".format)
type_summary_df["% Overall Passing"] = type_summary_df["% Overall Passing"].map("{:.0f}".format)
type_summary_df
44/828:
# Add the Pandas dependency.
import pandas as pd
44/829:
school_data_to_load = "Resources/schools_complete.csv"
student_data_to_load = "Resources/students_complete.csv"
44/830:
# Read the school data file and store it in a Pandas DataFrame.
school_data_df = pd.read_csv(school_data_to_load)
school_data_df
44/831:
# Read the student data file and store it in a Pandas DataFrame.
student_data_df = pd.read_csv(student_data_to_load)
student_data_df.head()
44/832:
# Determine if there are any missing values in the school data.
school_data_df.count()
44/833:
# Determine if there are any missing values in the student data.
student_data_df.count()
44/834: school_data_df.isnull()
44/835: student_data_df.isnull().sum()
44/836: student_data_df.notnull().sum()
44/837:
#Determin data types for the student DataFrame
school_data_df.dtypes
44/838:
# Determine data types for the student DataFrame.
student_data_df.dtypes
44/839:
# Read the school data file and store it in a Pandas DataFrame.
school_data_df= pd.read_csv(school_data_to_load)
school_data_df
44/840:
# Read the student data file and store it in a Pandas DataFrame.
student_data_df = pd.read_csv(student_data_to_load)
student_data_df.head()
44/841:
# Add each prefix and suffix to remove to a list.
prefixes_suffixes = ["Dr. ", "Mr. ","Ms. ", "Mrs. ", "Miss ", " MD", " DDS", " DVM", " PhD"]
44/842:
# Iterate through the words in the "prefixes_suffixes" list and replace them with an empty space, "".
for word in prefixes_suffixes:
    student_data_df["student_name"]= student_data_df["student_name"].str.replace(word,"",regex =True )
    print(student_data_df.head())
44/843:
# Combine the data into a single dataset.
school_data_complete_df = pd.merge(student_data_df, school_data_df, on=["school_name", "school_name"])
school_data_complete_df.head()
44/844:
#Get the total number of students
#student_count = school_data_complete_df.count()
student_count =school_data_complete_df["Student ID"].count()
student_count
44/845:
#Calculate the total number of schools
school_count=school_data_df["school_name"].count()
school_count
44/846:
# Calculate the total number of schools
school_count_2 = school_data_complete_df["school_name"].unique()
school_count_2
44/847:
#Running the code: 
#len(school_data_complete_df["school_name"].unique())
44/848:
# Calculate the total budget.
total_budget = school_data_df["budget"].sum()
total_budget
44/849:
#Calculate the average reading score
average_reading_score = school_data_complete_df["reading_score"].mean()
average_reading_score
44/850:
# Calculate the average math score.
average_math_score = school_data_complete_df["math_score"].mean()
average_math_score
44/851:
#Determine the passing grade
passing_math = school_data_complete_df["math_score"] >= 70
passing_math.head()
44/852:
passing_reading = school_data_complete_df["reading_score"] >= 70
passing_reading
44/853:
passing_math = school_data_complete_df[school_data_complete_df["math_score"] >= 70]
passing_math.head()
44/854:
# Get all the students that are passing reading in a new DataFrame.
passing_reading = school_data_complete_df[school_data_complete_df["reading_score"] >= 70]
passing_reading.head()
44/855:
# Calculate the number of students passing math.
passing_math_count = passing_math["student_name"].count()
print(passing_math_count)
# Calculate the number of students passing reading.
passing_reading_count = passing_reading["student_name"].count()
print(passing_reading_count)
44/856:
# Calculate the percent that passed math.
passing_math_percentage=passing_math_count / float(student_count) * 100
# Calculate the percent that passed reading.
passing_reading_percentage=passing_reading_count / float(student_count) * 100
print(passing_math_percentage)
print(passing_reading_percentage)
44/857:
# Calculate the students who passed both math and reading.
passing_math_reading = school_data_complete_df[(school_data_complete_df["math_score"] >= 70) & (school_data_complete_df["reading_score"] >= 70)]

passing_math_reading.head()
44/858:
# Calculate the number of students who passed both math and reading.
overall_passing_math_reading_count = passing_math_reading["student_name"].count()
44/859:
# Calculate the overall passing percentage.
overall_passing_percentage = overall_passing_math_reading_count / student_count * 100
overall_passing_percentage
44/860:
# Adding a list of values with keys to create a new DataFrame.
district_summary_df = pd.DataFrame(
          [{"Total Schools": school_count,
          "Total Students": student_count,
          "Total Budget": total_budget,
          "Average Math Score": average_math_score,
          "Average Reading Score": average_reading_score,
          "% Passing Math": passing_math_percentage,
         "% Passing Reading": passing_reading_percentage,
        "% Overall Passing": overall_passing_percentage}])
district_summary_df
44/861:
# Define a function that calculates the percentage of students that passed both 
# math and reading and returns the passing percentage when the function is called.

def passing_math_percent(pass_math_count, student_count):
    return pass_math_count / float(student_count) * 100
44/862:
passing_math_count = 29370
total_student_count = 39170
44/863: passing_math_percent(passing_math_count, total_student_count)
44/864:
# Format the "Total Students" to have the comma for a thousands separator.
district_summary_df["Total Students"] = district_summary_df["Total Students"].map("{:,}".format)

district_summary_df["Total Students"]
44/865:
district_summary_df["Total Budget"] = district_summary_df["Total Budget"].map("${:,.2f}".format)

district_summary_df["Total Budget"]
44/866:
# Format the columns.

district_summary_df["Average Math Score"] = district_summary_df["Average Math Score"].map("{:.1f}".format)

district_summary_df["Average Reading Score"] = district_summary_df["Average Reading Score"].map("{:,.1f}".format)

district_summary_df["% Passing Math"] = district_summary_df["% Passing Math"].map("{:.0f}".format)

district_summary_df["% Passing Reading"] = district_summary_df["% Passing Reading"].map("{:.0f}".format)

district_summary_df["% Overall Passing"] = district_summary_df["% Overall Passing"].map("{:.0f}".format)
44/867:
#Display the DataFrame
district_summary_df
44/868:
# Determine the school type.
per_school_types = school_data_df.set_index(["school_name"])["type"]
per_school_types
44/869:
# Add the per_school_types into a DataFrame for testing.
df = pd.DataFrame(per_school_types)
df
44/870:
# Calculate the total student count.
per_school_counts = school_data_df["size"]
per_school_counts
44/871:
# Calculate the total student count.
per_school_counts = school_data_df.set_index(["school_name"])["size"]
per_school_counts
44/872:
# Calculate the total student count.
per_school_counts = school_data_complete_df["school_name"].value_counts()
per_school_counts
44/873:
# Calculate the total school budget.
per_school_budget = school_data_df.set_index(["school_name"])["budget"]
per_school_budget
44/874:
# Calculate the per capita spending.
per_school_capita = per_school_budget / per_school_counts
per_school_capita
44/875:
# Calculate the math scores.
student_school_math = student_data_df.set_index(["school_name"])["math_score"]
student_school_math
44/876:
# Calculate the average math scores.
per_school_averages = school_data_complete_df.groupby(["school_name"]).mean()
per_school_averages
44/877:
# Calculate the average test scores.
per_school_math = school_data_complete_df.groupby(["school_name"]).mean()["math_score"]

per_school_reading = school_data_complete_df.groupby(["school_name"]).mean()["reading_score"]
44/878:
#Print the average test scores
per_school_math
44/879: per_school_reading
44/880:
# Calculate the passing scores by creating a filtered DataFrame.
per_school_passing_math = school_data_complete_df[(school_data_complete_df["math_score"] >= 70)]

per_school_passing_reading = school_data_complete_df[(school_data_complete_df["reading_score"] >= 70)]
44/881: per_school_passing_math.head()
44/882: per_school_passing_reading.head()
44/883:
# Calculate the number of students passing math and passing reading by school.
per_school_passing_math = per_school_passing_math.groupby(["school_name"]).count()["student_name"]

per_school_passing_reading = per_school_passing_reading.groupby(["school_name"]).count()["student_name"]
44/884: per_school_passing_math
44/885: per_school_passing_reading
44/886:
# Calculate the percentage of passing math and reading scores per school.
per_school_passing_math = per_school_passing_math / per_school_counts * 100

per_school_passing_reading = per_school_passing_reading / per_school_counts * 100
44/887: per_school_passing_math
44/888: per_school_passing_reading
44/889:
# Calculate the students who passed both math and reading.
per_passing_math_reading = school_data_complete_df[(school_data_complete_df["math_score"] >= 70) & (school_data_complete_df["reading_score"] >= 70)]

per_passing_math_reading.head()
44/890:
# Calculate the number of students who passed both math and reading.
per_passing_math_reading = per_passing_math_reading.groupby(["school_name"]).count()["student_name"]
44/891:
# Calculate the overall passing percentage.
per_overall_passing_percentage = per_passing_math_reading / per_school_counts * 100
44/892: per_overall_passing_percentage
44/893:
# Adding a list of values with keys to create a new DataFrame.

per_school_summary_df = pd.DataFrame({
             "School Type": per_school_types,
             "Total Students": per_school_counts,
             "Total School Budget": per_school_budget,
             "Per Student Budget": per_school_capita,
             "Average Math Score": per_school_math,
           "Average Reading Score": per_school_reading,
           "% Passing Math": per_school_passing_math,
           "% Passing Reading": per_school_passing_reading,
           "% Overall Passing": per_overall_passing_percentage})
per_school_summary_df.head()
44/894:
# Format the Total School Budget and the Per Student Budget columns.
per_school_summary_df["Total School Budget"] = per_school_summary_df["Total School Budget"].map("${:,.2f}".format)

per_school_summary_df["Per Student Budget"] = per_school_summary_df["Per Student Budget"].map("${:,.2f}".format)


# Display the data frame
per_school_summary_df.head()
44/895:
# Reorder the columns in the order you want them to appear.
new_column_order = ["School Type", "Total Students", "Total School Budget", "Per Student Budget", "Average Math Score", "Average Reading Score", "% Passing Math", "% Passing Reading", "% Overall Passing"]

# Assign district summary df the new column order.
per_school_summary_df = per_school_summary_df[new_column_order]

per_school_summary_df.head()
44/896:
# Sort and show top five schools.
top_schools = per_school_summary_df.sort_values(["% Overall Passing"], ascending=False)

top_schools.head()
44/897:
# Sort and show top five schools.
bottom_schools = per_school_summary_df.sort_values(["% Overall Passing"], ascending=True)

bottom_schools.head()
44/898:
# Create a grade level DataFrames.
ninth_graders = school_data_complete_df[(school_data_complete_df["grade"] == "9th")]

tenth_graders = school_data_complete_df[(school_data_complete_df["grade"] == "10th")]

eleventh_graders = school_data_complete_df[(school_data_complete_df["grade"] == "11th")]

twelfth_graders = school_data_complete_df[(school_data_complete_df["grade"] == "12th")]
44/899: ninth_graders.head()
44/900: tenth_graders.head()
44/901:
# Group each grade level DataFrame by the school name for the average math score.
ninth_grade_math_scores = ninth_graders.groupby(["school_name"]).mean()["math_score"]

tenth_grade_math_scores = tenth_graders.groupby(["school_name"]).mean()["math_score"]

eleventh_grade_math_scores = eleventh_graders.groupby(["school_name"]).mean()["math_score"]

twelfth_grade_math_scores = twelfth_graders.groupby(["school_name"]).mean()["math_score"]
44/902: ninth_grade_math_scores
44/903: eleventh_grade_math_scores
44/904:
# Group each grade level DataFrame by the school name for the average reading score.
ninth_grade_reading_scores = ninth_graders.groupby(["school_name"]).mean()["reading_score"]

tenth_grade_reading_scores = tenth_graders.groupby(["school_name"]).mean()["reading_score"]

eleventh_grade_reading_scores = eleventh_graders.groupby(["school_name"]).mean()["reading_score"]

twelfth_grade_reading_scores = twelfth_graders.groupby(["school_name"]).mean()["reading_score"]
44/905: ninth_grade_reading_scores
44/906: twelfth_grade_reading_scores
44/907:
# Combine each grade level Series for average math scores by school into a single DataFrame.
math_scores_by_grade = pd.DataFrame({
               "9th": ninth_grade_math_scores,
               "10th": tenth_grade_math_scores,
               "11th": eleventh_grade_math_scores,
               "12th": twelfth_grade_math_scores})

math_scores_by_grade.head
44/908:
# Combine each grade level Series for average reading scores by school into a single DataFrame.
reading_scores_by_grade = pd.DataFrame({
              "9th": ninth_grade_reading_scores,
              "10th": tenth_grade_reading_scores,
              "11th": eleventh_grade_reading_scores,
              "12th": twelfth_grade_reading_scores})

reading_scores_by_grade.head()
44/909:
# Format each grade column.

math_scores_by_grade["9th"] = math_scores_by_grade["9th"].map("{:.1f}".format)

math_scores_by_grade["10th"] = math_scores_by_grade["10th"].map("{:.1f}".format)

math_scores_by_grade["11th"] = math_scores_by_grade["11th"].map("{:.1f}".format)

math_scores_by_grade["12th"] = math_scores_by_grade["12th"].map("{:.1f}".format)

# Make sure the columns are in the correct order.
math_scores_by_grade = math_scores_by_grade[["9th", "10th", "11th", "12th"]]

# Remove the index name.
math_scores_by_grade.index.name = None
# Display the DataFrame.
math_scores_by_grade.head()
44/910:
# Format each grade column.
reading_scores_by_grade["9th"] = reading_scores_by_grade["9th"].map("{:,.1f}".format)

reading_scores_by_grade["10th"] = reading_scores_by_grade["10th"].map("{:,.1f}".format)

reading_scores_by_grade["11th"] = reading_scores_by_grade["11th"].map("{:,.1f}".format)

reading_scores_by_grade["12th"] = reading_scores_by_grade["12th"].map("{:,.1f}".format)

# Make sure the columns are in the correct order.
reading_scores_by_grade = reading_scores_by_grade[
        ["9th", "10th", "11th", "12th"]]
# Remove the index name.
reading_scores_by_grade.index.name = None
# Display the data frame.
reading_scores_by_grade.head()
44/911:
# Get the descriptive statistics for the per_school_capita.
per_school_capita.describe()
44/912:
# Cut the per_school_capita into the spending ranges.
spending_bins = [0, 585, 615, 645, 675]
pd.cut(per_school_capita, spending_bins)
44/913:
# Cut the per_school_capita into the spending ranges.
spending_bins = [585, 615, 645, 675]
pd.cut(per_school_capita, spending_bins)
44/914:
# Cut the per_school_capita into the spending ranges.
spending_bins = [0, 585, 615, 645, 675]
per_school_capita.groupby(pd.cut(per_school_capita, spending_bins)).count()
44/915:
# Cut the per_school_capita into the spending ranges.
spending_bins = [0, 585, 630, 645, 675]
per_school_capita.groupby(pd.cut(per_school_capita, spending_bins)).count()
44/916:
# Establish the spending bins and group names.
spending_bins = [0, 585, 630, 645, 675]
group_names = ["<$586", "$586-630", "$631-645", "$646-675"]
44/917:
# Categorize spending based on the bins.
per_school_summary_df["Spending Ranges (Per Student)"] = pd.cut(per_school_capita, spending_bins, labels=group_names)

per_school_summary_df
44/918:
# Calculate averages for the desired columns.
spending_math_scores = per_school_summary_df.groupby(["Spending Ranges (Per Student)"]).mean()["Average Math Score"]

spending_reading_scores = per_school_summary_df.groupby(["Spending Ranges (Per Student)"]).mean()["Average Reading Score"]

spending_passing_math = per_school_summary_df.groupby(["Spending Ranges (Per Student)"]).mean()["% Passing Math"]

spending_passing_reading = per_school_summary_df.groupby(["Spending Ranges (Per Student)"]).mean()["% Passing Reading"]

overall_passing_spending = per_school_summary_df.groupby(["Spending Ranges (Per Student)"]).mean()["% Overall Passing"]
44/919: overall_passing_spending
44/920:
# Assemble into DataFrame.
spending_summary_df = pd.DataFrame({
          "Average Math Score" : spending_math_scores,
          "Average Reading Score": spending_reading_scores,
          "% Passing Math": spending_passing_math,
          "% Passing Reading": spending_passing_reading,
          "% Overall Passing": overall_passing_spending})

spending_summary_df
44/921:
# Formatting
spending_summary_df["Average Math Score"] = spending_summary_df["Average Math Score"].map("{:.1f}".format)

spending_summary_df["Average Reading Score"] = spending_summary_df["Average Reading Score"].map("{:.1f}".format)

spending_summary_df["% Passing Math"] = spending_summary_df["% Passing Math"].map("{:.0f}".format)

spending_summary_df["% Passing Reading"] = spending_summary_df["% Passing Reading"].map("{:.0f}".format)

spending_summary_df["% Overall Passing"] = spending_summary_df["% Overall Passing"].map("{:.0f}".format)

spending_summary_df
44/922:
# Establish the bins.
size_bins = [0, 999, 1999, 5000]
group_names = ["Small (<1000)", "Medium (1000-1999)", "Large (2000-5000)"]
44/923:
# Categorize spending based on the bins.
per_school_summary_df["School Size"] = pd.cut(per_school_summary_df["Total Students"], size_bins, labels=group_names)

per_school_summary_df.head()
44/924:
# Calculate averages for the desired columns.
size_math_scores = per_school_summary_df.groupby(["School Size"]).mean()["Average Math Score"]

size_reading_scores = per_school_summary_df.groupby(["School Size"]).mean()["Average Reading Score"]

size_passing_math = per_school_summary_df.groupby(["School Size"]).mean()["% Passing Math"]

size_passing_reading = per_school_summary_df.groupby(["School Size"]).mean()["% Passing Reading"]

size_overall_passing = per_school_summary_df.groupby(["School Size"]).mean()["% Overall Passing"]
44/925: size_math_scores
44/926:
# Assemble into DataFrame.
size_summary_df = pd.DataFrame({
          "Average Math Score" : size_math_scores,
          "Average Reading Score": size_reading_scores,
          "% Passing Math": size_passing_math,
          "% Passing Reading": size_passing_reading,
          "% Overall Passing": size_overall_passing})

size_summary_df
44/927:
# Formatting.
size_summary_df["Average Math Score"] = size_summary_df["Average Math Score"].map("{:.1f}".format)

size_summary_df["Average Reading Score"] = size_summary_df["Average Reading Score"].map("{:.1f}".format)

size_summary_df["% Passing Math"] = size_summary_df["% Passing Math"].map("{:.0f}".format)

size_summary_df["% Passing Reading"] = size_summary_df["% Passing Reading"].map("{:.0f}".format)

size_summary_df["% Overall Passing"] = size_summary_df["% Overall Passing"].map("{:.0f}".format)

size_summary_df
44/928:
# Calculate averages for the desired columns.
type_math_scores = per_school_summary_df.groupby(["School Type"]).mean()["Average Math Score"]

type_reading_scores = per_school_summary_df.groupby(["School Type"]).mean()["Average Reading Score"]

type_passing_math = per_school_summary_df.groupby(["School Type"]).mean()["% Passing Math"]

type_passing_reading = per_school_summary_df.groupby(["School Type"]).mean()["% Passing Reading"]

type_overall_passing = per_school_summary_df.groupby(["School Type"]).mean()["% Overall Passing"]
44/929:
# Assemble into DataFrame.
type_summary_df = pd.DataFrame({
          "Average Math Score" : type_math_scores,
          "Average Reading Score": type_reading_scores,
          "% Passing Math": type_passing_math,
          "% Passing Reading": type_passing_reading,
          "% Overall Passing": type_overall_passing})

type_summary_df
44/930:
# Formatting
type_summary_df["Average Math Score"] = type_summary_df["Average Math Score"].map("{:.1f}".format)

type_summary_df["Average Reading Score"] = type_summary_df["Average Reading Score"].map("{:.1f}".format)

type_summary_df["% Passing Math"] = type_summary_df["% Passing Math"].map("{:.0f}".format)

type_summary_df["% Passing Reading"] = type_summary_df["% Passing Reading"].map("{:.0f}".format)

type_summary_df["% Overall Passing"] = type_summary_df["% Overall Passing"].map("{:.0f}".format)

type_summary_df
44/931:
# Combine each grade level Series for average math scores by school into a single DataFrame.
math_scores_by_grade = pd.DataFrame({
               "9th": ninth_grade_math_scores,
               "10th": tenth_grade_math_scores,
               "11th": eleventh_grade_math_scores,
               "12th": twelfth_grade_math_scores})

math_scores_by_grade
44/932:
# Combine each grade level Series for average reading scores by school into a single DataFrame.
reading_scores_by_grade = pd.DataFrame({
              "9th": ninth_grade_reading_scores,
              "10th": tenth_grade_reading_scores,
              "11th": eleventh_grade_reading_scores,
              "12th": twelfth_grade_reading_scores})

reading_scores_by_grade
44/933:
# Combine each grade level Series for average reading scores by school into a single DataFrame.
reading_scores_by_grade = pd.DataFrame({
              "9th": ninth_grade_reading_scores,
              "10th": tenth_grade_reading_scores,
              "11th": eleventh_grade_reading_scores,
              "12th": twelfth_grade_reading_scores})

reading_scores_by_grade
49/270:
# Create the DataFrame
spending_summary_df = pd.DataFrame({
    "Average Math Score": spending_math_scores,
    "Average Reading Score": spending_reading_scores,
    "% Passing Math": spending_passing_math,
    "% Passing Reading": spending_passing_reading,
    "% Overall Passing": overall_passing_spending}) 
spending_summary_df
49/271:
# Assemble into DataFrame. 
size_summary_df = pd.DataFrame({
    "Average Math Score": size_math_scores,
    "Average Reading Score": size_reading_scores,
    "% Passing Math": size_passing_math,
    "% Passing Reading": size_passing_reading,
    "% Overall Passing": size_overall_passing})
size_summary_df
49/272:
# Assemble into DataFrame. 
type_summary_df = pd.DataFrame({
    "Average Math Score": type_math_scores,
    "Average Reading Score": type_reading_scores,
    "% Passing Math": type_passing_math,
    "% Passing Reading": type_passing_reading,
    "% Overall Passing": type_overall_passing})
type_summary_df
49/273:
# Assemble into DataFrame. 
type_summary_df = pd.DataFrame({
    "Average Math Score": type_math_scores,
    "Average Reading Score": type_reading_scores,
    "% Passing Math": type_passing_math,
    "% Passing Reading": type_passing_reading,
    "% Overall Passing": type_overall_passing})
49/274:
# Assemble into DataFrame. 
size_summary_df = pd.DataFrame({
    "Average Math Score": size_math_scores,
    "Average Reading Score": size_reading_scores,
    "% Passing Math": size_passing_math,
    "% Passing Reading": size_passing_reading,
    "% Overall Passing": size_overall_passing})
49/275:
# Create the DataFrame
spending_summary_df = pd.DataFrame({
    "Average Math Score": spending_math_scores,
    "Average Reading Score": spending_reading_scores,
    "% Passing Math": spending_passing_math,
    "% Passing Reading": spending_passing_reading,
    "% Overall Passing": overall_passing_spending})
49/276:
# Format the Total School Budget and the Per Student Budget
per_school_summary_df["Total School Budget"] = per_school_summary_df["Total School Budget"].map("${:,.2f}".format)
per_school_summary_df["Per Student Budget"] = per_school_summary_df["Per Student Budget"].map("${:,.2f}".format)

# Display the data frame
#per_school_summary_df
49/277:
# Format the Total School Budget and the Per Student Budget
per_school_summary_df["Total School Budget"] = per_school_summary_df["Total School Budget"].map("${:,.2f}".format)
per_school_summary_df["Per Student Budget"] = per_school_summary_df["Per Student Budget"].map("${:,.2f}".format)

# Display the data frame
per_school_summary_df
49/278:
# Dependencies and Setup
import pandas as pd

# File to Load (Remember to change the path if needed.)
school_data_to_load = "Resources/schools_complete.csv"
student_data_to_load = "Resources/students_complete.csv"

# Read the School Data and Student Data and store into a Pandas DataFrame
school_data_df = pd.read_csv(school_data_to_load)
student_data_df = pd.read_csv(student_data_to_load)

# Cleaning Student Names and Replacing Substrings in a Python String
# Add each prefix and suffix to remove to a list.
prefixes_suffixes = ["Dr. ", "Mr. ","Ms. ", "Mrs. ", "Miss ", " MD", " DDS", " DVM", " PhD"]

# Iterate through the words in the "prefixes_suffixes" list and replace them with an empty space, "".
for word in prefixes_suffixes:
    student_data_df["student_name"] = student_data_df["student_name"].str.replace(word,"")

# Check names.
student_data_df.head(10)
49/279:
# Install numpy using conda install numpy or pip install numpy. 
# Step 1. Import numpy as np.
import numpy as np
49/280:
# Step 2. Use the loc method on the student_data_df to select all the reading scores from the 9th grade at Thomas High School and replace them with NaN.
student_data_df.loc[(student_data_df["school_name"] == "Thomas High School") & (student_data_df["grade"] == "9th"), "reading_score"] = np.nan
49/281:
#  Step 3. Refactor the code in Step 2 to replace the math scores with NaN.
student_data_df.loc[(student_data_df["school_name"] == "Thomas High School") & (student_data_df["grade"] == "9th"), "math_score"] = np.nan
49/282:
#  Step 4. Check the student data for NaN's. 

student_data_df.tail(10)
49/283:
# Combine the data into a single dataset
school_data_complete_df = pd.merge(student_data_df, school_data_df, how="left", on=["school_name", "school_name"])
school_data_complete_df.head()
49/284:
# Calculate the Totals (Schools and Students)
school_count = len(school_data_complete_df["school_name"].unique())
student_count = school_data_complete_df["Student ID"].count()

# Calculate the Total Budget
total_budget = school_data_df["budget"].sum()
49/285:
# Calculate the Average Scores using the "clean_student_data".
average_reading_score = school_data_complete_df["reading_score"].mean()
average_math_score = school_data_complete_df["math_score"].mean()
49/286:
# Step 1. Get the number of students that are in ninth grade at Thomas High School.
# These students have no grades. 

ninth_grades_student_count = len(student_data_df.loc[(student_data_df["school_name"] == "Thomas High School") & (student_data_df["grade"] == "9th")])


# Get the total student count 
student_count = school_data_complete_df["Student ID"].count()


# Step 2. Subtract the number of students that are in ninth grade at 
# Thomas High School from the total student count to get the new total student count.
new_total_student_count = (student_count - ninth_grades_student_count)
49/287:
# Calculate the passing rates using the "clean_student_data".
passing_math_count = school_data_complete_df[(school_data_complete_df["math_score"] >= 70)].count()["student_name"]
passing_reading_count = school_data_complete_df[(school_data_complete_df["reading_score"] >= 70)].count()["student_name"]
49/288:
# Step 3. Calculate the passing percentages with the new total student count.
passing_math_percentage = passing_math_count/float(new_total_student_count) *100
passing_reading_percentage = passing_reading_count/float(new_total_student_count) *100
49/289:
# Calculate the students who passed both reading and math.
passing_math_reading = school_data_complete_df[(school_data_complete_df["math_score"] >= 70)
                                               & (school_data_complete_df["reading_score"] >= 70)]

# Calculate the number of students that passed both reading and math.
overall_passing_math_reading_count = passing_math_reading["student_name"].count()


# Step 4.Calculate the overall passing percentage with new total student count.
overall_passing_percentage= overall_passing_math_reading_count/new_total_student_count*100
overall_passing_percentage
49/290:
# Create a DataFrame
district_summary_df = pd.DataFrame(
          [{"Total Schools": school_count, 
          "Total Students": student_count, 
          "Total Budget": total_budget,
          "Average Math Score": average_math_score, 
          "Average Reading Score": average_reading_score,
          "% Passing Math": passing_math_percentage,
         "% Passing Reading": passing_reading_percentage,
        "% Overall Passing": overall_passing_percentage}])



# Format the "Total Students" to have the comma for a thousands separator.
district_summary_df["Total Students"] = district_summary_df["Total Students"].map("{:,}".format)
# Format the "Total Budget" to have the comma for a thousands separator, a decimal separator and a "$".
district_summary_df["Total Budget"] = district_summary_df["Total Budget"].map("${:,.2f}".format)
# Format the columns.
district_summary_df["Average Math Score"] = district_summary_df["Average Math Score"].map("{:.1f}".format)
district_summary_df["Average Reading Score"] = district_summary_df["Average Reading Score"].map("{:.1f}".format)
district_summary_df["% Passing Math"] = district_summary_df["% Passing Math"].map("{:.1f}".format)
district_summary_df["% Passing Reading"] = district_summary_df["% Passing Reading"].map("{:.1f}".format)
district_summary_df["% Overall Passing"] = district_summary_df["% Overall Passing"].map("{:.1f}".format)

# Display the data frame
district_summary_df
49/291:
# Determine the School Type
per_school_types = school_data_df.set_index(["school_name"])["type"]

# Calculate the total student count.
per_school_counts = school_data_complete_df["school_name"].value_counts()

# Calculate the total school budget and per capita spending
per_school_budget = school_data_complete_df.groupby(["school_name"]).mean()["budget"]
# Calculate the per capita spending.
per_school_capita = per_school_budget / per_school_counts

# Calculate the average test scores.
per_school_math = school_data_complete_df.groupby(["school_name"]).mean()["math_score"]
per_school_reading = school_data_complete_df.groupby(["school_name"]).mean()["reading_score"]

# Calculate the passing scores by creating a filtered DataFrame.
per_school_passing_math = school_data_complete_df[(school_data_complete_df["math_score"] >= 70)]
per_school_passing_reading = school_data_complete_df[(school_data_complete_df["reading_score"] >= 70)]

# Calculate the number of students passing math and passing reading by school.
per_school_passing_math = per_school_passing_math.groupby(["school_name"]).count()["student_name"]
per_school_passing_reading = per_school_passing_reading.groupby(["school_name"]).count()["student_name"]

# Calculate the percentage of passing math and reading scores per school.
per_school_passing_math = per_school_passing_math / per_school_counts * 100
per_school_passing_reading = per_school_passing_reading / per_school_counts * 100

# Calculate the students who passed both reading and math.
per_passing_math_reading = school_data_complete_df[(school_data_complete_df["reading_score"] >= 70)
                                               & (school_data_complete_df["math_score"] >= 70)]

# Calculate the number of students passing math and passing reading by school.
per_passing_math_reading = per_passing_math_reading.groupby(["school_name"]).count()["student_name"]

# Calculate the percentage of passing math and reading scores per school.
per_overall_passing_percentage = per_passing_math_reading / per_school_counts * 100
49/292:
# Create the DataFrame
per_school_summary_df = pd.DataFrame({
    "School Type": per_school_types,
    "Total Students": per_school_counts,
    "Total School Budget": per_school_budget,
    "Per Student Budget": per_school_capita,
    "Average Math Score": per_school_math,
    "Average Reading Score": per_school_reading,
    "% Passing Math": per_school_passing_math,
    "% Passing Reading": per_school_passing_reading,
    "% Overall Passing": per_overall_passing_percentage})


per_school_summary_df.head()
49/293:
# Format the Total School Budget and the Per Student Budget
per_school_summary_df["Total School Budget"] = per_school_summary_df["Total School Budget"].map("${:,.2f}".format)
per_school_summary_df["Per Student Budget"] = per_school_summary_df["Per Student Budget"].map("${:,.2f}".format)

# Display the data frame
per_school_summary_df
49/294:
# Step 5.  Get the number of 10th-12th graders from Thomas High School (THS).

tenth_grades_student_count = student_data_df.loc[(student_data_df["school_name"] == "Thomas High School") & (student_data_df["grade"] == "10th")]
twelveth_grade_student_count =  student_data_df.loc[(student_data_df["school_name"] == "Thomas High School") & (student_data_df["grade"] == "12th")]
eleventh_grade_student_count =  student_data_df.loc[(student_data_df["school_name"] == "Thomas High School") & (student_data_df["grade"] == "11th")]
total_number_10thto12th_graders_count= (len(tenth_grades_student_count)+ len(twelveth_grade_student_count) + len(eleventh_grade_student_count))
total_number_10thto12th_graders_count
49/295:
# Step 6. Get all the students passing math from THS
student_passing_math_ths = school_data_complete_df.loc[(student_data_df["school_name"]=="Thomas High School")&(student_data_df["math_score"] >=70)]
49/296:
# Step 7. Get all the students passing reading from THS
student_passing_reading_ths = school_data_complete_df.loc[(student_data_df["school_name"]=="Thomas High School")&(student_data_df["reading_score"] >=70)]
49/297:
# Step 8. Get all the students passing math and reading from THS
student_passing_math_reading_ths = school_data_complete_df.loc[(student_data_df["school_name"]=="Thomas High School")
                                                               &(student_data_df["math_score"] >=70)
                                                               & (student_data_df["reading_score"] >= 70)]
student_passing_math_reading_ths.head()
49/298:
# Step 9. Calculate the percentage of 10th-12th grade students passing math from Thomas High School. 
student_passing_math_ths_count = len(student_passing_math_ths)
student_passing_math_ths_percentage = student_passing_math_ths_count /total_number_10thto12th_graders_count*100
49/299:
# Step 10. Calculate the percentage of 10th-12th grade students passing reading from Thomas High School.
student_passing_reading_ths_count = len(student_passing_reading_ths)
student_passing_reading_ths_percentage = student_passing_reading_ths_count /total_number_10thto12th_graders_count*100
49/300:
# Step 11. Calculate the overall passing percentage of 10th-12th grade from Thomas High School. 
student_passing_overall_ths_count = len(student_passing_math_reading_ths)
student_passing_overall_ths_percentage = student_passing_overall_ths_count /total_number_10thto12th_graders_count*100
49/301:
# Step 12. Replace the passing math percent for Thomas High School in the per_school_summary_df.
per_school_summary_df.loc["Thomas High School", "% Passing Math"] = student_passing_math_ths_percentage
49/302:
# Step 13. Replace the passing reading percentage for Thomas High School in the per_school_summary_df.
per_school_summary_df.loc["Thomas High School", "% Passing Reading"] = student_passing_reading_ths_percentage
49/303:
# Step 14. Replace the overall passing percentage for Thomas High School in the per_school_summary_df.
per_school_summary_df.loc["Thomas High School", "% Overall Passing"] = student_passing_overall_ths_percentage
49/304: per_school_summary_df
49/305:
# Sort and show top five schools.
# Sort and show top five schools.
top_schools = per_school_summary_df.sort_values(["% Overall Passing"], ascending=False)
top_schools.head()
49/306:
# Sort and show bottom five schools.
bottom_schools = per_school_summary_df.sort_values(["% Overall Passing"], ascending=True)
bottom_schools.head()
49/307:
# Create a Series of scores by grade levels using conditionals.
ninth_grades_students = school_data_complete_df[(school_data_complete_df["grade"] =="9th")]
tenth_grades_students = school_data_complete_df[(school_data_complete_df["grade"] =="10th")]
eleventh_grades_students = school_data_complete_df[(school_data_complete_df["grade"] =="11th")]
twelfth_grades_students = school_data_complete_df[(school_data_complete_df["grade"] =="12th")]

# Group each school Series by the school name for the average math score.
ninth_grade_math_scores = ninth_grades_students.groupby(["school_name"]).mean()["math_score"]
tenth_grade_math_scores = tenth_grades_students.groupby(["school_name"]).mean()["math_score"]
eleventh_grade_math_scores = eleventh_grades_students.groupby(["school_name"]).mean()["math_score"]
twelfth_grade_math_scores = twelfth_grades_students.groupby(["school_name"]).mean()["math_score"]

# Group each school Series by the school name for the average reading score.
ninth_grade_reading_scores = ninth_grades_students.groupby(["school_name"]).mean()["reading_score"]
tenth_grade_reading_scores = tenth_grades_students.groupby(["school_name"]).mean()["reading_score"]
eleventh_grade_reading_scores = eleventh_grades_students.groupby(["school_name"]).mean()["reading_score"]
twelfth_grade_reading_scores = twelfth_grades_students.groupby(["school_name"]).mean()["reading_score"]
49/308:
# Combine each Series for average math scores by school into single data frame.
math_scores_by_grade = pd.DataFrame({
    "9th": ninth_grade_math_scores,
    "10th": tenth_grade_math_scores,
    "11th": eleventh_grade_math_scores,
    "12th": twelfth_grade_math_scores})
49/309:
# Combine each Series for average reading scores by school into single data frame.
reading_scores_by_grade = pd.DataFrame({
    "9th": ninth_grade_reading_scores,
    "10th": tenth_grade_reading_scores,
    "11th": eleventh_grade_reading_scores,
    "12th": twelfth_grade_reading_scores})
49/310:
# Format each grade column.
# Format each grade column for math
math_scores_by_grade["9th"] = math_scores_by_grade["9th"].map("{:.1f}".format)
math_scores_by_grade["10th"] = math_scores_by_grade["10th"].map("{:.1f}".format)
math_scores_by_grade["11th"] = math_scores_by_grade["11th"].map("{:.1f}".format)
math_scores_by_grade["12th"] = math_scores_by_grade["12th"].map("{:.1f}".format)
# Put in order
math_scores_by_grade = math_scores_by_grade[["9th", "10th", "11th", "12th"]]

# Format each grade column for reading.
reading_scores_by_grade["9th"] = reading_scores_by_grade["9th"].map("{:.1f}".format)
reading_scores_by_grade["10th"] = reading_scores_by_grade["10th"].map("{:.1f}".format)
reading_scores_by_grade["11th"] = reading_scores_by_grade["11th"].map("{:.1f}".format)
reading_scores_by_grade["12th"] = reading_scores_by_grade["12th"].map("{:.1f}".format)
# Put in order
reading_scores_by_grade = reading_scores_by_grade[["9th", "10th", "11th", "12th"]]
49/311:
# Remove the index.for math score
math_scores_by_grade.index.name = None

# Display the data frame
math_scores_by_grade
49/312:
## Remove the index.
reading_scores_by_grade.index.name = None

# Display the data frame
reading_scores_by_grade
49/313:
# Establish the spending bins and group names.

per_school_capita.describe()
spending_bins=[0,585,630,645,675]
group_names=["<$584","$585-629", "$630-644", "$645-675"]
per_school_capita.groupby(pd.cut(per_school_capita, spending_bins)).count()

# Categorize spending based on the bins.
per_school_summary_df["Spending Ranges (Per Student)"]=pd.cut(per_school_capita, spending_bins, labels=group_names)
per_school_summary_df
49/314:
# Calculate averages for the desired columns. 
spending_math_scores = per_school_summary_df.groupby(["Spending Ranges (Per Student)"]).mean()["Average Math Score"]
spending_reading_scores = per_school_summary_df.groupby(["Spending Ranges (Per Student)"]).mean()["Average Reading Score"]
spending_passing_math = per_school_summary_df.groupby(["Spending Ranges (Per Student)"]).mean()["% Passing Math"]
spending_passing_reading = per_school_summary_df.groupby(["Spending Ranges (Per Student)"]).mean()["% Passing Reading"]
overall_passing_spending = per_school_summary_df.groupby(["Spending Ranges (Per Student)"]).mean()["% Overall Passing"]
49/315:
# Create the DataFrame
spending_summary_df = pd.DataFrame({
    "Average Math Score": spending_math_scores,
    "Average Reading Score": spending_reading_scores,
    "% Passing Math": spending_passing_math,
    "% Passing Reading": spending_passing_reading,
    "% Overall Passing": overall_passing_spending})
49/316:
# Format the DataFrame 
spending_summary_df["Average Math Score"] = spending_summary_df["Average Math Score"].map("{:.1f}".format)
spending_summary_df["Average Reading Score"] = spending_summary_df["Average Reading Score"].map("{:.1f}".format)
spending_summary_df["% Passing Math"] = spending_summary_df["% Passing Math"].map("{:.0f}".format)
spending_summary_df["% Passing Reading"] = spending_summary_df["% Passing Reading"].map("{:.0f}".format)
spending_summary_df["% Overall Passing"] = spending_summary_df["% Overall Passing"].map("{:.1f}".format)
spending_summary_df
49/317:
# Establish the bins.
size_bins = [0, 1000, 2000, 5000]
group_names = ["Small (<1000)", "Medium (1000-2000)", "Large(2000-5000)"]
# Categorize spending based on the bins.
per_school_summary_df["School Size"] = pd.cut(per_school_summary_df["Total Students"], size_bins, labels=group_names)
49/318:
# Calculate averages for the desired columns. 
size_math_scores = per_school_summary_df.groupby(["School Size"]).mean()["Average Math Score"]
size_reading_scores = per_school_summary_df.groupby(["School Size"]).mean()["Average Reading Score"]
size_passing_math = per_school_summary_df.groupby(["School Size"]).mean()["% Passing Math"]
size_passing_reading = per_school_summary_df.groupby(["School Size"]).mean()["% Passing Reading"]
size_overall_passing = per_school_summary_df.groupby(["School Size"]).mean()["% Overall Passing"]
49/319:
# Assemble into DataFrame. 
size_summary_df = pd.DataFrame({
    "Average Math Score": size_math_scores,
    "Average Reading Score": size_reading_scores,
    "% Passing Math": size_passing_math,
    "% Passing Reading": size_passing_reading,
    "% Overall Passing": size_overall_passing})
49/320:
# Format the DataFrame  
size_summary_df["Average Math Score"] = size_summary_df["Average Math Score"].map("{:.1f}".format)
size_summary_df["Average Reading Score"] = size_summary_df["Average Reading Score"].map("{:.1f}".format)
size_summary_df["% Passing Math"] = size_summary_df["% Passing Math"].map("{:.0f}".format)
size_summary_df["% Passing Reading"] = size_summary_df["% Passing Reading"].map("{:.0f}".format)
size_summary_df["% Overall Passing"] = size_summary_df["% Overall Passing"].map("{:.0f}".format)
size_summary_df
49/321:
# Calculate averages for the desired columns. 
type_math_scores = per_school_summary_df.groupby(["School Type"]).mean()["Average Math Score"]
type_reading_scores = per_school_summary_df.groupby(["School Type"]).mean()["Average Reading Score"]
type_passing_math = per_school_summary_df.groupby(["School Type"]).mean()["% Passing Math"]
type_passing_reading = per_school_summary_df.groupby(["School Type"]).mean()["% Passing Reading"]
type_overall_passing = per_school_summary_df.groupby(["School Type"]).mean()["% Overall Passing"]
49/322:
# Assemble into DataFrame. 
type_summary_df = pd.DataFrame({
    "Average Math Score": type_math_scores,
    "Average Reading Score": type_reading_scores,
    "% Passing Math": type_passing_math,
    "% Passing Reading": type_passing_reading,
    "% Overall Passing": type_overall_passing})
49/323:
# # Format the DataFrame 
type_summary_df["Average Math Score"] = type_summary_df["Average Math Score"].map("{:.1f}".format)
type_summary_df["Average Reading Score"] = type_summary_df["Average Reading Score"].map("{:.1f}".format)
type_summary_df["% Passing Math"] = type_summary_df["% Passing Math"].map("{:.0f}".format)
type_summary_df["% Passing Reading"] = type_summary_df["% Passing Reading"].map("{:.0f}".format)
type_summary_df["% Overall Passing"] = type_summary_df["% Overall Passing"].map("{:.0f}".format)
type_summary_df
49/324:
# Combine the data into a single dataset
school_data_complete_df = pd.merge(student_data_df, school_data_df, how="left", on=["school_name", "school_name"])
#school_data_complete_df.head()
49/325:
# Create the DataFrame
per_school_summary_df = pd.DataFrame({
    "School Type": per_school_types,
    "Total Students": per_school_counts,
    "Total School Budget": per_school_budget,
    "Per Student Budget": per_school_capita,
    "Average Math Score": per_school_math,
    "Average Reading Score": per_school_reading,
    "% Passing Math": per_school_passing_math,
    "% Passing Reading": per_school_passing_reading,
    "% Overall Passing": per_overall_passing_percentage})


#per_school_summary_df.head()
49/326:
# Format the Total School Budget and the Per Student Budget
per_school_summary_df["Total School Budget"] = per_school_summary_df["Total School Budget"].map("${:,.2f}".format)
per_school_summary_df["Per Student Budget"] = per_school_summary_df["Per Student Budget"].map("${:,.2f}".format)

# Display the data frame
#per_school_summary_df
52/1:
# Create the DataFrame
per_school_summary_df = pd.DataFrame({
    "School Type": per_school_types,
    "Total Students": per_school_counts,
    "Total School Budget": per_school_budget,
    "Per Student Budget": per_school_capita,
    "Average Math Score": per_school_math,
    "Average Reading Score": per_school_reading,
    "% Passing Math": per_school_passing_math,
    "% Passing Reading": per_school_passing_reading,
    "% Overall Passing": per_overall_passing_percentage})


#per_school_summary_df.head()
52/2:
# Dependencies and Setup
import pandas as pd

# File to Load (Remember to change the path if needed.)
school_data_to_load = "Resources/schools_complete.csv"
student_data_to_load = "Resources/students_complete.csv"

# Read the School Data and Student Data and store into a Pandas DataFrame
school_data_df = pd.read_csv(school_data_to_load)
student_data_df = pd.read_csv(student_data_to_load)

# Cleaning Student Names and Replacing Substrings in a Python String
# Add each prefix and suffix to remove to a list.
prefixes_suffixes = ["Dr. ", "Mr. ","Ms. ", "Mrs. ", "Miss ", " MD", " DDS", " DVM", " PhD"]

# Iterate through the words in the "prefixes_suffixes" list and replace them with an empty space, "".
for word in prefixes_suffixes:
    student_data_df["student_name"] = student_data_df["student_name"].str.replace(word,"")

# Check names.
student_data_df.head(10)
52/3:
# Install numpy using conda install numpy or pip install numpy. 
# Step 1. Import numpy as np.
import numpy as np
52/4:
# Step 2. Use the loc method on the student_data_df to select all the reading scores from the 9th grade at Thomas High School and replace them with NaN.
student_data_df.loc[(student_data_df["school_name"] == "Thomas High School") & (student_data_df["grade"] == "9th"), "reading_score"] = np.nan
52/5:
#  Step 3. Refactor the code in Step 2 to replace the math scores with NaN.
student_data_df.loc[(student_data_df["school_name"] == "Thomas High School") & (student_data_df["grade"] == "9th"), "math_score"] = np.nan
52/6:
#  Step 4. Check the student data for NaN's. 

student_data_df.tail(10)
52/7:
# Combine the data into a single dataset
school_data_complete_df = pd.merge(student_data_df, school_data_df, how="left", on=["school_name", "school_name"])
#school_data_complete_df.head()
52/8:
# Calculate the Totals (Schools and Students)
school_count = len(school_data_complete_df["school_name"].unique())
student_count = school_data_complete_df["Student ID"].count()

# Calculate the Total Budget
total_budget = school_data_df["budget"].sum()
52/9:
# Calculate the Average Scores using the "clean_student_data".
average_reading_score = school_data_complete_df["reading_score"].mean()
average_math_score = school_data_complete_df["math_score"].mean()
52/10:
# Step 1. Get the number of students that are in ninth grade at Thomas High School.
# These students have no grades. 

ninth_grades_student_count = len(student_data_df.loc[(student_data_df["school_name"] == "Thomas High School") & (student_data_df["grade"] == "9th")])


# Get the total student count 
student_count = school_data_complete_df["Student ID"].count()


# Step 2. Subtract the number of students that are in ninth grade at 
# Thomas High School from the total student count to get the new total student count.
new_total_student_count = (student_count - ninth_grades_student_count)
52/11:
# Calculate the passing rates using the "clean_student_data".
passing_math_count = school_data_complete_df[(school_data_complete_df["math_score"] >= 70)].count()["student_name"]
passing_reading_count = school_data_complete_df[(school_data_complete_df["reading_score"] >= 70)].count()["student_name"]
52/12:
# Step 3. Calculate the passing percentages with the new total student count.
passing_math_percentage = passing_math_count/float(new_total_student_count) *100
passing_reading_percentage = passing_reading_count/float(new_total_student_count) *100
52/13:
# Calculate the students who passed both reading and math.
passing_math_reading = school_data_complete_df[(school_data_complete_df["math_score"] >= 70)
                                               & (school_data_complete_df["reading_score"] >= 70)]

# Calculate the number of students that passed both reading and math.
overall_passing_math_reading_count = passing_math_reading["student_name"].count()


# Step 4.Calculate the overall passing percentage with new total student count.
overall_passing_percentage= overall_passing_math_reading_count/new_total_student_count*100
overall_passing_percentage
52/14:
# Create a DataFrame
district_summary_df = pd.DataFrame(
          [{"Total Schools": school_count, 
          "Total Students": student_count, 
          "Total Budget": total_budget,
          "Average Math Score": average_math_score, 
          "Average Reading Score": average_reading_score,
          "% Passing Math": passing_math_percentage,
         "% Passing Reading": passing_reading_percentage,
        "% Overall Passing": overall_passing_percentage}])



# Format the "Total Students" to have the comma for a thousands separator.
district_summary_df["Total Students"] = district_summary_df["Total Students"].map("{:,}".format)
# Format the "Total Budget" to have the comma for a thousands separator, a decimal separator and a "$".
district_summary_df["Total Budget"] = district_summary_df["Total Budget"].map("${:,.2f}".format)
# Format the columns.
district_summary_df["Average Math Score"] = district_summary_df["Average Math Score"].map("{:.1f}".format)
district_summary_df["Average Reading Score"] = district_summary_df["Average Reading Score"].map("{:.1f}".format)
district_summary_df["% Passing Math"] = district_summary_df["% Passing Math"].map("{:.1f}".format)
district_summary_df["% Passing Reading"] = district_summary_df["% Passing Reading"].map("{:.1f}".format)
district_summary_df["% Overall Passing"] = district_summary_df["% Overall Passing"].map("{:.1f}".format)

# Display the data frame
district_summary_df
52/15:
# Determine the School Type
per_school_types = school_data_df.set_index(["school_name"])["type"]

# Calculate the total student count.
per_school_counts = school_data_complete_df["school_name"].value_counts()

# Calculate the total school budget and per capita spending
per_school_budget = school_data_complete_df.groupby(["school_name"]).mean()["budget"]
# Calculate the per capita spending.
per_school_capita = per_school_budget / per_school_counts

# Calculate the average test scores.
per_school_math = school_data_complete_df.groupby(["school_name"]).mean()["math_score"]
per_school_reading = school_data_complete_df.groupby(["school_name"]).mean()["reading_score"]

# Calculate the passing scores by creating a filtered DataFrame.
per_school_passing_math = school_data_complete_df[(school_data_complete_df["math_score"] >= 70)]
per_school_passing_reading = school_data_complete_df[(school_data_complete_df["reading_score"] >= 70)]

# Calculate the number of students passing math and passing reading by school.
per_school_passing_math = per_school_passing_math.groupby(["school_name"]).count()["student_name"]
per_school_passing_reading = per_school_passing_reading.groupby(["school_name"]).count()["student_name"]

# Calculate the percentage of passing math and reading scores per school.
per_school_passing_math = per_school_passing_math / per_school_counts * 100
per_school_passing_reading = per_school_passing_reading / per_school_counts * 100

# Calculate the students who passed both reading and math.
per_passing_math_reading = school_data_complete_df[(school_data_complete_df["reading_score"] >= 70)
                                               & (school_data_complete_df["math_score"] >= 70)]

# Calculate the number of students passing math and passing reading by school.
per_passing_math_reading = per_passing_math_reading.groupby(["school_name"]).count()["student_name"]

# Calculate the percentage of passing math and reading scores per school.
per_overall_passing_percentage = per_passing_math_reading / per_school_counts * 100
52/16:
# Create the DataFrame
per_school_summary_df = pd.DataFrame({
    "School Type": per_school_types,
    "Total Students": per_school_counts,
    "Total School Budget": per_school_budget,
    "Per Student Budget": per_school_capita,
    "Average Math Score": per_school_math,
    "Average Reading Score": per_school_reading,
    "% Passing Math": per_school_passing_math,
    "% Passing Reading": per_school_passing_reading,
    "% Overall Passing": per_overall_passing_percentage})


#per_school_summary_df.head()
52/17:
# Format the Total School Budget and the Per Student Budget
per_school_summary_df["Total School Budget"] = per_school_summary_df["Total School Budget"].map("${:,.2f}".format)
per_school_summary_df["Per Student Budget"] = per_school_summary_df["Per Student Budget"].map("${:,.2f}".format)

# Display the data frame
per_school_summary_df
52/18:
# Step 5.  Get the number of 10th-12th graders from Thomas High School (THS).

tenth_grades_student_count = student_data_df.loc[(student_data_df["school_name"] == "Thomas High School") & (student_data_df["grade"] == "10th")]
twelveth_grade_student_count =  student_data_df.loc[(student_data_df["school_name"] == "Thomas High School") & (student_data_df["grade"] == "12th")]
eleventh_grade_student_count =  student_data_df.loc[(student_data_df["school_name"] == "Thomas High School") & (student_data_df["grade"] == "11th")]
total_number_10thto12th_graders_count= (len(tenth_grades_student_count)+ len(twelveth_grade_student_count) + len(eleventh_grade_student_count))
total_number_10thto12th_graders_count
52/19:
# Step 6. Get all the students passing math from THS
student_passing_math_ths = school_data_complete_df.loc[(student_data_df["school_name"]=="Thomas High School")&(student_data_df["math_score"] >=70)]
52/20:
# Step 7. Get all the students passing reading from THS
student_passing_reading_ths = school_data_complete_df.loc[(student_data_df["school_name"]=="Thomas High School")&(student_data_df["reading_score"] >=70)]
52/21:
# Step 8. Get all the students passing math and reading from THS
student_passing_math_reading_ths = school_data_complete_df.loc[(student_data_df["school_name"]=="Thomas High School")
                                                               &(student_data_df["math_score"] >=70)
                                                               & (student_data_df["reading_score"] >= 70)]
student_passing_math_reading_ths.head()
52/22:
# Step 9. Calculate the percentage of 10th-12th grade students passing math from Thomas High School. 
student_passing_math_ths_count = len(student_passing_math_ths)
student_passing_math_ths_percentage = student_passing_math_ths_count /total_number_10thto12th_graders_count*100
52/23:
# Step 10. Calculate the percentage of 10th-12th grade students passing reading from Thomas High School.
student_passing_reading_ths_count = len(student_passing_reading_ths)
student_passing_reading_ths_percentage = student_passing_reading_ths_count /total_number_10thto12th_graders_count*100
52/24:
# Step 11. Calculate the overall passing percentage of 10th-12th grade from Thomas High School. 
student_passing_overall_ths_count = len(student_passing_math_reading_ths)
student_passing_overall_ths_percentage = student_passing_overall_ths_count /total_number_10thto12th_graders_count*100
52/25:
# Step 12. Replace the passing math percent for Thomas High School in the per_school_summary_df.
per_school_summary_df.loc["Thomas High School", "% Passing Math"] = student_passing_math_ths_percentage
52/26:
# Step 13. Replace the passing reading percentage for Thomas High School in the per_school_summary_df.
per_school_summary_df.loc["Thomas High School", "% Passing Reading"] = student_passing_reading_ths_percentage
52/27:
# Step 14. Replace the overall passing percentage for Thomas High School in the per_school_summary_df.
per_school_summary_df.loc["Thomas High School", "% Overall Passing"] = student_passing_overall_ths_percentage
52/28: per_school_summary_df
52/29:
# Sort and show top five schools.
# Sort and show top five schools.
top_schools = per_school_summary_df.sort_values(["% Overall Passing"], ascending=False)
top_schools.head()
52/30:
# Sort and show bottom five schools.
bottom_schools = per_school_summary_df.sort_values(["% Overall Passing"], ascending=True)
bottom_schools.head()
52/31:
# Create a Series of scores by grade levels using conditionals.
ninth_grades_students = school_data_complete_df[(school_data_complete_df["grade"] =="9th")]
tenth_grades_students = school_data_complete_df[(school_data_complete_df["grade"] =="10th")]
eleventh_grades_students = school_data_complete_df[(school_data_complete_df["grade"] =="11th")]
twelfth_grades_students = school_data_complete_df[(school_data_complete_df["grade"] =="12th")]

# Group each school Series by the school name for the average math score.
ninth_grade_math_scores = ninth_grades_students.groupby(["school_name"]).mean()["math_score"]
tenth_grade_math_scores = tenth_grades_students.groupby(["school_name"]).mean()["math_score"]
eleventh_grade_math_scores = eleventh_grades_students.groupby(["school_name"]).mean()["math_score"]
twelfth_grade_math_scores = twelfth_grades_students.groupby(["school_name"]).mean()["math_score"]

# Group each school Series by the school name for the average reading score.
ninth_grade_reading_scores = ninth_grades_students.groupby(["school_name"]).mean()["reading_score"]
tenth_grade_reading_scores = tenth_grades_students.groupby(["school_name"]).mean()["reading_score"]
eleventh_grade_reading_scores = eleventh_grades_students.groupby(["school_name"]).mean()["reading_score"]
twelfth_grade_reading_scores = twelfth_grades_students.groupby(["school_name"]).mean()["reading_score"]
52/32:
# Combine each Series for average math scores by school into single data frame.
math_scores_by_grade = pd.DataFrame({
    "9th": ninth_grade_math_scores,
    "10th": tenth_grade_math_scores,
    "11th": eleventh_grade_math_scores,
    "12th": twelfth_grade_math_scores})
52/33:
# Combine each Series for average reading scores by school into single data frame.
reading_scores_by_grade = pd.DataFrame({
    "9th": ninth_grade_reading_scores,
    "10th": tenth_grade_reading_scores,
    "11th": eleventh_grade_reading_scores,
    "12th": twelfth_grade_reading_scores})
52/34:
# Format each grade column.
# Format each grade column for math
math_scores_by_grade["9th"] = math_scores_by_grade["9th"].map("{:.1f}".format)
math_scores_by_grade["10th"] = math_scores_by_grade["10th"].map("{:.1f}".format)
math_scores_by_grade["11th"] = math_scores_by_grade["11th"].map("{:.1f}".format)
math_scores_by_grade["12th"] = math_scores_by_grade["12th"].map("{:.1f}".format)
# Put in order
math_scores_by_grade = math_scores_by_grade[["9th", "10th", "11th", "12th"]]

# Format each grade column for reading.
reading_scores_by_grade["9th"] = reading_scores_by_grade["9th"].map("{:.1f}".format)
reading_scores_by_grade["10th"] = reading_scores_by_grade["10th"].map("{:.1f}".format)
reading_scores_by_grade["11th"] = reading_scores_by_grade["11th"].map("{:.1f}".format)
reading_scores_by_grade["12th"] = reading_scores_by_grade["12th"].map("{:.1f}".format)
# Put in order
reading_scores_by_grade = reading_scores_by_grade[["9th", "10th", "11th", "12th"]]
52/35:
# Remove the index.for math score
math_scores_by_grade.index.name = None

# Display the data frame
math_scores_by_grade
52/36:
## Remove the index.
reading_scores_by_grade.index.name = None

# Display the data frame
reading_scores_by_grade
52/37:
# Establish the spending bins and group names.

per_school_capita.describe()
spending_bins=[0,585,630,645,675]
group_names=["<$584","$585-629", "$630-644", "$645-675"]
per_school_capita.groupby(pd.cut(per_school_capita, spending_bins)).count()

# Categorize spending based on the bins.
per_school_summary_df["Spending Ranges (Per Student)"]=pd.cut(per_school_capita, spending_bins, labels=group_names)
per_school_summary_df
52/38:
# Calculate averages for the desired columns. 
spending_math_scores = per_school_summary_df.groupby(["Spending Ranges (Per Student)"]).mean()["Average Math Score"]
spending_reading_scores = per_school_summary_df.groupby(["Spending Ranges (Per Student)"]).mean()["Average Reading Score"]
spending_passing_math = per_school_summary_df.groupby(["Spending Ranges (Per Student)"]).mean()["% Passing Math"]
spending_passing_reading = per_school_summary_df.groupby(["Spending Ranges (Per Student)"]).mean()["% Passing Reading"]
overall_passing_spending = per_school_summary_df.groupby(["Spending Ranges (Per Student)"]).mean()["% Overall Passing"]
52/39:
# Create the DataFrame
spending_summary_df = pd.DataFrame({
    "Average Math Score": spending_math_scores,
    "Average Reading Score": spending_reading_scores,
    "% Passing Math": spending_passing_math,
    "% Passing Reading": spending_passing_reading,
    "% Overall Passing": overall_passing_spending})
52/40:
# Format the DataFrame 
spending_summary_df["Average Math Score"] = spending_summary_df["Average Math Score"].map("{:.1f}".format)
spending_summary_df["Average Reading Score"] = spending_summary_df["Average Reading Score"].map("{:.1f}".format)
spending_summary_df["% Passing Math"] = spending_summary_df["% Passing Math"].map("{:.0f}".format)
spending_summary_df["% Passing Reading"] = spending_summary_df["% Passing Reading"].map("{:.0f}".format)
spending_summary_df["% Overall Passing"] = spending_summary_df["% Overall Passing"].map("{:.1f}".format)
spending_summary_df
52/41:
# Establish the bins.
size_bins = [0, 1000, 2000, 5000]
group_names = ["Small (<1000)", "Medium (1000-2000)", "Large(2000-5000)"]
# Categorize spending based on the bins.
per_school_summary_df["School Size"] = pd.cut(per_school_summary_df["Total Students"], size_bins, labels=group_names)
52/42:
# Calculate averages for the desired columns. 
size_math_scores = per_school_summary_df.groupby(["School Size"]).mean()["Average Math Score"]
size_reading_scores = per_school_summary_df.groupby(["School Size"]).mean()["Average Reading Score"]
size_passing_math = per_school_summary_df.groupby(["School Size"]).mean()["% Passing Math"]
size_passing_reading = per_school_summary_df.groupby(["School Size"]).mean()["% Passing Reading"]
size_overall_passing = per_school_summary_df.groupby(["School Size"]).mean()["% Overall Passing"]
52/43:
# Assemble into DataFrame. 
size_summary_df = pd.DataFrame({
    "Average Math Score": size_math_scores,
    "Average Reading Score": size_reading_scores,
    "% Passing Math": size_passing_math,
    "% Passing Reading": size_passing_reading,
    "% Overall Passing": size_overall_passing})
52/44:
# Format the DataFrame  
size_summary_df["Average Math Score"] = size_summary_df["Average Math Score"].map("{:.1f}".format)
size_summary_df["Average Reading Score"] = size_summary_df["Average Reading Score"].map("{:.1f}".format)
size_summary_df["% Passing Math"] = size_summary_df["% Passing Math"].map("{:.0f}".format)
size_summary_df["% Passing Reading"] = size_summary_df["% Passing Reading"].map("{:.0f}".format)
size_summary_df["% Overall Passing"] = size_summary_df["% Overall Passing"].map("{:.0f}".format)
size_summary_df
52/45:
# Calculate averages for the desired columns. 
type_math_scores = per_school_summary_df.groupby(["School Type"]).mean()["Average Math Score"]
type_reading_scores = per_school_summary_df.groupby(["School Type"]).mean()["Average Reading Score"]
type_passing_math = per_school_summary_df.groupby(["School Type"]).mean()["% Passing Math"]
type_passing_reading = per_school_summary_df.groupby(["School Type"]).mean()["% Passing Reading"]
type_overall_passing = per_school_summary_df.groupby(["School Type"]).mean()["% Overall Passing"]
52/46:
# Assemble into DataFrame. 
type_summary_df = pd.DataFrame({
    "Average Math Score": type_math_scores,
    "Average Reading Score": type_reading_scores,
    "% Passing Math": type_passing_math,
    "% Passing Reading": type_passing_reading,
    "% Overall Passing": type_overall_passing})
52/47:
# # Format the DataFrame 
type_summary_df["Average Math Score"] = type_summary_df["Average Math Score"].map("{:.1f}".format)
type_summary_df["Average Reading Score"] = type_summary_df["Average Reading Score"].map("{:.1f}".format)
type_summary_df["% Passing Math"] = type_summary_df["% Passing Math"].map("{:.0f}".format)
type_summary_df["% Passing Reading"] = type_summary_df["% Passing Reading"].map("{:.0f}".format)
type_summary_df["% Overall Passing"] = type_summary_df["% Overall Passing"].map("{:.0f}".format)
type_summary_df
52/48:
# Step 8. Get all the students passing math and reading from THS
student_passing_math_reading_ths = school_data_complete_df.loc[(student_data_df["school_name"]=="Thomas High School")
                                                               &(student_data_df["math_score"] >=70)
                                                               & (student_data_df["reading_score"] >= 70)]
#student_passing_math_reading_ths.head()
52/49:
# Combine the data into a single dataset
school_data_complete_df = pd.merge(student_data_df, school_data_df, how="left", on=["school_name", "school_name"])
school_data_complete_df.head()
52/50:
# Combine the data into a single dataset
school_data_complete_df = pd.merge(student_data_df, school_data_df, how="left", on=["school_name", "school_name"])
school_data_complete_df.tail()
53/1:
import matplotlib
matplotlib.__version__
53/2: import matplotlib.pyplot as plt
53/3: savings = [0,100,150,200,300,500,300,350,500,600,750,1000]
53/4:
plt.plot(savings)
plt.show()
53/5:
savings = [0,100,150,200,300,500,300,350,500,600,750,1000]
months = ['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep'.'Oct'.'Nov','Dec']
53/6:
import matplotlib
matplotlib.__version__
53/7: import matplotlib.pyplot as plt
53/8:
savings = [0,100,150,200,300,500,300,350,500,600,750,1000]
months = ['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep'.'Oct'.'Nov','Dec']
53/9:
savings = [0,100,150,200,300,500,300,350,500,600,750,1000]
months = ['Jan','Feb', 'Mar', 'Apr', 'May', 'Jun' ,'Jul' ,'Aug','Sep','Oct','Nov', 'Dec']
53/10:
plt.plot(month,savings)
plt.show()
53/11: import matplotlib.pyplot as plt
53/12:
savings = [0,100,150,200,300,500,300,350,500,600,750,1000]
months = ['Jan','Feb', 'Mar', 'Apr', 'May', 'Jun' ,'Jul' ,'Aug','Sep','Oct','Nov', 'Dec']
53/13:
plt.plot(month,savings)
plt.show()
53/14:
plt.plot(months,savings)
plt.show()
53/15:
plt.plot(months,savings)
plt.xlablel('Month')
plt.ylabel('Savings ($)')
plt.show()
53/16:
savings = [0,100,150,200,300,500,300,350,500,600,750,1000]
months = ['Jan','Feb', 'Mar', 'Apr', 'May', 'Jun' ,'Jul' ,'Aug','Sep','Oct','Nov', 'Dec']
53/17:
plt.plot(months,savings)
plt.xlablel('Month')
plt.ylabel('Savings ($)')
plt.show()
53/18:
plt.plot(months,savings)
plt.xlablel('Month')
plt.ylabel('Savings ($)')
plt.title('Savings Account Results')
plt.show()
53/19:
savings = [0,100,150,200,300,500,300,350,500,600,750,1000]
months = ['Jan','Feb', 'Mar', 'Apr', 'May', 'Jun' ,'Jul' ,'Aug','Sep','Oct','Nov', 'Dec']
53/20:
plt.plot(months,savings)
plt.xlablel('Month')
plt.ylabel('Savings ($)')
plt.title('Savings Account Results')
plt.show()
53/21: import matplotlib.pyplot as plt
53/22:
savings = [0,100,150,200,300,500,300,350,500,600,750,1000]
months = ['Jan','Feb', 'Mar', 'Apr', 'May', 'Jun' ,'Jul' ,'Aug','Sep','Oct','Nov', 'Dec']
53/23:
plt.plot(months,savings)
plt.xlablel('Month')
plt.ylabel('Savings ($)')
plt.title('Savings Account Results')
plt.show()
53/24:
plt.plot(months,savings)
plt.xlabel('Month')
plt.ylabel('Savings ($)')
plt.title('Savings Account Results')
plt.show()
54/1: %matplotlib inline
54/2:
# Import dependencies.
import matplotlib.pyplot as plt
54/3:
# Set the x-axis to a list of strings for each month.
x_axis = ["Jan", "Feb", "Mar", "April", "May", "June", "July", "Aug", "Sept", "Oct", "Nov", "Dec"]

# Set the y-axis to a list of floats as the total fare in US dollars accumulated for each month.
y_axis = [10.02, 23.24, 39.20, 35.42, 32.34, 27.04, 43.82, 10.56, 11.85, 27.90, 20.71, 20.09]
54/4:
# Create the plot
plt.plot(x_axis, y_axis)
54/5:
# Create the plot with ax.plt()
fig, ax = plt.subplots()
ax.plot(x_axis, y_axis)
54/6:
# Create the plot with ax.plt()
fig = plt.figure()
ax = fig.add_subplot()
54/7:
# Set the x-axis to a list of strings for each month.
x_axis = ["Jan", "Feb", "Mar", "April", "May", "June", "July", "Aug", "Sept", "Oct", "Nov", "Dec"]

# Set the y-axis to a list of floats as the total fare in US dollars accumulated for each month.
y_axis = [10.02, 23.24, 39.20, 35.42, 32.34, 27.04, 43.82, 10.56, 11.85, 27.90, 20.71, 20.09]
54/8:
# Create the plot
plt.plot(x_axis, y_axis)
54/9:
# Create the plot with ax.plt()
fig, ax = plt.subplots()
ax.plot(x_axis, y_axis)
54/10:
# Create the plot with ax.plt()
fig = plt.figure()
ax = fig.add_subplot()
54/11:
# Create the plot with ax.plt()
fig = plt.figure()
ax = fig.add_subplot()
ax.plot(x_axis, y_axis)
54/12:
# Create the plot with ax.plt()
ax = plt.axes()
ax.plot(x_axis, y_axis)
54/13:
# Create the plot.
plt.plot(x_axis, y_axis)
plt.show()
55/1:
# Create the plot and add a label for the legend.
plt.plot(x_axis, y_axis, label='Boston')
55/2: %matplotlib inline
55/3:
# Import dependencies.
import matplotlib.pyplot as plt
55/4:
# Set the x-axis to a list of strings for each month.
x_axis = ["Jan", "Feb", "Mar", "April", "May", "June", "July", "Aug", "Sept", "Oct", "Nov", "Dec"]

# Set the y-axis to a list of floats as the total fare in US dollars accumulated for each month.
y_axis = [10.02, 23.24, 39.20, 35.42, 32.34, 27.04, 43.82, 10.56, 11.85, 27.90, 20.71, 20.09]
55/5:
# Create the plot
plt.plot(x_axis, y_axis)
55/6:
# Create the plot with ax.plt()
fig, ax = plt.subplots()
ax.plot(x_axis, y_axis)
55/7:
# Create the plot with ax.plt()
fig = plt.figure()
ax = fig.add_subplot()
ax.plot(x_axis, y_axis)
55/8:
# Create the plot with ax.plt()
ax = plt.axes()
ax.plot(x_axis, y_axis)
55/9:
# Create the plot.
plt.plot(x_axis, y_axis)
plt.show()
55/10:
# Create the plot and add a label for the legend.
plt.plot(x_axis, y_axis, label='Boston')
55/11:
# Create the plot and add a label for the legend.
plt.plot(x_axis, y_axis, label='Boston')
55/12:
# Create the plot and add a label for the legend.
plt.plot(x_axis, y_axis, label='Boston')
# Create labels for the x and y axes.
plt.xlabel("Date")
plt.ylabel("Fare($)")
# Set the y limit between 0 and 45.
plt.ylim(0, 45)
# Create a title.
plt.title("PyBer Fare by Month")
# Add the legend.
plt.legend()
55/13:
# Create the plot and add a label for the legend.
plt.plot(x_axis, y_axis, label='Boston')
55/14:
# Create the plot and add a label for the legend.
plt.plot(x_axis, y_axis, label='Boston')
# Create labels for the x and y axes.
plt.xlabel("Date")
plt.ylabel("Fare($)")
# Set the y limit between 0 and 45.
plt.ylim(0, 45)
# Create a title.
plt.title("PyBer Fare by Month")
# Add the legend.
plt.legend()
55/15:
# Create the plot.
plt.plot(x_axis, y_axis, marker="*", color="blue", linewidth=2, label='Boston')
# Create labels for the x and y axes.
plt.xlabel("Date")
plt.ylabel("Fare($)")
# Set the y limit between 0 and 45.
plt.ylim(0, 45)
# Create a title.
plt.title("PyBer Fare by Month")
# Add a grid.
plt.grid()
# Add the legend.
plt.legend()
55/16:
# Create the plot.
plt.plot(x_axis, y_axis, marker="*", color="blue", linewidth=2, label='Boston')
55/17:
# Create the plot.
plt.plot(x_axis, y_axis, marker="*", color="blue", linewidth=2, label='Boston')
# Create labels for the x and y axes.
plt.xlabel("Date")
plt.ylabel("Fare($)")
# Set the y limit between 0 and 45.
plt.ylim(0, 45)
# Create a title.
plt.title("PyBer Fare by Month")
# Add a grid.
plt.grid()
# Add the legend.
plt.legend()
55/18:
# Create the plot.
plt.plot(x_axis, y_axis, marker="*", color="blue", label='Boston')
# Create labels for the x and y axes.
plt.xlabel("Date")
plt.ylabel("Fare($)")
# Set the y limit between 0 and 45.
plt.ylim(0, 45)
# Create a title.
plt.title("PyBer Fare by Month")
# Add a grid.
plt.grid()
# Add the legend.
plt.legend()
55/19:
# Create the plot.
plt.plot(x_axis, y_axis, marker="*", color="blue", linewidth=2, label='Boston')
# Create labels for the x and y axes.
plt.xlabel("Date")
plt.ylabel("Fare($)")
# Set the y limit between 0 and 45.
plt.ylim(0, 45)
# Create a title.
plt.title("PyBer Fare by Month")
# Add a grid.
plt.grid()
# Add the legend.
plt.legend()
55/20:
# Create the plot.
plt.plot(x_axis, y_axis, marker="diamond", color="green", linewidth=2, label='Boston')
# Create labels for the x and y axes.
plt.xlabel("Date")
plt.ylabel("Fare($)")
# Set the y limit between 0 and 45.
plt.ylim(0, 45)
# Create a title.
plt.title("PyBer Fare by Month")
# Add a grid.
plt.grid()
# Add the legend.
plt.legend()
55/21: %matplotlib inline
55/22:
# Import dependencies.
import matplotlib.pyplot as plt
55/23:
# Set the x-axis to a list of strings for each month.
x_axis = ["Jan", "Feb", "Mar", "April", "May", "June", "July", "Aug", "Sept", "Oct", "Nov", "Dec"]

# Set the y-axis to a list of floats as the total fare in US dollars accumulated for each month.
y_axis = [10.02, 23.24, 39.20, 35.42, 32.34, 27.04, 43.82, 10.56, 11.85, 27.90, 20.71, 20.09]
55/24:
# Create the plot
plt.plot(x_axis, y_axis)
55/25:
# Create the plot with ax.plt()
fig, ax = plt.subplots()
ax.plot(x_axis, y_axis)
55/26:
# Create the plot with ax.plt()
fig = plt.figure()
ax = fig.add_subplot()
ax.plot(x_axis, y_axis)
55/27:
# Create the plot with ax.plt()
ax = plt.axes()
ax.plot(x_axis, y_axis)
55/28:
# Create the plot.
plt.plot(x_axis, y_axis)
plt.show()
55/29:
# Create the plot and add a label for the legend.
plt.plot(x_axis, y_axis, label='Boston')
55/30:
# Create the plot and add a label for the legend.
plt.plot(x_axis, y_axis, label='Boston')
# Create labels for the x and y axes.
plt.xlabel("Date")
plt.ylabel("Fare($)")
# Set the y limit between 0 and 45.
plt.ylim(0, 45)
# Create a title.
plt.title("PyBer Fare by Month")
# Add the legend.
plt.legend()
55/31:
# Create the plot.
plt.plot(x_axis, y_axis, marker="*", color="blue", linewidth=2, label='Boston')
# Create labels for the x and y axes.
plt.xlabel("Date")
plt.ylabel("Fare($)")
# Set the y limit between 0 and 45.
plt.ylim(0, 45)
# Create a title.
plt.title("PyBer Fare by Month")
# Add a grid.
plt.grid()
# Add the legend.
plt.legend()
55/32:
# Create the plot.
plt.plot(x_axis, y_axis, marker="diamond", color="green", linewidth=2, label='Boston')
# Create labels for the x and y axes.
plt.xlabel("Date")
plt.ylabel("Fare($)")
# Set the y limit between 0 and 45.
plt.ylim(0, 45)
# Create a title.
plt.title("PyBer Fare by Month")
# Add a grid.
plt.grid()
# Add the legend.
plt.legend()
55/33:
# Create the plot.
plt.plot(x_axis, y_axis, marker="d", color="green", linewidth=2, label='Boston')
# Create labels for the x and y axes.
plt.xlabel("Date")
plt.ylabel("Fare($)")
# Set the y limit between 0 and 45.
plt.ylim(0, 45)
# Create a title.
plt.title("PyBer Fare by Month")
# Add a grid.
plt.grid()
# Add the legend.
plt.legend()
55/34:
# Create the plot.
plt.plot(x_axis, y_axis,color="green", linewidth=2, label='Boston')
# Create labels for the x and y axes.
plt.xlabel("Date")
plt.ylabel("Fare($)")
# Set the y limit between 0 and 45.
plt.ylim(0, 45)
# Create a title.
plt.title("PyBer Fare by Month")
# Add a grid.
plt.grid()
# Add the legend.
plt.legend()
55/35:
# Create the plot.
plt.plot(x_axis, y_axis, marker="d", color="green", linewidth=2, label='Boston')
# Create labels for the x and y axes.
plt.xlabel("Date")
plt.ylabel("Fare($)")
# Set the y limit between 0 and 45.
plt.ylim(0, 45)
# Create a title.
plt.title("PyBer Fare by Month")
# Add a grid.
plt.grid()
# Add the legend.
plt.legend()
55/36:
# Set the x-axis to a list of strings for each month.
x_axis = ["Jan", "Feb", "Mar", "April", "May", "June", "July", "Aug", "Sept", "Oct", "Nov", "Dec"]

# Set the y-axis to a list of floats as the total fare in US dollars accumulated for each month.
y_axis = [10.02, 23.24, 39.20, 35.42, 32.34, 27.04, 43.82, 10.56, 11.85, 27.90, 20.71, 20.09]
55/37:
#create the plot
plt.bar(x_axis,y_axis)
55/38:
# Create the plot.
plt.bar(x_axis, y_axis, color="green", label='Boston')
# Create labels for the x and y axes.
plt.xlabel("Date")
plt.ylabel("Fare($)")
# Create a title.
plt.title("PyBer Fare by Month")
# Add the legend.
plt.legend(
55/39:
# Set the x-axis to a list of strings for each month.
x_axis = ["Jan", "Feb", "Mar", "April", "May", "June", "July", "Aug", "Sept", "Oct", "Nov", "Dec"]

# Set the y-axis to a list of floats as the total fare in US dollars accumulated for each month.
y_axis = [10.02, 23.24, 39.20, 35.42, 32.34, 27.04, 43.82, 10.56, 11.85, 27.90, 20.71, 20.09]
55/40:
#create the plot
plt.bar(x_axis,y_axis)
55/41:
# Create the plot.
plt.bar(x_axis, y_axis, color="green", label='Boston')
# Create labels for the x and y axes.
plt.xlabel("Date")
plt.ylabel("Fare($)")
# Create a title.
plt.title("PyBer Fare by Month")
# Add the legend.
plt.legend(
55/42:
# Create the plot.
plt.bar(x_axis, y_axis, color="green", label='Boston')
# Create labels for the x and y axes.
plt.xlabel("Date")
plt.ylabel("Fare($)")
# Create a title.
plt.title("PyBer Fare by Month")
# Add the legend.
plt.legend()
55/43:
# Create t# Create the plot
plt.barh(y_axis, x_axis)he plot
plt.barh(y_axis, x_axis)
55/44: %matplotlib inline
55/45:
# Import dependencies.
import matplotlib.pyplot as plt
55/46:
# Set the x-axis to a list of strings for each month.
x_axis = ["Jan", "Feb", "Mar", "April", "May", "June", "July", "Aug", "Sept", "Oct", "Nov", "Dec"]

# Set the y-axis to a list of floats as the total fare in US dollars accumulated for each month.
y_axis = [10.02, 23.24, 39.20, 35.42, 32.34, 27.04, 43.82, 10.56, 11.85, 27.90, 20.71, 20.09]
55/47:
# Create the plot
plt.plot(x_axis, y_axis)
55/48:
# Create the plot with ax.plt()
fig, ax = plt.subplots()
ax.plot(x_axis, y_axis)
55/49:
# Create the plot with ax.plt()
fig = plt.figure()
ax = fig.add_subplot()
ax.plot(x_axis, y_axis)
55/50:
# Create the plot with ax.plt()
ax = plt.axes()
ax.plot(x_axis, y_axis)
55/51:
# Create the plot.
plt.plot(x_axis, y_axis)
plt.show()
55/52:
# Create the plot and add a label for the legend.
plt.plot(x_axis, y_axis, label='Boston')
55/53:
# Create the plot and add a label for the legend.
plt.plot(x_axis, y_axis, label='Boston')
# Create labels for the x and y axes.
plt.xlabel("Date")
plt.ylabel("Fare($)")
# Set the y limit between 0 and 45.
plt.ylim(0, 45)
# Create a title.
plt.title("PyBer Fare by Month")
# Add the legend.
plt.legend()
55/54:
# Create the plot.
plt.plot(x_axis, y_axis, marker="*", color="blue", linewidth=2, label='Boston')
# Create labels for the x and y axes.
plt.xlabel("Date")
plt.ylabel("Fare($)")
# Set the y limit between 0 and 45.
plt.ylim(0, 45)
# Create a title.
plt.title("PyBer Fare by Month")
# Add a grid.
plt.grid()
# Add the legend.
plt.legend()
55/55:
# Create the plot.
plt.plot(x_axis, y_axis, marker="d", color="green", linewidth=2, label='Boston')
# Create labels for the x and y axes.
plt.xlabel("Date")
plt.ylabel("Fare($)")
# Set the y limit between 0 and 45.
plt.ylim(0, 45)
# Create a title.
plt.title("PyBer Fare by Month")
# Add a grid.
plt.grid()
# Add the legend.
plt.legend()
55/56:
# Set the x-axis to a list of strings for each month.
x_axis = ["Jan", "Feb", "Mar", "April", "May", "June", "July", "Aug", "Sept", "Oct", "Nov", "Dec"]

# Set the y-axis to a list of floats as the total fare in US dollars accumulated for each month.
y_axis = [10.02, 23.24, 39.20, 35.42, 32.34, 27.04, 43.82, 10.56, 11.85, 27.90, 20.71, 20.09]
55/57:
#create the plot
plt.bar(x_axis,y_axis)
55/58:
# Create the plot.
plt.bar(x_axis, y_axis, color="green", label='Boston')
# Create labels for the x and y axes.
plt.xlabel("Date")
plt.ylabel("Fare($)")
# Create a title.
plt.title("PyBer Fare by Month")
# Add the legend.
plt.legend()
55/59:
# Create t# Create the plot
plt.barh(y_axis, x_axis)he plot
plt.barh(y_axis, x_axis)
55/60:
#Create the plot
plt.barh(y_axis, x_axis)
55/61:
# Create the plot.
plt.barh(x_axis, y_axis)
plt.gca().invert_yaxis()
55/62:
plt.barh(y_axis, x_axis,color="magenta", label='Boston')
plt.gca().invert_yaxis()
55/63:
plt.barh(x_axis, y_axis,color="magenta", label='Boston')
plt.gca().invert_yaxis()
55/64:
plt.barh(x_axis, y_axis,color="magenta", label='Boston')
plt.gca().invert_yaxis()
plt.legend()
55/65:
# Set the x-axis to a list of strings for each month.
x_axis = ["Jan", "Feb", "Mar", "April", "May", "June", "July", "Aug", "Sept", "Oct", "Nov", "Dec"]

# Set the y-axis to a list of floats as the total fare in US dollars accumulated for each month.
y_axis = [10.02, 23.24, 39.20, 35.42, 32.34, 27.04, 43.82, 10.56, 11.85, 27.90, 20.71, 20.09]
55/66:
#create the plot with ax.ply()
fig,ax = plt.subplots()
ax.bar(x_axis, y_axis)
55/67:
fig, ax = plt.subplots()
ax.barh(x_axis, y_axis)
55/68:
fig,ax = plt.subplots()
ax.barh(y_axis,x_axis)
55/69:
plt.barh(x_axis, y_axis,color="cyan", label='Chicago')
plt.title("Pyber Fare by Month")
plt.legend
55/70:
plt.barh(x_axis, y_axis,color="cyan", label='Chicago')
plt.title("Pyber Fare by Month")
plt.xlabel("Date")
plt.ylabel("Fare($)")
plt.legend
55/71:
plt.barh(x_axis, y_axis,color="cyan", label='Chicago')
plt.title("Pyber Fare by Month")
plt.xlabel("Fare($)")
plt.ylabel("Date")
plt.legend
55/72: import matplotlib.pyplot as plt
55/73:
x= [50,42,39,34,32,48,22,17,8,13]
y= [17,19,21,22,24,23,34,3143,35]
55/74:
plt.scatter(x,y)
plt.show()
55/75:
x= [50,42,39,34,32,48,22,17,8,13]
y= [17,19,21,22,24,23,34,3143,35]
55/76: import matplotlib.pyplot as plt
55/77:
x= [50,42,39,34,32,48,22,17,8,13]
y= [17,19,21,22,24,23,34,3143,35]
55/78:
x = [50,42,39,34,32,48,22,17,8,13]
y = [17,19,21,22,24,23,34,3143,35]
55/79:
x = [50,42,39,34,32,48,22,17,8,13]
y = [17,19,21,22,24,23,34,3143,35]
55/80: import matplotlib.pyplot as plt
55/81:
x = [50,42,39,34,32,48,22,17,8,13]
y = [17,19,21,22,24,23,34,3143,35]
55/82:
plt.scatter(x,y)
plt.show()
55/83: %matplotlib inline
55/84:
# Import dependencies.
import matplotlib.pyplot as plt
55/85:
# Set the x-axis to a list of strings for each month.
x_axis = ["Jan", "Feb", "Mar", "April", "May", "June", "July", "Aug", "Sept", "Oct", "Nov", "Dec"]

# Set the y-axis to a list of floats as the total fare in US dollars accumulated for each month.
y_axis = [10.02, 23.24, 39.20, 35.42, 32.34, 27.04, 43.82, 10.56, 11.85, 27.90, 20.71, 20.09]
55/86:
# Create the plot
plt.plot(x_axis, y_axis)
55/87:
# Create the plot with ax.plt()
fig, ax = plt.subplots()
ax.plot(x_axis, y_axis)
55/88:
# Create the plot with ax.plt()
fig = plt.figure()
ax = fig.add_subplot()
ax.plot(x_axis, y_axis)
55/89:
# Create the plot with ax.plt()
ax = plt.axes()
ax.plot(x_axis, y_axis)
55/90:
# Create the plot.
plt.plot(x_axis, y_axis)
plt.show()
55/91:
# Create the plot and add a label for the legend.
plt.plot(x_axis, y_axis, label='Boston')
55/92:
# Create the plot and add a label for the legend.
plt.plot(x_axis, y_axis, label='Boston')
# Create labels for the x and y axes.
plt.xlabel("Date")
plt.ylabel("Fare($)")
# Set the y limit between 0 and 45.
plt.ylim(0, 45)
# Create a title.
plt.title("PyBer Fare by Month")
# Add the legend.
plt.legend()
55/93:
# Create the plot.
plt.plot(x_axis, y_axis, marker="*", color="blue", linewidth=2, label='Boston')
# Create labels for the x and y axes.
plt.xlabel("Date")
plt.ylabel("Fare($)")
# Set the y limit between 0 and 45.
plt.ylim(0, 45)
# Create a title.
plt.title("PyBer Fare by Month")
# Add a grid.
plt.grid()
# Add the legend.
plt.legend()
55/94:
# Create the plot.
plt.plot(x_axis, y_axis, marker="d", color="green", linewidth=2, label='Boston')
# Create labels for the x and y axes.
plt.xlabel("Date")
plt.ylabel("Fare($)")
# Set the y limit between 0 and 45.
plt.ylim(0, 45)
# Create a title.
plt.title("PyBer Fare by Month")
# Add a grid.
plt.grid()
# Add the legend.
plt.legend()
55/95:
# Set the x-axis to a list of strings for each month.
x_axis = ["Jan", "Feb", "Mar", "April", "May", "June", "July", "Aug", "Sept", "Oct", "Nov", "Dec"]

# Set the y-axis to a list of floats as the total fare in US dollars accumulated for each month.
y_axis = [10.02, 23.24, 39.20, 35.42, 32.34, 27.04, 43.82, 10.56, 11.85, 27.90, 20.71, 20.09]
55/96:
#create the plot
plt.bar(x_axis,y_axis)
55/97:
# Create the plot.
plt.bar(x_axis, y_axis, color="green", label='Boston')
# Create labels for the x and y axes.
plt.xlabel("Date")
plt.ylabel("Fare($)")
# Create a title.
plt.title("PyBer Fare by Month")
# Add the legend.
plt.legend()
55/98:
#Create the plot
plt.barh(y_axis, x_axis)
55/99:
# Create the plot.
plt.barh(x_axis, y_axis)
plt.gca().invert_yaxis()
55/100:
plt.barh(x_axis, y_axis,color="magenta", label='Boston')
plt.gca().invert_yaxis()
plt.legend()
55/101:
# Set the x-axis to a list of strings for each month.
x_axis = ["Jan", "Feb", "Mar", "April", "May", "June", "July", "Aug", "Sept", "Oct", "Nov", "Dec"]

# Set the y-axis to a list of floats as the total fare in US dollars accumulated for each month.
y_axis = [10.02, 23.24, 39.20, 35.42, 32.34, 27.04, 43.82, 10.56, 11.85, 27.90, 20.71, 20.09]
55/102:
#create the plot with ax.ply()
fig,ax = plt.subplots()
ax.bar(x_axis, y_axis)
55/103:
fig, ax = plt.subplots()
ax.barh(x_axis, y_axis)
55/104:
fig,ax = plt.subplots()
ax.barh(y_axis,x_axis)
55/105:
plt.barh(x_axis, y_axis,color="cyan", label='Chicago')
plt.title("Pyber Fare by Month")
plt.xlabel("Fare($)")
plt.ylabel("Date")
plt.legend
55/106: import matplotlib.pyplot as plt
55/107:
x = [50,42,39,34,32,48,22,17,8,13]
y = [17,19,21,22,24,23,34,3143,35]
55/108:
plt.scatter(x,y)
plt.show()
55/109:
x = [50,42,39,34,32,48,22,17,8,13]
y = [17,19,21,22,24,23,34,31,43,35]
55/110:
plt.scatter(x,y)
plt.show()
55/111:
plt.scatter(x,y)
plt,xlabel('Total Number of Rides(Per City)')
plt,ylabel('Average Fare($)')
plt.title('Average are vs Total Rides')
plt.show()
55/112:
plt.scatter(x,y)
plt,xlabel('Total Number of Rides(Per City)')
plt,ylabel('Average Fare($)')
plt.title('Average Fare vs Total Rides')
plt.show()
55/113: import matplotlib.pyplot as plt
55/114:
x = [50,42,39,34,32,48,22,17,8,13]
y = [17,19,21,22,24,23,34,31,43,35]
55/115:
plt.scatter(x,y)
plt,xlabel('Total Number of Rides(Per City)')
plt,ylabel('Average Fare($)')
plt.title('Average Fare vs Total Rides')
plt.show()
55/116:
plt.scatter(x,y)
plt,xlabel('Total Number of Rides (Per City)')
plt,ylabel('Average Fare ($)')
plt.title('Average Fare vs Total Rides')
plt.show()
55/117:
plt.scatter(x,y)
plt.xlabel('Total Number of Rides (Per City)')
plt.ylabel('Average Fare ($)')
plt.title('Average Fare vs Total Rides')
plt.show()
55/118:
plt.scatter(x,y, c='green',marker='x',s=x)
plt.xlabel('Total Number of Rides (Per City)')
plt.ylabel('Average Fare ($)')
plt.title('Average Fare vs Total Rides')
plt.show()
57/1:
# Create our x_axis numpy array
x_axis = np.arange(0, 6, 0.1)
57/2:
# Import Numpy for calculations and matplotlib for charting
import numpy as np
import matplotlib.pyplot as plt
57/3:
# Create our x_axis numpy array
x_axis = np.arange(0, 6, 0.1)
57/4:
# Creates a numpy array based on the sin of our x_axis values
sin = np.sin(x_axis)
57/5:
# Creates a numpy array based on the cos of our x_axis values
cos = np.cos(x_axis)
57/6:
# Create our x_axis numpy array
x_axis = np.arange(0, 6, 0.1)
x_axis
57/7:
# Creates a numpy array based on the cos of our x_axis values
cos = np.cos(x_axis)
cos
57/8:
# Plot both of these lines so that they will appear on our final chart
plt.plot(x_axis, sin)
plt.plot(x_axis, cos)
57/9:
# Plot both of these lines so that they will appear on our final chart
plt.plot(x_axis, sin)
plt.plot(x_axis, cos)
plt.show()
58/1:
# Include this line to make plots interactive
%matplotlib notebook
58/2:
# Dependencies
import matplotlib.pyplot as plt
import numpy as np
58/3: x = np.arange [1,13,1]
58/4:
x = np.arange (1,13,1)
x_axis
58/5:
x_axis = np.arange (1,13,1)
x_axis
58/6:
# Plot both of these lines so that they will appear on our final chart.
plt.plot(x_axis,lows)
plt.plot(x_axis,highs)

# Create labels for the X and Y axis
plt.xlabel("Months")
plt.ylabel("Degrees")

# Save and display the chart
plt.show
58/7:
# Include this line to make plots interactive
%matplotlib notebook
58/8:
# Dependencies
import matplotlib.pyplot as plt
import numpy as np
58/9:
x_axis = np.arange (1,13,1)
x_axis
58/10:
# Avearge high temperature for each month
highs = [39, 42, 51, 62, 72, 82, 86, 84, 77, 65, 55, 44]
58/11:
# Avearge low temperature for each month
lows = [20, 22, 30, 40, 50, 60, 65, 63, 55, 42, 34, 25]
58/12:
# Plot both of these lines so that they will appear on our final chart.
plt.plot(x_axis,lows)
plt.plot(x_axis,highs)

# Create labels for the X and Y axis
plt.xlabel("Months")
plt.ylabel("Temperature")

# Save and display the chart
plt.show
59/1: %matplotlib notebook
59/2:
import matplotlib.pyplot as plt
import numpy as np
59/3:
# Create an array that contains the number of users each language has
users = [13000, 26000, 52000, 30000, 9000]
x_axis = np.arange(len(users))
59/4:
# Tell matplotlib that we will be making a bar chart
# Users is our y axis and x_axis is, of course, our x axis
# We apply align="edge" to ensure our bars line up with our tick marks
plt.bar(x_axis, users, color='r', alpha=0.5, align="center")
59/5:
# Tell matplotlib that we will be making a bar chart
# Users is our y axis and x_axis is, of course, our x axis
# We apply align="edge" to ensure our bars line up with our tick marks
plt.bar(x_axis, users, color='r', alpha=0.5, align="center")
59/6:
# Tell matplotlib where we would like to place each of our x axis headers
tick_locations = [value for value in x_axis]
plt.xticks(tick_locations, ["Java", "C++", "Python", "Ruby", "Clojure"])
59/7:
# Sets the x limits of the current chart
plt.xlim(-0.75, len(x_axis)-0.25)
59/8:
# Sets the y limits of the current chart
plt.ylim(0, max(users)+5000)
59/9:
# Give our chart some labels and a tile
plt.title("Popularity of Programming Languages")
plt.xlabel("Programming Language")
plt.ylabel("Number of People Using Programming Languages")
59/10:
# Sets the y limits of the current chart
plt.ylim(0, max(users)+55000)
59/11:
# Sets the y limits of the current chart
plt.ylim(0, max(users)+5000)
60/1:
# Create a bar chart based upon the above data
plt.bar(x_axis, users, color='r', alpha=0.5, align="center")
60/2:
# Create a bar chart based upon the above data
plt.bar(x_axis, citirs, color='b', alpha=0.5, align="center")
60/3: %matplotlib notebook
60/4:
import matplotlib.pyplot as plt
import numpy as np
60/5:
cities = ["New Orleans", "Milwaukee", "Omaha", "Pittsburgh", "Toledo"]
bars_in_cities = [8.6, 8.5, 8.3, 7.9, 7.2]
x_axis = np.arange(len(bars_in_cities))
60/6:
# Create a bar chart based upon the above data
plt.bar(x_axis, citirs, color='b', alpha=0.5, align="center")
60/7:
# Create a bar chart based upon the above data
plt.bar(x_axis, cities, color='b', alpha=0.5, align="center")
60/8:
# Create a bar chart based upon the above data
plt.bar(cities, x_axis, color='b', alpha=0.5, align="center")
60/9:
# Create a bar chart based upon the above data
plt.bar(cities, x_axis, color='b', align="center")
60/10:
# Create the ticks for our bar chart's x axis
tick_locations = [value for value in x_axis]
plt.xticks(tick_locations,["New Orleans", "Milwaukee", "Omaha", "Pittsburgh", "Toledo"])
60/11:
# Create a bar chart based upon the above data
plt.bar(cities, x_axis, color='b', align="center")
60/12:
# Create the ticks for our bar chart's x axis
tick_locations = [value for value in x_axis]
plt.xticks(tick_locations,["New Orleans", "Milwaukee", "Omaha", "Pittsburgh", "Toledo"])
60/13:
# Create a bar chart based upon the above data
plt.bar(cities,bars_in_cities, color='b', align="center")
60/14:
# Create the ticks for our bar chart's x axis
tick_locations = [value for value in x_axis]
plt.xticks(tick_locations,["New Orleans", "Milwaukee", "Omaha", "Pittsburgh", "Toledo"])
60/15:
# Save an image of the chart and print it to the screen
plt.savefig(..)
61/1:
# Creates the pie chart based upon the values above
# Automatically finds the percentages of each part of the pie chart
plt.pie(sizes, explode=explode, labels=labels, colors=mycolors,
        autopct="%1.1f%%", shadow=True, startangle=140)
61/2: %matplotlib notebook
61/3:
# Import our dependencies
import matplotlib.pyplot as plt
import numpy as np
61/4:
# Labels for the sections of our pie chart
labels = ["Humans", "Smurfs", "Hobbits", "Ninjas"]

# The values of each section of the pie chart
sizes = [220, 95, 80, 100]

# The colors of each section of the pie chart
mycolors = ["red", "orange", "lightcoral", "lightskyblue"]

# Tells matplotlib to seperate the "Humans" section from the others
explode = (0.1, 0, 0, 0)
61/5:
# Creates the pie chart based upon the values above
# Automatically finds the percentages of each part of the pie chart
plt.pie(sizes, explode=explode, labels=labels, colors=mycolors,
        autopct="%1.1f%%", shadow=True, startangle=140)
61/6:
# Creates the pie chart based upon the values above
# Automatically finds the percentages of each part of the pie chart
plt.pie(sizes, explode=explode, labels=labels, colors=mycolors,
        autopct="%1.0f%%", shadow=True, startangle=140)
62/1:
# Tell matplotlib to create a pie chart based upon the above data
plt.pie(sizes, explode=explode, labels=labels, colors=mycolors,
        autopct="%1.1f%%", shadow=True, startangle=140)
# Create axes which are equal so we have a perfect circle

# Save an image of our chart and print the final product to the screen
62/2: %matplotlib notebook
62/3:
import matplotlib.pyplot as plt
import numpy as np
62/4:
pies = ["Apple", "Pumpkin", "Chocolate Creme", "Cherry", "Apple Crumb",
        "Pecan", "Lemon Meringue", "Blueberry", "Key Lime", "Peach"]
pie_votes = [47, 37, 32, 27, 25, 24, 24, 21, 18, 16]
colors = ["yellow", "green", "lightblue", "orange", "red",
          "purple", "pink", "yellowgreen", "lightskyblue", "lightcoral"]
explode = (0.1, 0, 0, 0, 0, 0, 0, 0, 0, 0)
62/5:
# Tell matplotlib to create a pie chart based upon the above data
plt.pie(sizes, explode=explode, labels=labels, colors=mycolors,
        autopct="%1.1f%%", shadow=True, startangle=140)
# Create axes which are equal so we have a perfect circle

# Save an image of our chart and print the final product to the screen
62/6:
# Tell matplotlib to create a pie chart based upon the above data
plt.pie(sizes, explode=explode, labels=labels, colors=colors,
        autopct="%1.1f%%", shadow=True, startangle=140)
# Create axes which are equal so we have a perfect circle

# Save an image of our chart and print the final product to the screen
62/7:
# Tell matplotlib to create a pie chart based upon the above data
plt.pie(pie_votes, explode=explode, labels=pies, colors=colors,
        autopct="%1.1f%%", shadow=True, startangle=140)
# Create axes which are equal so we have a perfect circle

# Save an image of our chart and print the final product to the screen
62/8:
# Tell matplotlib to create a pie chart based upon the above data
# Create axes which are equal so we have a perfect circle
plt.pie(pie_votes, explode=explode, labels=pies, colors=colors,
        autopct="%1.1f%%", shadow=True, startangle=140)

plt.axis("equal")
# Save an image of our chart and print the final product to the screen
62/9:
# Tell matplotlib to create a pie chart based upon the above data
# Create axes which are equal so we have a perfect circle
plt.pie(pie_votes, explode=explode, labels=pies, colors=colors,
        autopct="%1.1f%%", shadow=True, startangle=140)


# Save an image of our chart and print the final product to the screen
62/10:
# Tell matplotlib to create a pie chart based upon the above data
# Create axes which are equal so we have a perfect circle
plt.pie(pie_votes, explode=explode, labels=pies, colors=colors,
        autopct="%1.1f%%", shadow=True, startangle=140)
plt.axis("equal")

# Save an image of our chart and print the final product to the screen
62/11:
# Tell matplotlib to create a pie chart based upon the above data
# Create axes which are equal so we have a perfect circle
plt.pie(pie_votes, explode=explode, labels=pies, colors=colors,
        autopct="%1.1f%%", shadow=True, startangle=140)


# Save an image of our chart and print the final product to the screen
62/12:
# Tell matplotlib to create a pie chart based upon the above data
# Create axes which are equal so we have a perfect circle
plt.pie(pie_votes, explode=explode, labels=pies, colors=colors,
        autopct="%1.1f%%", shadow=True, startangle=140)
plt.axis("equal")

# Save an image of our chart and print the final product to the screen
62/13:
# Tell matplotlib to create a pie chart based upon the above data
# Create axes which are equal so we have a perfect circle
plt.pie(pie_votes, explode=explode, labels=pies, colors=colors,
        autopct="%1.1f%%", shadow=True, startangle=140)
plt.axis("equal")

# Save an image of our chart and print the final product to the screen

savefig=()
62/14:
# Tell matplotlib to create a pie chart based upon the above data
# Create axes which are equal so we have a perfect circle
plt.pie(pie_votes, explode=explode, labels=pies, colors=colors,
        autopct="%1.1f%%", shadow=True, startangle=140)


# Save an image of our chart and print the final product to the screen

savefig=()
62/15:
# Tell matplotlib to create a pie chart based upon the above data
# Create axes which are equal so we have a perfect circle
plt.pie(pie_votes, explode=explode, labels=pies, colors=colors,
        autopct="%1.1f%%", shadow=True, startangle=140)

plt.axis("equal")
# Save an image of our chart and print the final product to the screen

savefig=()
63/1: %matplotlib notebook
63/2:
# Import Dependencies
import random
import matplotlib.pyplot as plt
import numpy as np
63/3:
# The maximum x value for our chart will be 100
x_limit = 100

# List of values from 0 to 100 each value being 1 greater than the last
x_axis = np.arange(0, x_limit, 1)

# Create a random array of data that we will use for our y values
data = [random.random() for value in x_axis]
63/4:
# Tells matplotlib that we want to make a scatter plot
# The size of each point on our plot is determined by their x value
plt.scatter(x_axis, data, marker="o", facecolors="red", edgecolors="black",
            s=x_axis, alpha=0.75)
63/5:
# The y limits of our scatter plot is 0 to 1.1
plt.ylim(-0.1, 1.1)
63/6:
# The x limits of our scatter plot is 0 to 110
plt.xlim(0, x_limit+5)
63/7:
# Prints the scatter plot to the screen
plt.show()
64/1: %matplotlib notebook
64/2:
import matplotlib.pyplot as plt
import numpy as np
64/3:
temp = [14.2, 16.4, 11.9, 15.2, 18.5, 22.1, 19.4, 25.1, 23.4, 18.1, 22.6, 17.2]
sales = [215, 325, 185, 332, 406, 522, 412, 614, 544, 421, 445, 408]
x_axis
64/4:
# Tell matplotlib to create a scatter plot based upon the above data
plt.scatter(temp,sales)
64/5:
temp = [14.2, 16.4, 11.9, 15.2, 18.5, 22.1, 19.4, 25.1, 23.4, 18.1, 22.6, 17.2]
sales = [215, 325, 185, 332, 406, 522, 412, 614, 544, 421, 445, 408]
64/6:
# Tell matplotlib to create a scatter plot based upon the above data
plt.scatter(temp,sales)
64/7:
# Tell matplotlib to create a scatter plot based upon the above data
plt.scatter(temp,sales,facecolors="red" edgecolors="black",
            s=x_axis, alpha=0.75))
64/8:
# Tell matplotlib to create a scatter plot based upon the above data
plt.scatter(temp,sales,facecolors="red",edgecolors="black",
            s=x_axis, alpha=0.75))
64/9:
temp = [14.2, 16.4, 11.9, 15.2, 18.5, 22.1, 19.4, 25.1, 23.4, 18.1, 22.6, 17.2]
sales = [215, 325, 185, 332, 406, 522, 412, 614, 544, 421, 445, 408]
64/10:
# Tell matplotlib to create a scatter plot based upon the above data
plt.scatter(temp,sales,facecolors="red",edgecolors="black", s=x_axis, alpha=0.75))
64/11:
# Tell matplotlib to create a scatter plot based upon the above data
plt.scatter(temp,sales,facecolors="red",edgecolors="black", s=x_axis, alpha=0.75)
64/12: %matplotlib notebook
64/13:
import matplotlib.pyplot as plt
import numpy as np
64/14:
temp = [14.2, 16.4, 11.9, 15.2, 18.5, 22.1, 19.4, 25.1, 23.4, 18.1, 22.6, 17.2]
sales = [215, 325, 185, 332, 406, 522, 412, 614, 544, 421, 445, 408]
64/15:
# Tell matplotlib to create a scatter plot based upon the above data
plt.scatter(temp,sales,facecolors="red",edgecolors="black", s=x_axis, alpha=0.75)
64/16:
# Tell matplotlib to create a scatter plot based upon the above data
plt.scatter(temp,sales,facecolors="red",edgecolor="black")
64/17:
# Set the upper and lower limits of our y axis
plt.ylim (200.600)
64/18:
# Set the upper and lower limits of our y axis
plt.ylim (200,600)
64/19:
# Tell matplotlib to create a scatter plot based upon the above data
plt.scatter(temp,sales,facecolors="red",edgecolor="black")
64/20:
# Set the upper and lower limits of our x axis
plt.xlim(11,26)
64/21:
# Create a title, x label, and y label for our chart
plt.title("Ice cream Sales v Temperature")
plt.xlabel("Temperature(Celcius)")
plt.ylabel("Sales(Dollars)")
64/22:
# Set the upper and lower limits of our y axis
plt.ylim (100,620)
64/23:
# Set the upper and lower limits of our x axis
plt.xlim(11,26)
64/24:
# Create a title, x label, and y label for our chart
plt.title("Ice cream Sales v Temperature")
plt.xlabel("Temperature(Celcius)")
plt.ylabel("Sales(Dollars)")
64/25:
# Save an image of the chart and print to screen
# NOTE: If your plot shrinks after saving an image,
# update matplotlib to 2.2 or higher,
# or simply run the above cells again.
64/26:
# Save an image of the chart and print to screen
# NOTE: If your plot shrinks after saving an image,
# update matplotlib to 2.2 or higher,
# or simply run the above cells again.
plt.savefig("../Images/IcecreamSales.png")
plt.show()
64/27: %matplotlib notebook
64/28:
import matplotlib.pyplot as plt
import numpy as np
64/29:
temp = [14.2, 16.4, 11.9, 15.2, 18.5, 22.1, 19.4, 25.1, 23.4, 18.1, 22.6, 17.2]
sales = [215, 325, 185, 332, 406, 522, 412, 614, 544, 421, 445, 408]
scoop_price = [89, 18, 10, 28, 79, 46, 29, 38, 89, 26, 45, 62]
64/30:
# Tell matplotlib to create a scatter plot based upon the above data
plt.scatter(temp,sales,facecolors="red",edgecolor="black",s=scoop_price)
64/31:
# Set the upper and lower limits of our y axis
plt.ylim (100,620)
64/32:
# Set the upper and lower limits of our x axis
plt.xlim(11,26)
64/33:
# Create a title, x label, and y label for our chart
plt.title("Ice cream Sales v Temperature")
plt.xlabel("Temperature(Celcius)")
plt.ylabel("Sales(Dollars)")
64/34:
# Save an image of the chart and print to screen
# NOTE: If your plot shrinks after saving an image,
# update matplotlib to 2.2 or higher,
# or simply run the above cells again.
plt.savefig("../Images/IcecreamSales.png")
plt.show()
64/35:
# Tell matplotlib to create a scatter plot based upon the above data
plt.scatter(temp,sales,marker="o",facecolors="red",edgecolor="black",s=scoop_price)
64/36:
# Set the upper and lower limits of our y axis
plt.ylim (100,620)
64/37:
# Set the upper and lower limits of our x axis
plt.xlim(11,26)
64/38:
# Create a title, x label, and y label for our chart
plt.title("Ice cream Sales v Temperature")
plt.xlabel("Temperature(Celcius)")
plt.ylabel("Sales(Dollars)")
64/39:
# Tell matplotlib to create a scatter plot based upon the above data
plt.scatter(temp,sales,facecolors="red",edgecolor="black",s=scoop_price)
64/40:
# Set the upper and lower limits of our y axis
plt.ylim (100,620)
64/41:
# Set the upper and lower limits of our x axis
plt.xlim(11,26)
64/42:
# Create a title, x label, and y label for our chart
plt.title("Ice cream Sales v Temperature")
plt.xlabel("Temperature(Celcius)")
plt.ylabel("Sales(Dollars)")
64/43:
# Save an image of the chart and print to screen
# NOTE: If your plot shrinks after saving an image,
# update matplotlib to 2.2 or higher,
# or simply run the above cells again.
plt.savefig("../Images/IcecreamSales.png")
plt.show()
64/44:
# Tell matplotlib to create a scatter plot based upon the above data
plt.scatter(temp,sales,marker="o",facecolors="red",edgecolor="black",s=scoop_price)
65/1:
# Set the x-axis to a list of strings for each month.
x_axis = ["Jan", "Feb", "Mar", "April", "May", "June", "July", "Aug", "Sept", "Oct", "Nov", "Dec"]

# Set the y-axis to a list of floats as the total fare in US dollars accumulated for each month.
y_axis = [10.02, 23.24, 39.20, 35.42, 32.34, 27.04, 43.82, 10.56, 11.85, 27.90, 20.71, 20.09]
65/2: plt.plot(x_axis, y_axis, 'o')
65/3: plt.plot(x_axis,y_axis, 'o')
65/4:
# Set the x-axis to a list of strings for each month.
x_axis = ["Jan", "Feb", "Mar", "April", "May", "June", "July", "Aug", "Sept", "Oct", "Nov", "Dec"]

# Set the y-axis to a list of floats as the total fare in US dollars accumulated for each month.
y_axis = [10.02, 23.24, 39.20, 35.42, 32.34, 27.04, 43.82, 10.56, 11.85, 27.90, 20.71, 20.09]
65/5: plt.plot(x_axis,y_axis, 'o')
65/6: plt.plot(x_axis, y_axis, 'o')
65/7:
# Set the x-axis to a list of strings for each month.
x_axis = ["Jan", "Feb", "Mar", "April", "May", "June", "July", "Aug", "Sept", "Oct", "Nov", "Dec"]

# Set the y-axis to a list of floats as the total fare in US dollars accumulated for each month.
y_axis = [10.02, 23.24, 39.20, 35.42, 32.34, 27.04, 43.82, 10.56, 11.85, 27.90, 20.71, 20.09]
65/8: plt.plot(x_axis, y_axis, 'o')
65/9:
#plt.plot(x_axis, y_axis, 'o')
plt.plot(x_axis, y_axis, 'o')
65/10:
#plt.plot(x_axis, y_axis, 'o')
plt.plot(x_axis, y_axis, 'o')
plt.show()
65/11:
# Set the x-axis to a list of strings for each month.
x_axis = ["Jan", "Feb", "Mar", "April", "May", "June", "July", "Aug", "Sept", "Oct", "Nov", "Dec"]

# Set the y-axis to a list of floats as the total fare in US dollars accumulated for each month.
y_axis = [10.02, 23.24, 39.20, 35.42, 32.34, 27.04, 43.82, 10.56, 11.85, 27.90, 20.71, 20.09]
65/12:
#plt.plot(x_axis, y_axis, 'o')
plt.plot(x_axis, y_axis, 'o')
plt.show()
65/13: import matplotlib.pyplot as plt
65/14:
x = [50,42,39,34,32,48,22,17,8,13]
y = [17,19,21,22,24,23,34,31,43,35]
65/15:
plt.scatter(x,y, c='green',marker='x',s=x)
plt.xlabel('Total Number of Rides (Per City)')
plt.ylabel('Average Fare ($)')
plt.title('Average Fare vs Total Rides')
plt.show()
65/16:
# Set the x-axis to a list of strings for each month.
x_axis = ["Jan", "Feb", "Mar", "April", "May", "June", "July", "Aug", "Sept", "Oct", "Nov", "Dec"]

# Set the y-axis to a list of floats as the total fare in US dollars accumulated for each month.
y_axis = [10.02, 23.24, 39.20, 35.42, 32.34, 27.04, 43.82, 10.56, 11.85, 27.90, 20.71, 20.09]
65/17:
#plt.plot(x_axis, y_axis, 'o')
plt.plot(x_axis, y_axis, 'o')
plt.show()
65/18:
plt.plot(x_axis, y_axis, 'o')
plt.show()
65/19: plt.plot(x_axis, y_axis, 'o')
65/20:
plt.plot(x_axis, y_axis, 'o')
plt.show()
65/21:
plt.plot(x_axis, y_axis, 'o',color"red", label"Chicago")
plt.xlabel("Fare($)")
plt.ylabel("Date")
plt.title("Pyber Fare by Month")
plt.show()
65/22:
plt.plot(x_axis, y_axis, 'o',color = "red", label = "Chicago")
plt.xlabel("Fare($)")
plt.ylabel("Date")
plt.title("Pyber Fare by Month")
plt.show()
65/23:
plt.plot(x_axis, y_axis, 'o',color = "red", label = "Chicago")
plt.xlabel("Fare($)")
plt.ylabel("Date")
plt.title("Pyber Fare by Month")
plt.legend
plt.show()
65/24:
plt.plot(x_axis, y_axis, 'o',color = "red", label = "Chicago")
plt.xlabel("Fare($)")
plt.ylabel("Date")
plt.title("Pyber Fare by Month")
plt.legend()
plt.show()
65/25: plt.scatter(x_axis, y_axis)
65/26: plt.scatter(x_axis, y_axis,s=yaxis)
65/27: plt.scatter(x_axis, y_axis,s=y_axis)
65/28: plt.scatter(x_axis, y_axis)
65/29: plt.scatter(x_axis, y_axis,s=y_axis)
65/30:
y_axis_larger =[]
for data in y_axis:
    y_axis_larger.append(data*3)
65/31: plt.scatter(x_axis, y_axis, s=y_axis_larger)
65/32: plt.scatter(x_axis, y_axis, s = [i * 3 for i in y_axis])
65/33:
fig, ax = plt.subplots()
ax.scatter(x_axis, y_axis)
65/34:
fig, ax = plt.subplots()
ax.scatter(x_axis, y_axis, s=y_axis)
65/35:
fig, ax = plt.subplots()
ax.scatter(x_axis, y_axis, s=y_axis, color="sky blue")
65/36: %matplotlib inline
65/37:
# Import dependencies.
import matplotlib.pyplot as plt
65/38:
# Set the x-axis to a list of strings for each month.
x_axis = ["Jan", "Feb", "Mar", "April", "May", "June", "July", "Aug", "Sept", "Oct", "Nov", "Dec"]

# Set the y-axis to a list of floats as the total fare in US dollars accumulated for each month.
y_axis = [10.02, 23.24, 39.20, 35.42, 32.34, 27.04, 43.82, 10.56, 11.85, 27.90, 20.71, 20.09]
65/39:
# Create the plot
plt.plot(x_axis, y_axis)
65/40:
# Create the plot with ax.plt()
fig, ax = plt.subplots()
ax.plot(x_axis, y_axis)
65/41:
# Create the plot with ax.plt()
fig = plt.figure()
ax = fig.add_subplot()
ax.plot(x_axis, y_axis)
65/42:
# Create the plot with ax.plt()
ax = plt.axes()
ax.plot(x_axis, y_axis)
65/43:
# Create the plot.
plt.plot(x_axis, y_axis)
plt.show()
65/44:
# Create the plot and add a label for the legend.
plt.plot(x_axis, y_axis, label='Boston')
65/45:
# Create the plot and add a label for the legend.
plt.plot(x_axis, y_axis, label='Boston')
# Create labels for the x and y axes.
plt.xlabel("Date")
plt.ylabel("Fare($)")
# Set the y limit between 0 and 45.
plt.ylim(0, 45)
# Create a title.
plt.title("PyBer Fare by Month")
# Add the legend.
plt.legend()
65/46:
# Create the plot.
plt.plot(x_axis, y_axis, marker="*", color="blue", linewidth=2, label='Boston')
# Create labels for the x and y axes.
plt.xlabel("Date")
plt.ylabel("Fare($)")
# Set the y limit between 0 and 45.
plt.ylim(0, 45)
# Create a title.
plt.title("PyBer Fare by Month")
# Add a grid.
plt.grid()
# Add the legend.
plt.legend()
65/47:
# Create the plot.
plt.plot(x_axis, y_axis, marker="d", color="green", linewidth=2, label='Boston')
# Create labels for the x and y axes.
plt.xlabel("Date")
plt.ylabel("Fare($)")
# Set the y limit between 0 and 45.
plt.ylim(0, 45)
# Create a title.
plt.title("PyBer Fare by Month")
# Add a grid.
plt.grid()
# Add the legend.
plt.legend()
65/48:
# Set the x-axis to a list of strings for each month.
x_axis = ["Jan", "Feb", "Mar", "April", "May", "June", "July", "Aug", "Sept", "Oct", "Nov", "Dec"]

# Set the y-axis to a list of floats as the total fare in US dollars accumulated for each month.
y_axis = [10.02, 23.24, 39.20, 35.42, 32.34, 27.04, 43.82, 10.56, 11.85, 27.90, 20.71, 20.09]
65/49:
#create the plot
plt.bar(x_axis,y_axis)
65/50:
# Create the plot.
plt.bar(x_axis, y_axis, color="green", label='Boston')
# Create labels for the x and y axes.
plt.xlabel("Date")
plt.ylabel("Fare($)")
# Create a title.
plt.title("PyBer Fare by Month")
# Add the legend.
plt.legend()
65/51:
#Create the plot
plt.barh(y_axis, x_axis)
65/52:
# Create the plot.
plt.barh(x_axis, y_axis)
plt.gca().invert_yaxis()
65/53:
plt.barh(x_axis, y_axis,color="magenta", label='Boston')
plt.gca().invert_yaxis()
plt.legend()
65/54:
# Set the x-axis to a list of strings for each month.
x_axis = ["Jan", "Feb", "Mar", "April", "May", "June", "July", "Aug", "Sept", "Oct", "Nov", "Dec"]

# Set the y-axis to a list of floats as the total fare in US dollars accumulated for each month.
y_axis = [10.02, 23.24, 39.20, 35.42, 32.34, 27.04, 43.82, 10.56, 11.85, 27.90, 20.71, 20.09]
65/55:
#create the plot with ax.ply()
fig,ax = plt.subplots()
ax.bar(x_axis, y_axis)
65/56:
fig, ax = plt.subplots()
ax.barh(x_axis, y_axis)
65/57:
fig,ax = plt.subplots()
ax.barh(y_axis,x_axis)
65/58:
plt.barh(x_axis, y_axis,color="cyan", label='Chicago')
plt.title("Pyber Fare by Month")
plt.xlabel("Fare($)")
plt.ylabel("Date")
plt.legend
65/59: import matplotlib.pyplot as plt
65/60:
x = [50,42,39,34,32,48,22,17,8,13]
y = [17,19,21,22,24,23,34,31,43,35]
65/61:
plt.scatter(x,y, c='green',marker='x',s=x)
plt.xlabel('Total Number of Rides (Per City)')
plt.ylabel('Average Fare ($)')
plt.title('Average Fare vs Total Rides')
plt.show()
65/62:
# Set the x-axis to a list of strings for each month.
x_axis = ["Jan", "Feb", "Mar", "April", "May", "June", "July", "Aug", "Sept", "Oct", "Nov", "Dec"]

# Set the y-axis to a list of floats as the total fare in US dollars accumulated for each month.
y_axis = [10.02, 23.24, 39.20, 35.42, 32.34, 27.04, 43.82, 10.56, 11.85, 27.90, 20.71, 20.09]
65/63:
plt.plot(x_axis, y_axis, 'o')
plt.show()
65/64:
plt.plot(x_axis, y_axis, 'o',color = "red", label = "Chicago")
plt.xlabel("Fare($)")
plt.ylabel("Date")
plt.title("Pyber Fare by Month")
plt.legend()
plt.show()
65/65: plt.scatter(x_axis, y_axis,s=y_axis)
65/66:
y_axis_larger =[]
for data in y_axis:
    y_axis_larger.append(data*3)
65/67: plt.scatter(x_axis, y_axis, s=y_axis_larger)
65/68: plt.scatter(x_axis, y_axis, s = [i * 3 for i in y_axis])
65/69:
fig, ax = plt.subplots()
ax.scatter(x_axis, y_axis)
65/70:
fig, ax = plt.subplots()
ax.scatter(x_axis, y_axis, s=y_axis, color="sky blue")
65/71:
fig, ax = plt.subplots()
ax.scatter(x_axis, y_axis, s=y_axis)
65/72:  plt.subplots(x_axis, y_axis, s=y_axis, color ="sky blue")
65/73:  plt.subplots(x_axis, y_axis, s=y_axis, color ="blue")
65/74:  plt.subplots(x_axis, y_axis, s="y_axis", color ="blue")
65/75: import matplotlib.pyplot as plt
65/76: revenue = [25,15,5,20,10,25]
65/77:
plt.pie(revenue)
plt.show()
65/78:
plt.pie(revenue,label=categories)
plt.show()
65/79: import matplotlib.pyplot as plt
65/80: categories = ['pants','shirts','outerwear','underwear', 'shoes']
65/81: revenue = [25,15,5,20,10,25]
65/82:
plt.pie(revenue)
plt.show()
65/83:
plt.pie(revenue,label=categories)
plt.show()
65/84:
plt.pie(revenue,labels=categories)
plt.show()
65/85: import matplotlib.pyplot as plt
65/86: categories = ['pants','shirts','outerwear','underwear', 'shoes']
65/87: revenue = [25,15,5,20,10,25]
65/88:
plt.pie(revenue)
plt.show()
65/89:
plt.pie(revenue,labels=categories)
plt.show()
65/90: %matplotlib inline
65/91:
# Import dependencies.
import matplotlib.pyplot as plt
65/92:
# Set the x-axis to a list of strings for each month.
x_axis = ["Jan", "Feb", "Mar", "April", "May", "June", "July", "Aug", "Sept", "Oct", "Nov", "Dec"]

# Set the y-axis to a list of floats as the total fare in US dollars accumulated for each month.
y_axis = [10.02, 23.24, 39.20, 35.42, 32.34, 27.04, 43.82, 10.56, 11.85, 27.90, 20.71, 20.09]
65/93:
# Create the plot
plt.plot(x_axis, y_axis)
65/94:
# Create the plot with ax.plt()
fig, ax = plt.subplots()
ax.plot(x_axis, y_axis)
65/95:
# Create the plot with ax.plt()
fig = plt.figure()
ax = fig.add_subplot()
ax.plot(x_axis, y_axis)
65/96:
# Create the plot with ax.plt()
ax = plt.axes()
ax.plot(x_axis, y_axis)
65/97:
# Create the plot.
plt.plot(x_axis, y_axis)
plt.show()
65/98:
# Create the plot and add a label for the legend.
plt.plot(x_axis, y_axis, label='Boston')
65/99:
# Create the plot and add a label for the legend.
plt.plot(x_axis, y_axis, label='Boston')
# Create labels for the x and y axes.
plt.xlabel("Date")
plt.ylabel("Fare($)")
# Set the y limit between 0 and 45.
plt.ylim(0, 45)
# Create a title.
plt.title("PyBer Fare by Month")
# Add the legend.
plt.legend()
65/100:
# Create the plot.
plt.plot(x_axis, y_axis, marker="*", color="blue", linewidth=2, label='Boston')
# Create labels for the x and y axes.
plt.xlabel("Date")
plt.ylabel("Fare($)")
# Set the y limit between 0 and 45.
plt.ylim(0, 45)
# Create a title.
plt.title("PyBer Fare by Month")
# Add a grid.
plt.grid()
# Add the legend.
plt.legend()
65/101:
# Create the plot.
plt.plot(x_axis, y_axis, marker="d", color="green", linewidth=2, label='Boston')
# Create labels for the x and y axes.
plt.xlabel("Date")
plt.ylabel("Fare($)")
# Set the y limit between 0 and 45.
plt.ylim(0, 45)
# Create a title.
plt.title("PyBer Fare by Month")
# Add a grid.
plt.grid()
# Add the legend.
plt.legend()
65/102:
# Set the x-axis to a list of strings for each month.
x_axis = ["Jan", "Feb", "Mar", "April", "May", "June", "July", "Aug", "Sept", "Oct", "Nov", "Dec"]

# Set the y-axis to a list of floats as the total fare in US dollars accumulated for each month.
y_axis = [10.02, 23.24, 39.20, 35.42, 32.34, 27.04, 43.82, 10.56, 11.85, 27.90, 20.71, 20.09]
65/103:
#create the plot
plt.bar(x_axis,y_axis)
65/104:
# Create the plot.
plt.bar(x_axis, y_axis, color="green", label='Boston')
# Create labels for the x and y axes.
plt.xlabel("Date")
plt.ylabel("Fare($)")
# Create a title.
plt.title("PyBer Fare by Month")
# Add the legend.
plt.legend()
65/105:
#Create the plot
plt.barh(y_axis, x_axis)
65/106:
# Create the plot.
plt.barh(x_axis, y_axis)
plt.gca().invert_yaxis()
65/107:
plt.barh(x_axis, y_axis,color="magenta", label='Boston')
plt.gca().invert_yaxis()
plt.legend()
65/108:
# Set the x-axis to a list of strings for each month.
x_axis = ["Jan", "Feb", "Mar", "April", "May", "June", "July", "Aug", "Sept", "Oct", "Nov", "Dec"]

# Set the y-axis to a list of floats as the total fare in US dollars accumulated for each month.
y_axis = [10.02, 23.24, 39.20, 35.42, 32.34, 27.04, 43.82, 10.56, 11.85, 27.90, 20.71, 20.09]
65/109:
#create the plot with ax.ply()
fig,ax = plt.subplots()
ax.bar(x_axis, y_axis)
65/110:
fig, ax = plt.subplots()
ax.barh(x_axis, y_axis)
65/111:
fig,ax = plt.subplots()
ax.barh(y_axis,x_axis)
65/112:
plt.barh(x_axis, y_axis,color="cyan", label='Chicago')
plt.title("Pyber Fare by Month")
plt.xlabel("Fare($)")
plt.ylabel("Date")
plt.legend
65/113: import matplotlib.pyplot as plt
65/114:
x = [50,42,39,34,32,48,22,17,8,13]
y = [17,19,21,22,24,23,34,31,43,35]
65/115:
plt.scatter(x,y, c='green',marker='x',s=x)
plt.xlabel('Total Number of Rides (Per City)')
plt.ylabel('Average Fare ($)')
plt.title('Average Fare vs Total Rides')
plt.show()
65/116:
# Set the x-axis to a list of strings for each month.
x_axis = ["Jan", "Feb", "Mar", "April", "May", "June", "July", "Aug", "Sept", "Oct", "Nov", "Dec"]

# Set the y-axis to a list of floats as the total fare in US dollars accumulated for each month.
y_axis = [10.02, 23.24, 39.20, 35.42, 32.34, 27.04, 43.82, 10.56, 11.85, 27.90, 20.71, 20.09]
65/117:
plt.plot(x_axis, y_axis, 'o')
plt.show()
65/118:
plt.plot(x_axis, y_axis, 'o',color = "red", label = "Chicago")
plt.xlabel("Fare($)")
plt.ylabel("Date")
plt.title("Pyber Fare by Month")
plt.legend()
plt.show()
65/119: plt.scatter(x_axis, y_axis,s=y_axis)
65/120:
y_axis_larger =[]
for data in y_axis:
    y_axis_larger.append(data*3)
65/121: plt.scatter(x_axis, y_axis, s=y_axis_larger)
65/122: plt.scatter(x_axis, y_axis, s = [i * 3 for i in y_axis])
65/123:
fig, ax = plt.subplots()
ax.scatter(x_axis, y_axis)
65/124:
fig, ax = plt.subplots()
ax.scatter(x_axis, y_axis, s=y_axis)
65/125: import matplotlib.pyplot as plt
65/126: categories = ['pants','shirts','outerwear','underwear', 'shoes']
65/127: revenue = [25,15,5,20,10,25]
65/128:
plt.pie(revenue)
plt.show()
65/129:
plt.pie(revenue,labels=categories)
plt.show()
65/130:
plt.pie(revenue,labels="categories")
plt.show()
65/131:
plt.pie(revenue,labels= categories)
plt.show()
65/132:
plt.pie(revenue,labels = categories)
plt.show()
65/133: import matplotlib.pyplot as plt
65/134: categories = ['pants','shirts','outerwear','underwear', 'shoes']
65/135: revenue = [25,15,5,20,10,25]
65/136:
plt.pie(revenue)
plt.show()
65/137: categories = ['pants','shirts','outerwear','pajamas','underwear', 'shoes']
65/138: revenue = [25,15,5,20,10,25]
65/139:
plt.pie(revenue)
plt.show()
65/140:
plt.pie(revenue,labels = categories)
plt.show()
65/141: plt.pie(revenie,labels=categories,autpct="%1.1f%%")
65/142:
plt.pie(revenie,labels=categories,autopct="%1.1f%%")
plt.show()
65/143:
plt.pie(revenue,labels=categories,autopct="%1.1f%%")
plt.show()
65/144: explode =['1','0','0','0','0', '0']
65/145: plt.pie(revenue,labels=categories,autopct="%1.1f%%",explode=explode)
65/146: explode =[.1,0,0,0,0,0]
65/147: plt.pie(revenue,labels=categories,autopct="%1.1f%%", explode=explode)
65/148:
plt.pie(revenue,labels=categories,autopct="%1.1f%%", explode=explode)
plt.show()
65/149: explode =[1,0,0,0,0,0]
65/150:
plt.pie(revenue,labels=categories,autopct="%1.1f%%", explode=explode)
plt.show()
65/151: explode =[.1,0,0,0,0,0]
65/152:
plt.pie(revenue,labels=categories,autopct="%1.1f%%", explode=explode)
plt.show()
65/153:
plt.pie(y_axis, labels=x_axis)
plt.show()
65/154:
explode_values = (0, 0, 0, 0, 0, 0, 0.2, 0, 0, 0, 0, 0)
plt.pie(y_axis, explode=explode_values, labels=x_axis, autopct='%.1f%%')
65/155:
explode_values = (0, 0, 0, 0, 0, 0, 0.2, 0, 0, 0, 0, 0)
plt.pie(y_axis, explode=explode_values, labels=x_axis, autopct='%.1f%%')
plt.show()
65/156:
explode_values = (0, 0, 0, 0, 0, 0, 0.2, 0, 0, 0, 0, 0)
plt.pie(y_axis, explode=explode_values, labels=x_axis, autopct='%.0f%%')
plt.show()
65/157:
# Assign 12 colors, one for each month.
colors = ["slateblue", "magenta", "lightblue", "green", "yellowgreen", "greenyellow", "yellow", "orange", "gold", "indianred", "tomato", "mistyrose"]
explode_values = (0, 0, 0, 0, 0, 0, 0.2, 0, 0, 0, 0, 0)
plt.subplots(figsize=(8, 8))
plt.pie(y_axis,
    explode=explode_values,
    colors=colors,
    labels=x_axis,
    autopct='%.1f%%')

plt.show()
65/158:
# Assign 12 colors, one for each month.
colors = ["slateblue", "magenta", "lightblue", "green", "yellowgreen", "greenyellow", "yellow", "orange", "gold", "indianred", "tomato", "mistyrose"]
explode_values = (0, 0, 0, 0, 0, 0, 0.2, 0, 0, 0, 0, 0)

plt.pie(y_axis,
    explode=explode_values,
    colors=colors,
    labels=x_axis,
    autopct='%.1f%%')

plt.show()
65/159:
# Assign 12 colors, one for each month.
colors = ["slateblue", "magenta", "lightblue", "green", "yellowgreen", "greenyellow", "yellow", "orange", "gold", "indianred", "tomato", "mistyrose"]
explode_values = (0, 0, 0, 0, 0, 0, 0.2, 0, 0, 0, 0, 0)
plt.subplots(figsize=(5, 5))
plt.pie(y_axis,
    explode=explode_values,
    colors=colors,
    labels=x_axis,
    autopct='%.1f%%')

plt.show()
65/160:
# Assign 12 colors, one for each month.
colors = ["slateblue", "magenta", "lightblue", "green", "yellowgreen", "greenyellow", "yellow", "orange", "gold", "indianred", "tomato", "mistyrose"]
explode_values = (0, 0, 0, 0, 0, 0, 0.2, 0, 0, 0, 0, 0)
plt.subplots(figsize=(9, 9))
plt.pie(y_axis,
    explode=explode_values,
    colors=colors,
    labels=x_axis,
    autopct='%.1f%%')

plt.show()
65/161:
# Assign 12 colors, one for each month.
colors = ["slateblue", "magenta", "lightblue", "green", "yellowgreen", "greenyellow", "yellow", "orange", "gold", "indianred", "tomato", "mistyrose"]
explode_values = (0, 0, 0, 0, 0, 0, 0.2, 0, 0, 0, 0, 0)
plt.subplots(figsize=(8, 9))
plt.pie(y_axis,
    explode=explode_values,
    colors=colors,
    labels=x_axis,
    autopct='%.1f%%')

plt.show()
65/162:
# Assign 12 colors, one for each month.
colors = ["slateblue", "magenta", "lightblue", "green", "yellowgreen", "greenyellow", "yellow", "orange", "gold", "indianred", "tomato", "mistyrose"]
explode_values = (0, 0, 0, 0, 0, 0, 0.2, 0, 0, 0, 0, 0)
plt.subplots(figsize=(8, 8))
plt.pie(y_axis,
    explode=explode_values,
    colors=colors,
    labels=x_axis,
    autopct='%.1f%%')

plt.show()
65/163:
fig,ax = plt.subplots()
ax.pie(y_axis,labels=x_axis)
plt.show()
65/164:
fig,ax = plt.subplots(revenue,labels=categories,autopct="%1.1f%%")
ax.pie(y_axis,labels=x_axis)
plt.show()
65/165:
fig,ax = plt.subplots()
ax.pie(revenue,labels=categories,autopct="%1.1f%%")
plt.show()
65/166:
fig,ax = plt.subplots()
ax.pie(y_axis,labels=x_axis,autopct="%1.1f%%")
plt.show()
65/167:
fig,ax = plt.subplots()
explode_values = (0, 0, 0.2, 0, 0, 0, 0.2, 0, 0, 0, 0, 0)
ax.pie(y_axis,labels=x_axis,autopct="%1.1f%%",explode=explode_values)
plt.show()
65/168:
fig,ax = plt.subplots()
plt.subplots(figsize=(8, 8))
explode_values = (0, 0, 0.2, 0, 0, 0, 0.2, 0, 0, 0, 0, 0)
ax.pie(y_axis,labels=x_axis,autopct="%1.1f%%",explode=explode_values)
plt.show()
65/169:
fig,ax = plt.subplots()

explode_values = (0, 0, 0.2, 0, 0, 0, 0.2, 0, 0, 0, 0, 0)
ax.pie(y_axis,labels=x_axis,autopct="%1.1f%%",explode=explode_values)
plt.show()
65/170:
fig,ax = plt.subplots()

explode_values = (0, 0, 0.2, 0, 0, 0, 0.2, 0, 0, 0, 0, 0)
ax.pie(y_axis,labels=x_axis,autopct="%1.1f%%",explode=explode_values,startangle=90)
plt.show()
65/171:
fig,ax = plt.subplots()

explode_values = (0, 0, 0.2, 0, 0, 0, 0.2, 0, 0, 0, 0, 0)
ax.pie(y_axis,labels=x_axis,autopct="%1.1f%%",explode=explode_values,startangle=90,shadow=True)
plt.show()
65/172:
fig,ax = plt.subplots()

explode_values = (0, 0, 0.2, 0, 0, 0, 0.2, 0, 0, 0, 0, 0)
ax.pie(y_axis,labels=x_axis,autopct="%1.1f%%",explode=explode_values,startangle=90,shadow=True,figsize=(8,8))
plt.show()
65/173:
fig,ax = plt.subplots()

explode_values = (0, 0, 0.2, 0, 0, 0, 0.2, 0, 0, 0, 0, 0)
ax.pie(y_axis,labels=x_axis,autopct="%1.1f%%",explode=explode_values,startangle=90,shadow=True,(figsize=(8,8))
plt.show()
65/174:
fig,ax = plt.subplots()

explode_values = (0, 0, 0.2, 0, 0, 0, 0.2, 0, 0, 0, 0, 0)
ax.pie[y_axis,labels=x_axis,autopct="%1.1f%%",explode=explode_values,startangle=90,shadow=True,(figsize=(8,8)]
plt.show()
65/175:
fig,ax = plt.subplots()

explode_values = (0, 0, 0.2, 0, 0, 0, 0.2, 0, 0, 0, 0, 0)
ax.pie(y_axis,labels=x_axis,autopct="%1.1f%%",explode=explode_values,startangle=90,shadow=True)
plt.show()
65/176:
fig,ax = plt.subplots(figsize=(8,8))

explode_values = (0, 0, 0.2, 0, 0, 0, 0.2, 0, 0, 0, 0, 0)
ax.pie(y_axis,labels=x_axis,autopct="%1.1f%%",explode=explode_values,startangle=90,shadow=True)
plt.show()
65/177:
fig,ax = plt.subplots(figsize=(8,8))

explode_values = (0, 0, 0.2, 0, 0, 0, 0.2, 0, 0, 0, 0, 0)
ax.pie(y_axis,labels=x_axis,autopct="%1.1f%%",explode=explode_values,startangle=190,shadow=True)
plt.show()
65/178:
fig,ax = plt.subplots(figsize=(8,8))

explode_values = (0, 0, 0.2, 0, 0, 0, 0.2, 0, 0, 0, 0, 0)
ax.pie(y_axis,labels=x_axis,autopct="%1.1f%%",explode=explode_values,startangle=120,shadow=True)
plt.show()
65/179:
fig,ax = plt.subplots(figsize=(8,8))

explode_values = (0, 0, 0.2, 0, 0, 0, 0.2, 0, 0, 0, 0, 0)
ax.pie(y_axis,labels=x_axis,autopct="%1.1f%%",explode=explode_values,startangle=75,shadow=True)
plt.show()
65/180:
fig,ax = plt.subplots(figsize=(8,8))

explode_values = (0, 0, 0.2, 0, 0, 0, 0.2, 0, 0, 0, 0, 0)
ax.pie(y_axis,labels=x_axis,autopct="%1.1f%%",explode=explode_values,startangle=180,shadow=True)
plt.show()
65/181:
fig,ax = plt.subplots(figsize=(8,8))

explode_values = (0, 0, 0.2, 0, 0, 0, 0.2, 0, 0, 0, 0, 0)
ax.pie(y_axis,labels=x_axis,autopct="%1.1f%%",explode=explode_values,startangle=90,shadow=True)
plt.show()
65/182:
fig,ax = plt.subplots(figsize=(8,8))

explode_values = (0, 0, 0.2, 0, 0, 0, 0.2, 0, 0, 0, 0, 0)
ax.pie(y_axis,labels=x_axis,autopct="%1.1f%%",explode=explode_values,startangle=0,shadow=True)
plt.show()
65/183:
fig,ax = plt.subplots(figsize=(8,8))

explode_values = (0, 0, 0.2, 0, 0, 0, 0.2, 0, 0, 0, 0, 0)
ax.pie(y_axis,labels=x_axis,autopct="%1.1f%%",explode=explode_values,startangle=20,shadow=True)
plt.show()
65/184:
fig,ax = plt.subplots(figsize=(8,8))

explode_values = (0, 0, 0.2, 0, 0, 0, 0.2, 0, 0, 0, 0, 0)
ax.pie(y_axis,labels=x_axis,autopct="%1.1f%%",explode=explode_values,startangle=50,shadow=True)
plt.show()
65/185:
fig,ax = plt.subplots(figsize=(8,8))

explode_values = (0, 0, 0.2, 0, 0, 0, 0.2, 0, 0, 0, 0, 0)
ax.pie(y_axis,labels=x_axis,autopct="%1.1f%%",explode=explode_values,startangle=90,shadow=True)
plt.show()
65/186:
fig,ax = plt.subplots(figsize=(8,8))

explode_values = (0, 0, 0.2, 0, 0, 0, 0.2, 0, 0, 0, 0, 0)
ax.pie(y_axis,labels=x_axis,autopct="%1.1f%%",explode=explode_values,startangle=90,shadow=True,counterclock=True)
plt.show()
65/187:
fig,ax = plt.subplots(figsize=(8,8))

explode_values = (0, 0, 0.2, 0, 0, 0, 0.2, 0, 0, 0, 0, 0)
ax.pie(y_axis,labels=x_axis,autopct="%1.1f%%",explode=explode_values,startangle=90,shadow=True,counterclock=False)
plt.show()
65/188:
fig,ax = plt.subplots(figsize=(8,8))
colors = ["slateblue", "magenta", "lightblue", "green", "yellowgreen", "greenyellow", "yellow", "orange", "gold", "indianred", "tomato", "mistyrose"]
explode_values = (0, 0, 0.2, 0, 0, 0, 0.2, 0, 0, 0, 0, 0)
ax.pie(y_axis,labels=x_axis,autopct="%1.1f%%",explode=explode_values,startangle=90,shadow=True,counterclock=False,colors=colors)
plt.show()
67/1:
# Dependencies
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
67/2:
# Load in csv
rain_df = pd.read_csv("../Resources/avg_rain_state.csv")
rain_df.head()
67/3:
# Set x axis and tick locations
x_axis = np.arange(len(rain_df))
tick_locations = [value for value in x_axis]
67/4:
# Save our graph and show the grap
plt.tight_layout()
plt.savefig("../Images/avg_state_rain.png")
plt.show()
67/5:
# Filter the DataFrame down only to those columns to chart
state_and_inches = rain_df[["State","Inches"]]

# Set the index to be "State" so they will be used as labels
state_and_inches = state_and_inches.set_index("State")

state_and_inches.head()
67/6:
# Filter the DataFrame down only to those columns to chart
state_and_inches = rain_df[["State","Inches"]]

# Set the index to be "State" so they will be used as labels


state_and_inches.head()
67/7:
# Use DataFrame.plot() in order to create a bar chart of the data
state_and_inches.plot(kind="bar", figsize=(20,3))

# Set a title for the chart
plt.title("Average Rain Per State")

plt.show()
plt.tight_layout()
67/8:
# Filter the DataFrame down only to those columns to chart
state_and_inches = rain_df[["State","Inches"]]

# Set the index to be "State" so they will be used as labels
state_and_inches = state_and_inches.set_index("State")

state_and_inches.head()
67/9:
# Filter the DataFrame down only to those columns to chart
state_and_inches = rain_df[["State","Inches"]]

# Set the index to be "State" so they will be used as labels
state_and_inches = state_and_inches.set_index("State")

state_and_inches.head()
67/10:
# Use DataFrame.plot() in order to create a bar chart of the data
state_and_inches.plot(kind="bar", figsize=(20,3))

# Set a title for the chart
plt.title("Average Rain Per State")

plt.show()
plt.tight_layout()
67/11: %matplotlib notebook
67/12:
# Dependencies
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
67/13:
# Load in csv
rain_df = pd.read_csv("../Resources/avg_rain_state.csv")
rain_df.head()
67/14:
# Set x axis and tick locations
x_axis = np.arange(len(rain_df))
tick_locations = [value for value in x_axis]
67/15:
# Create a list indicating where to write x labels and set figure size to adjust for space
plt.figure(figsize=(20,3))
plt.bar(x_axis, rain_df["Inches"], color='r', alpha=0.5, align="center")
plt.xticks(tick_locations, rain_df["State"], rotation="vertical")
plt.show()
67/16:
# Set x and y limits
plt.xlim(-0.75, len(x_axis))
plt.ylim(0, max(rain_df["Inches"])+10)
67/17:
# Set a Title and labels
plt.title("Average Rain per State")
plt.xlabel("State")
plt.ylabel("Average Amount of Rainfall in Inches")
67/18:
# Save our graph and show the grap
plt.tight_layout()
plt.savefig("../Images/avg_state_rain.png")
plt.show()
67/19:
# Filter the DataFrame down only to those columns to chart
state_and_inches = rain_df[["State","Inches"]]

# Set the index to be "State" so they will be used as labels
state_and_inches = state_and_inches.set_index("State")

state_and_inches.head()
67/20:
# Use DataFrame.plot() in order to create a bar chart of the data
state_and_inches.plot(kind="bar", figsize=(20,3))

# Set a title for the chart
plt.title("Average Rain Per State")

plt.show()
plt.tight_layout()
67/21:
# Pandas can also plot multiple columns if the DataFrame includes them
multi_plot = rain_df.plot(kind="bar", figsize=(20,5))

# PandasPlot.set_xticklabels() can be used to set the tick labels as well
multi_plot.set_xticklabels(rain_df["State"], rotation=45)

plt.show()
plt.tight_layout()
68/1:
# Read CSV
battling_king_data = pd.read_csv("Ressources"/"got_csv")
68/2:
# Read CSV
battling_king_data = pd.read_csv(Ressources/ got_csv)
68/3:
# Read CSV
battling_king_data = pd.read_csv(.../Ressources/ got_csv)
68/4:
# Read CSV
battling_king_data = pd.read_csv(.../Ressources/ got_csv)
68/5:
# Dependencies
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
68/6:
# Read CSV
battling_king_data = pd.read_csv(.../Ressources/ got_csv)
68/7:
# Read CSV
battling_king_data = pd.read_csv(".../Ressources/ got_csv")
68/8:
# Read CSV
battling_king_data = pd.read_csv(".../Resources/ got_csv")
68/9:
# Read CSV
battling_king_data = pd.read_csv(".../Resources/got_csv")
68/10:
# Read CSV
battling_king_data = pd.read_csv(""/Resources/got_csv")
68/11:
# Read CSV
battling_king_data = pd.read_csv("/Resources/got_csv")
68/12:
# Read CSV
got_data = pd.read_csv("/Resources/got_csv")
68/13: %matplotlib notebook
68/14:
# Dependencies
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
68/15:
# Read CSV
got_data = pd.read_csv("/Resources/got_csv")
68/16:
# Read CSV
got_data = pd.read_csv("Resources/got_csv")
68/17:
# Dependencies
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
68/18:
# Read CSV
got_data = pd.read_csv("Resources/got_csv")
68/19:
# Read CSV
got_data = pd.read_csv('Resources/got_csv')
69/1: %matplotlib notebook
69/2:
# Import Dependencies
import matplotlib.pyplot as plt
import pandas as pd
69/3:
# Import our data into pandas from CSV
used_car_data_path = '../Resources/used_cars.csv'
used_car_df = pd.read_csv(used_car_data_path)

used_car_df
69/4:
# Create a group based on the values in the 'maker' column
maker_group = used_car_df.groupby('maker')

# Count how many times each maker appears in our group
count_makers = maker_group['maker'].count()

count_makers
69/5:
# Import our data into pandas from CSV
used_car_data_path = '../Resources/used_cars.csv'
used_car_df = pd.read_csv(used_car_data_path)

used_car_df.head()
69/6:
# Create a group based on the values in the 'maker' column
maker_group = used_car_df.groupby('maker').count

# Count how many times each maker appears in our group
count_makers = maker_group['maker'].count()

count_makers
69/7:
# Create a group based on the values in the 'maker' column
maker_group = used_car_df.groupby('maker').count()

# Count how many times each maker appears in our group
count_makers = maker_group['maker'].count()

count_makers
69/8:
# Create a group based on the values in the 'maker' column
maker_group = used_car_df.groupby('maker').count()

# Count how many times each maker appears in our group
#count_makers = maker_group['maker'].count()

#count_makers
69/9:
# Create a group based on the values in the 'maker' column
maker_group = used_car_df.groupby('maker').count()


# Count how many times each maker appears in our group
#count_makers = maker_group['maker'].count()

counr_makers = maker_group["model"]
69/10:
# Create a bar chart based off of the group series from before
count_chart = count_makers.plot(kind='bar')

# Set the xlabel and ylabel using class methods
count_chart.set_xlabel("Car Manufacturer")
count_chart.set_ylabel("Number of Cars")


plt.show()
plt.tight_layout()
68/20:
# Read CSV
got_data = pd.read_csv 'Resources/got_csv'
68/21:
# Read CSV
got_data = pd.read_csv ('Resources/got_csv')
68/22:
# Read CSV
got_data = pd.read_csv('Resources/got_csv')
68/23:
# Read CSV
got_data = pd.read_csv('Resources / got_csv')
70/1:
# Import our data into pandas from CSV
bike_trippin_path = '..Resources/trip.csv'
bike_trippin.head()
70/2:
# Import our data into pandas from CSV
bike_trippin_path = '..Resources/trip.csv'
bike_trippin_df = pd.read_csv("bike_trippin_path")
70/3:
# Import our data into pandas from CSV
bike_trippin_path = '..Resources/trip.csv'
bike_trippin_df = pd.read_csv(bike_trippin_path)
70/4:
# Import Dependencies
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
70/5:
# Import our data into pandas from CSV
bike_trippin_path = '..Resources/trip.csv'
bike_trippin_df = pd.read_csv(bike_trippin_path)
70/6:
# Import Dependencies
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
70/7:
# Import our data into pandas from CSV
bike_trippin_path = '..Resources/trip.csv'
bike_trippin_df = pd.read_csv(bike_trippin_path)
70/8:
# Import our data into pandas from CSV
bike_trippin_path = '..Resources/trip.csv'
bike_trippin_df = pd.read_csv(bike_trippin_path)
bike_tripping_df.head()
70/9:
# Import Dependencies
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
70/10:
# Import our data into pandas from CSV
bike_trippin_path = '..Resources/trip.csv'
bike_trippin_df = pd.read_csv(bike_trippin_path)
bike_tripping_df.head()
70/11:
# Import Dependencies
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
70/12:
# Import our data into pandas from CSV
bike_trippin_path = '..Resources/trip.csv'
bike_trippin_df = pd.read_csv(bike_trippin_path)
bike_tripping_df.head()
70/13:
# Import our data into pandas from CSV
bike_trippin_path = '.. Resources/trip.csv'
bike_trippin_df = pd.read_csv(bike_trippin_path)
bike_tripping_df.head()
70/14:
# Import our data into pandas from CSV
bike_trippin_df = pd.read_csv("Resources/trip.csv")
bike_tripping_df.head()
70/15:
# Import Dependencies
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
70/16:
# Import our data into pandas from CSV
bike_trips_df = pd.read_csv("Resources/trip.csv")
bike_trips_df.head()
70/17:
# Get the last 5 rows 
bike_trips_df.tail()
70/18:
# Check for null or NaNs.
brike_trips_df.isnull().sum()
70/19:
# Check for null or NaNs.
bike_trips_df.isnull().sum()
70/20:
# Check for null or NaNs.
bike_trips_df.isnull().sum()
70/21:
# Create a clean DataFrame after dropping the null values.
clean_bike_df.dropna()
71/1:
# Import our data into pandas from CSV
bike_trips_df = pd.read_csv("Resources/trip.csv")
bike_trips_df.head()
71/2:
# Import Dependencies
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
71/3:
# Import our data into pandas from CSV
bike_trips_df = pd.read_csv("Resources/trip.csv")
bike_trips_df.head()
71/4:
#  Get the names of the columns.
bike_trips_values()
71/5:
#  Get the names of the columns.
bike_trips.values()
71/6:
#  Get the names of the columns.
bike_trips.count()
71/7:
#  Get the names of the columns.
bike_trips_df.count()
71/8:
#  Get the names of the columns.
bike_trips_df.values()
71/9:
#  Get the names of the columns.
bike_trips_df.dtype
71/10:
#  Get the names of the columns.
bike_trips_df.dtypes
71/11:
# Import our data into pandas from CSV
bike_trips_df = pd.read_csv("Resources/trip.csv")
bike_trips_df.head()
71/12:
#  Get the names of the columns.
bike_trips_df.dtypes
71/13:
#  Get the names of the columns.
bike_trips_df.columns
72/1: %matplotlib inline
72/2:
import matplotlib.pyplot as plt
import statistics
72/3:
# Set the x-axis to a list of strings for each month.
x_axis = ["Jan", "Feb", "Mar", "April", "May", "June", "July", "Aug", "Sept", "Oct", "Nov", "Dec"]

# Set the y-axis to a list of floats as the total fare in US dollars accumulated for each month.
y_axis = [10.02, 23.24, 39.20, 35.42, 32.34, 27.04, 43.82, 10.56, 11.85, 27.90, 20.71, 20.09]
72/4:
# Get the standard deviation of the values in the y-axis.
stdev = statistics.stdev(y_axis)
stdev
72/5: plt.errorbar(x_ais,yerr=stdev)
72/6: plt.errorbar(x_axis,yerr=stdev)
72/7: plt.errorbar(x_axis,y_axis,yerr=stdev)
72/8: plt.errorbar(x_axis,y_axis,yerr=stdev, capsize=3)
72/9: plt.errorbar(x_axis,y_axis,yerr=stdev, capsize=5)
72/10: plt.errorbar(x_axis,y_axis,yerr=stdev, capsize=7)
72/11: plt.errorbar(x_axis,y_axis,yerr=stdev, capsize=3)
72/12: plt.errorbar(x_axis,y_axis,yerr=stdev, capsize=7)
72/13: plt.errorbar(x_axis,y_axis,yerr=stdev, capsize=3)
72/14:
fig, ax = plt.subplots()
ax.errorbar(x_axis, y_axis, yerr=stdev, capsize=3)
plt.show
72/15: plt.bar(x_axis, y_axis, yerr=stdev, capsize=3)
72/16:
fig,ax=plt.suplots()
ax.bar(x_axis, y_axis, yerr=stdev, capsize=3)
72/17:
fig,ax=plt.subplots()
ax.bar(x_axis, y_axis, yerr=stdev, capsize=3)
plt.show()
72/18:
import numpy as np
plt.barh(x_axis, y_axis)
plt.xticks(np.arange(0, 51, step=5.0))
plt.gca().invert_yaxis()
72/19:
import numpy as np
plt.barh(x_axis, y_axis)
plt.xticks(np.arange(0, 51, step=4.0))
plt.gca().invert_yaxis()
72/20:
import numpy as np
plt.barh(x_axis, y_axis)
plt.xticks(np.arange(0, 51, step=5.0))
plt.gca().invert_yaxis()
72/21:
import numpy as np
plt.barh(x_axis, y_axis)
plt.xticks(np.arange(0, 51, step=5.0))
plt.gca().invert_xaxis()
72/22:
import numpy as np
plt.barh(x_axis, y_axis)
plt.xticks(np.arange(0, 51, step=5.0))
plt.gca().invert_yaxis()
72/23:
import numpy as np
np.arange(0, 51, step=5.0)
72/24:
fig, ax = plt.subplots()
ax.barh(x_axis, y_axis)
ax.set_xticks(np.arange(0, 51, step=5.0))
plt.show()
72/25:
fig, ax = plt.subplots()
ax.barh(x_axis, y_axis)
x.xaxis.set_minor_locator()
ax.set_xticks(np.arange(0, 51, step=5.0))
plt.show()
72/26:
fig, ax = plt.subplots()
ax.barh(x_axis, y_axis)

ax.set_xticks(np.arange(0, 51, step=5.0))
plt.show()
72/27: x.xaxis.set_minor_locator()
72/28:
from matplotlib.ticker import MultipleLocator
#Increase the size of the plot figure.
fig,ax = plt.subplots(figsize=(8,8))
ax.barh(x_axis,y_axis)
ax.set_xticks(np.arrange(0,51, step=5.0))
#Create minor ticks at an increment of 1.
ax.xaxis.set_minor_locator(MultipleLocatocator(1))
plt.show
72/29: %matplotlib inline
72/30:
import matplotlib.pyplot as plt
import statistics
72/31:
# Set the x-axis to a list of strings for each month.
x_axis = ["Jan", "Feb", "Mar", "April", "May", "June", "July", "Aug", "Sept", "Oct", "Nov", "Dec"]

# Set the y-axis to a list of floats as the total fare in US dollars accumulated for each month.
y_axis = [10.02, 23.24, 39.20, 35.42, 32.34, 27.04, 43.82, 10.56, 11.85, 27.90, 20.71, 20.09]
72/32:
# Get the standard deviation of the values in the y-axis.
stdev = statistics.stdev(y_axis)
stdev
72/33: plt.errorbar(x_axis,y_axis,yerr=stdev)
72/34: plt.errorbar(x_axis,y_axis,yerr=stdev, capsize=3)
72/35:
fig, ax = plt.subplots()
ax.errorbar(x_axis, y_axis, yerr=stdev, capsize=3)
plt.show
72/36: plt.bar(x_axis, y_axis, yerr=stdev, capsize=3)
72/37:
fig,ax=plt.subplots()
ax.bar(x_axis, y_axis, yerr=stdev, capsize=3)
plt.show()
72/38:
import numpy as np
plt.barh(x_axis, y_axis)
plt.xticks(np.arange(0, 51, step=5.0))
plt.gca().invert_yaxis()
72/39:
import numpy as np
np.arange(0, 51, step=5.0)
72/40:
fig, ax = plt.subplots()
ax.barh(x_axis, y_axis)

ax.set_xticks(np.arange(0, 51, step=5.0))
plt.show()
72/41:
from matplotlib.ticker import MultipleLocator
#Increase the size of the plot figure.
fig, ax = plt.subplots(figsize=(8,8))
ax.barh(x_axis,y_axis)
ax.set_xticks(np.arrange(0, 51, step=5.0))
#Create minor ticks at an increment of 1.
ax.xaxis.set_minor_locator(MultipleLocatocator(1))
plt.show
72/42:
from matplotlib.ticker import MultipleLocator
#Increase the size of the plot figure.
fig, ax = plt.subplots(figsize=(8,8))
ax.barh(x_axis,y_axis)
ax.set_xticks(np.arrange(0, 51, step=5.0))
#Create minor ticks at an increment of 1.
ax.xaxis.set_minor_locator(MultipleLocatocator(1))
plt.show
72/43:
import numpy as np
np.arange(0, 51, step=5.0)
72/44:
fig, ax = plt.subplots()
ax.barh(x_axis, y_axis)

ax.set_xticks(np.arange(0, 51, step=5.0))
plt.show()
72/45:
from matplotlib.ticker import MultipleLocator
#Increase the size of the plot figure.
fig, ax = plt.subplots(figsize=(8,8))
ax.barh(x_axis,y_axis)
ax.set_xticks(np.arrange(0, 51, step=5.0))
#Create minor ticks at an increment of 1.
ax.xaxis.set_minor_locator(MultipleLocatocator(1))
plt.show
72/46:
from matplotlib.ticker import MultipleLocator
#Increase the size of the plot figure.
fig, ax = plt.subplots(figsize=(8,8))
ax.barh(x_axis,y_axis)
ax.set_xticks(np.arrange(0,51, step=5.0))
#Create minor ticks at an increment of 1.
ax.xaxis.set_minor_locator(MultipleLocatocator(1))
plt.show
72/47:
from matplotlib.ticker import MultipleLocator
#Increase the size of the plot figure.
fig, ax = plt.subplots(figsize=(8,8))
ax.barh(x_axis,y_axis)
ax.set_xticks(np.arange(0,51, step=5.0))
#Create minor ticks at an increment of 1.
ax.xaxis.set_minor_locator(MultipleLocatocator(1))
plt.show
72/48:
import numpy as np
np.arange(0, 51, step=5.0)
72/49:
fig, ax = plt.subplots()
ax.barh(x_axis, y_axis)

ax.set_xticks(np.arange(0, 51, step=5.0))
plt.show()
72/50:
from matplotlib.ticker import MultipleLocator
#Increase the size of the plot figure.
fig, ax = plt.subplots(figsize=(8,8))
ax.barh(x_axis,y_axis)
ax.set_xticks(np.arange(0,51, step=5.0))
#Create minor ticks at an increment of 1.
ax.xaxis.set_minor_locator(MultipleLocatocator(1))
plt.show
72/51:
from matplotlib.ticker import MultipleLocator
#Increase the size of the plot figure.
fig, ax = plt.subplots(figsize=(8,8))
ax.barh(x_axis,y_axis)
ax.set_xticks(np.arange(0, 51, step=5.0))
#Create minor ticks at an increment of 1.
ax.xaxis.set_minor_locator(MultipleLocatocator(1))
plt.show
72/52:
from matplotlib.ticker import MultipleLocator
#Increase the size of the plot figure.
fig, ax = plt.subplots(figsize=(8,8))
ax.barh(x_axis,y_axis)
ax.set_xticks(np.arange(0, 51, step=5.0))
#Create minor ticks at an increment of 1.
ax.xaxis.set_minor_locator(MultipleLocator(1))
plt.show
73/1: %matplotlib inline
73/2:
#Import dependencies
import matpotib.pyplot as plt
import numpy as np
import pandas as pd
#Load in csv
pyber_ride_df = pd.read.csv("Resources/Pyber_ride_data.csv")
73/3:
#Import dependencies
import matpotlib.pyplot as plt
import numpy as np
import pandas as pd
#Load in csv
pyber_ride_df = pd.read.csv("Resources/Pyber_ride_data.csv")
73/4:
#Import dependencies
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
#Load in csv
pyber_ride_df = pd.read.csv("Resources/Pyber_ride_data.csv")
73/5:
#Import dependencies
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
#Load in csv
pyber_ride_df = pd.read.csv("Resources/Pyber_ride_data.csv")
pyber_ride_df
73/6: %matplotlib inline
73/7:
#Import dependencies
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
#Load in csv
pyber_ride_df = pd.read.csv("Resources/Pyber_ride_data.csv")
pyber_ride_df
73/8:
#Import dependencies
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
#Load in csv
pyber_ride_df = pd.read_csv("Resources/Pyber_ride_data.csv")
pyber_ride_df
73/9: pyber_ride_df.plot(x="Month",y="Avg.Fare($USD)")
73/10: pyber_ride_df.plot(x="Month", y="Avg. Fare ($USD)")
73/11:
pyber_ride_df.plot(x="Month", y="Avg. Fare ($USD)")
pkt.show()
73/12:
pyber_ride_df.plot(x="Month", y="Avg. Fare ($USD)")
plt.show()
73/13:
#Set the axis and tick locations.
x_axis = np.arange(len(pyber_ride_df))
73/14:
#Set the axis and tick locations.
x_axis = np.arange(len(pyber_ride_df))
x_axis
73/15:
#Set the axis and tick locations.
x_axis = np.arange(len(pyber_ride_df))
tick_locations = [value for value in x_axis]
73/16:
#Set the axis and tick locations.
x_axis = np.arange(len(pyber_ride_df))
tick_locations = [value for value in x_axis]
tick_locations
73/17:
#Set the axis and tick locations.
x_axis = np.arange(len(pyber_ride_df))
tick_locations = [value for value in x_axis]
#Plot the data.
plt.xticks(tick_locations,pyber_ride_df["Month"])
plt.show()
73/18:
#Set the axis and tick locations.
x_axis = np.arange(len(pyber_ride_df))
tick_locations = [value for value in x_axis]
#Plot the data.
pyber_ride_df.plot(x="Month",y="Avg.Fare($USD)")
plt.xticks(tick_locations,pyber_ride_df["Month"])
plt.show()
73/19:
#Set the axis and tick locations.
x_axis = np.arange(len(pyber_ride_df))
tick_locations = [value for value in x_axis]
#Plot the data.
pyber_ride_df.plot(x="Month",y="Avg. Fare ($USD)")
plt.xticks(tick_locations,pyber_ride_df["Month"])
plt.show()
73/20:
#Set the axis and tick locations.
x_axis = np.arange(len(pyber_ride_df))
tick_locations = [value for value in x_axis]
#Plot the data.
pyber_ride_df.plot(x="Month",y="Avg. Fare ($USD)")
plt.errorbar(x_axis,y_axis,yerr=stdev)
plt.errorbar(x_axis,y_axis,yerr=stdev, capsize=3)
plt.xticks(tick_locations,pyber_ride_df["Month"])
plt.show()
73/21:
#Import dependencies
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
#Load in csv
pyber_ride_df = pd.read_csv("Resources/Pyber_ride_data.csv")
pyber_ride_df
73/22: %matplotlib inline
73/23:
#Import dependencies
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
#Load in csv
pyber_ride_df = pd.read_csv("Resources/Pyber_ride_data.csv")
pyber_ride_df
73/24:
pyber_ride_df.plot(x="Month", y="Avg. Fare ($USD)")
plt.show()
73/25:
#Set the axis and tick locations.
x_axis = np.arange(len(pyber_ride_df))
tick_locations = [value for value in x_axis]
#Plot the data.
pyber_ride_df.plot(x="Month",y="Avg. Fare ($USD)")
plt.errorbar(x_axis,y_axis,yerr=stdev)
plt.errorbar(x_axis,y_axis,yerr=stdev, capsize=3)
plt.xticks(tick_locations,pyber_ride_df["Month"])
plt.show()
73/26:
#Set the axis and tick locations.
x_axis = np.arange(len(pyber_ride_df))
tick_locations = [value for value in x_axis]
#Plot the data.
pyber_ride_df.plot(x="Month",y="Avg. Fare ($USD)")
plt.errorbar(x,y,yerr=stdev)
plt.errorbar(x_axis,y_axis,yerr=stdev, capsize=3)
plt.xticks(tick_locations,pyber_ride_df["Month"])
plt.show()
73/27:
#Set the axis and tick locations.
x_axis = np.arange(len(pyber_ride_df))
tick_locations = [value for value in x_axis]
#Plot the data.
pyber_ride_df.plot(x="Month",y="Avg. Fare ($USD)")
plt.errorbar(x_axis=x,y_axis=y,yerr=stdev)
plt.errorbar(x_axis,y_axis,yerr=stdev, capsize=3)
plt.xticks(tick_locations,pyber_ride_df["Month"])
plt.show()
73/28:
#Set the axis and tick locations.
x_axis = np.arange(len(pyber_ride_df))
tick_locations = [value for value in x_axis]
#Plot the data.
pyber_ride_df.plot(x="Month",y="Avg. Fare ($USD)")
plt.xticks(tick_locations,pyber_ride_df["Month"])
plt.show()
74/1:
#Add Matplotlib inline magic command
%matplotlib inline
# Dependencies and Set up
import matplotlib.pyplot as plt
import pandas as pd
74/2:
city_data_load = "Resources/city_data.csv"
ride_data_load = "Resources/ride_data.csv"
74/3:
city_plan_load = "Resources/city_data.csv"
ride_data_load = "Resources/ride_data.csv"
74/4:
# Read the datafile and store it in DataFrame.
city_data_df = pd.read_csv(city_plan_load)
74/5:
city_data_load = "Resources/city_data.csv"
ride_data_load = "Resources/ride_data.csv"
74/6:
# Read the datafile and store it in DataFrame.
city_data_df = pd.read_csv(city_data_load)
city_data_df.head()
74/7:
# Read the ride datafile and store it in a pandas DataFrame.
ride_data_df = pd.read_csv(ride_data_load)
ride_data_df.head()
74/8:
# Read the ride datafile and store it in a pandas DataFrame.
ride_data_df = pd.read_csv(ride_data_load)
ride_data_df.head(10)
74/9:
# Read the city datafile and store it in a pandas DataFrame.
city_data_df = pd.read_csv(city_data_load)
city_data_df.head(10)
74/10:
# Get the columns and the rows that are not null
city_data_df.count()
74/11:
# Get the columns and the rows that are not null.
city_data_df.isnull().sum()
74/12:
# Get the data types of each column.
city_data_df.dtypes
74/13:
# Get the unique values of the type of city.
city_data_df["type"].unique()
74/14:
# Get the unique values of the type of city.
city_data_df["driver_count"].unique()
74/15:
# Get the unique values of the type of city.
city_data_df["type"].unique()
74/16:
# Get the number of data points from the Urban cities.
sum(city_data_df["type"]=="Urban")
74/17: sum(city_data_df["type"]== "Suburban")
74/18: sum(city_data_df["type"]== "Rural")
74/19:
# Get the columns and the rows that are not null.
ride_data_df.count()
74/20:
# Get the columns and the rows that are not null.
ride_data_df.isnull().sum()
74/21:
# Get the data types of each column.
ride_data_df.dtypes
74/22:
# Combine the data into a single dataset
pyber_data_df = pd.merge(ride_data_df, city_data_df, how="left", on=["city", "city"])
74/23:
# Combine the data into a single dataset
pyber_data_df = pd.merge(ride_data_df, city_data, on =["city","city"])
#Display the DataFrame 
pyber_data_df.head()
74/24:
# Combine the data into a single dataset
pyber_data_df = pd.merge(ride_data_df, city_data_df, on =["city","city"])
#Display the DataFrame 
pyber_data_df.head()
74/25:
# Combine the data into a single dataset
pyber_data_df = pd.merge(ride_data_df, city_data_df, on =["city","city"])
#Display the DataFrame 
pyber_data_df.head(121)
74/26:
# Combine the data into a single dataset
pyber_data_df = pd.merge(ride_data_df, city_data_df, on =["city","city"])
#Display the DataFrame 
pyber_data_df.head(131)
74/27:
# Combine the data into a single dataset
pyber_data_df = pd.merge(ride_data_df, city_data_df, on =["city","city"])
#Display the DataFrame 
pyber_data_df.head()
74/28:
# Create the Urban city DataFrame.
urban_cities_df = pyber_data_df[pyber_data_df["type"] == "Urban"]
urban_cities_df.head()
74/29:
# Create the Suburban and Rural city DataFrames.
suburban_cities_df = pyber_data_df[pyber_data_df["type"]== "Suburban"]
rural_cities_df = pyber_data_df[pyber_data_df["type"]=="Rural"]
rural_cities_df.head()
74/30:
# Create the Suburban and Rural city DataFrames.
suburban_cities_df = pyber_data_df[pyber_data_df["type"]== "Suburban"]
rural_cities_df = pyber_data_df[pyber_data_df["type"]=="Rural"]
74/31:
# get the number of rides for urban cities
urban_ride_count = urban_cities_df.groupby(["city"]).count() ["ride_id"]
urban_ride_count.head()
74/32:
surban_ride_count = subarban_cities_df.groupby(["city"]).count
urban_ride_count.head()
74/33:
surban_ride_count = subarban_cities_df.groupby(["city"]).count()
urban_ride_count.head()
74/34:
surban_ride_count = subarban_cities_df.groupby(["city"]).count() ["ride_id"]
urban_ride_count.head()
74/35:
suburban_ride_count = suburban_cities_df.groupby(["city"]).count() ["ride_id"]
urban_ride_count.head()
74/36:
suburban_ride_count = suburban_cities_df.groupby(["city"]).count() 
urban_ride_count.head()
74/37:
suburban_ride_count = suburban_cities_df.groupby(["city"]).count() 
urban_ride_count.head()
74/38:
suburban_ride_count = suburban_cities_df.groupby(["city"]).count() ["ride_id"]
urban_ride_count.head()
74/39:
# get the number of rides for urban cities
urban_ride_count = urban_cities_df.groupby(["city"]).count() ["ride_id"]
urban_ride_count.head()
74/40:
suburban_ride_count = suburban_cities_df.groupby(["city"]).count() ["ride_id"]
urban_ride_count.head()
74/41:
suburban_ride_count = suburban_cities_df.groupby(["city"]).count() ["ride_id"]
suburban_ride_count.head()
74/42:
suburban_ride_count = suburban_cities_df.groupby(["city"]).count() 
suburban_ride_count.head()
74/43:
suburban_ride_count = suburban_cities_df.groupby(["city"]).count() ["ride_id"]
suburban_ride_count.head()
74/44:
suburban_ride_count = suburban_cities_df.groupby(["city"]).count() ["driver_count"]
suburban_ride_count.head()
74/45:
suburban_ride_count = suburban_cities_df.groupby(["city"]).count() ["driver_count"]
suburban_ride_count.head()
74/46:
suburban_ride_count = suburban_cities_df.groupby(["city"]).count() ["rider_count"]
suburban_ride_count.head()
74/47:
suburban_ride_count = suburban_cities_df.groupby(["city"]).count() ["rider_id"]
suburban_ride_count.head()
74/48:
suburban_ride_count = suburban_cities_df.groupby(["city"]).count() ["rider_id"]
suburban_ride_count.head()
74/49:
suburban_ride_count = suburban_cities_df.groupby(["city"]).count() ["ride_id"]
suburban_ride_count.head()
74/50:
suburban_ride_count = suburban_cities_df.groupby(["city"]).count() ["ride_id"]
rural_ride_count.head = rural_cities_df.groupby(["city"]).count() ["ride_id"]
74/51:
suburban_ride_count = suburban_cities_df.groupby(["city"]).count() ["ride_id"]
rural_ride_count= rural_cities_df.groupby(["city"]).count() ["ride_id"]
74/52:
#get the average fare for each city in the urban cities
urban_avg_fare = urban_cities_df.groupby(["city"].mean()["ride_id"])
urban_avg_fare.head ()
74/53:
#get the average fare for each city in the urban cities
urban_avg_fare = urban_cities_df.groupby(["city"].mean()["fare"])
urban_avg_fare.head ()
74/54:
#get the average fare for each city in the urban cities
urban_avg_fare = urban_cities_df.groupby(["city"].mean()["fare"]
urban_avg_fare.head ()
74/55:
#Add Matplotlib inline magic command
%matplotlib inline
# Dependencies and Set up
import matplotlib.pyplot as plt
import pandas as pd
74/56:
city_data_load = "Resources/city_data.csv"
ride_data_load = "Resources/ride_data.csv"
74/57:
# Read the city datafile and store it in a pandas DataFrame.
city_data_df = pd.read_csv(city_data_load)
city_data_df.head(10)
74/58:
# Read the ride datafile and store it in a pandas DataFrame.
ride_data_df = pd.read_csv(ride_data_load)
ride_data_df.head(10)
74/59:
# Get the columns and the rows that are not null
city_data_df.count()
74/60:
# Get the columns and the rows that are not null.
city_data_df.isnull().sum()
74/61:
# Get the data types of each column.
city_data_df.dtypes
74/62:
# Get the unique values of the type of city.
city_data_df["type"].unique()
74/63:
# Get the columns and the rows that are not null.
ride_data_df.count()
74/64:
# Get the columns and the rows that are not null.
ride_data_df.isnull().sum()
74/65:
# Get the data types of each column.
ride_data_df.dtypes
74/66:
# Combine the data into a single dataset
pyber_data_df = pd.merge(ride_data_df, city_data_df, on =["city","city"])
#Display the DataFrame 
pyber_data_df.head()
74/67:
# Create the Urban city DataFrame.
urban_cities_df = pyber_data_df[pyber_data_df["type"] == "Urban"]
urban_cities_df.head()
74/68:
# Create the Suburban and Rural city DataFrames.
suburban_cities_df = pyber_data_df[pyber_data_df["type"]== "Suburban"]
rural_cities_df = pyber_data_df[pyber_data_df["type"]=="Rural"]
74/69:
# get the number of rides for urban cities
urban_ride_count = urban_cities_df.groupby(["city"]).count() ["ride_id"]
urban_ride_count.head()
74/70:
# get the number of rides for suburban and rural cities
suburban_ride_count = suburban_cities_df.groupby(["city"]).count() ["ride_id"]
rural_ride_count= rural_cities_df.groupby(["city"]).count() ["ride_id"]
74/71:
#get the average fare for each city in the urban cities
urban_avg_fare = urban_cities_df.groupby(["city"].mean()["fare"]
urban_avg_fare.head ()
74/72:
#get the average fare for each city in the urban cities
urban_avg_fare = urban_cities_df.groupby(["city"]).mean()["fare"]
urban_avg_fare.head ()
74/73:
#get the average fare for each city in the urban cities
urban_avg_fare = urban_cities_df.groupby(["city"]).mean()["ride_id"]
urban_avg_fare.head ()
74/74:
#get the average fare for each city in the urban cities
urban_avg_fare = urban_cities_df.groupby(["city"]).mean()["fare"]
urban_avg_fare.head ()
74/75:
#get the average fare for each city in the suurban and rural cities
suburban_avg_fare = suburban_cities_df.groupby(["city"]).mean()["fare"]
74/76:
#get the average fare for each city in the suurban and rural cities
suburban_avg_fare = suburban_cities_df.groupby(["city"]).mean()["fare"]
rural_avg_fare = rural_cities_df.groupby(["city"]).mean()["fare"]
74/77:
urban_driver_count = urban_cities_df.groupby(["city"]).mean()["driver_count"]
urban_driver_count.head()
74/78:
sburban_driver_count = suburban_cities_df.groupby(["city"]).mean()["driver_count"]
urban_driver_count.head()
74/79:
sburban_driver_count = suburban_cities_df.groupby(["city"]).mean()["driver_count"]
rural_avg_fare = rural_cities_df.groupby(["city"]).mean()["driver_count"]
74/80:
sburban_driver_count = suburban_cities_df.groupby(["city"]).mean()["driver_count"]
rural_driver_count = rural_cities_df.groupby(["city"]).mean()["driver_count"]
74/81:
# Build the scatter plots for urban cities.
plt.scatter(urban_ride_count, urban_avg_fare)
74/82:
# Build the scatter plots for urban cities.
plt.scatter(urban_ride_count, urban_avg_fare)
plt.show()
74/83:
# Build the scatter plots for urban cities.
plt.scatter(urban_ride_count, 
            urban_avg_fare
            s=urban_driver_count)
plt.show()
74/84:
# Build the scatter plots for urban cities.
plt.scatter(urban_ride_count,
      urban_avg_fare,
      s=urban_driver_count)
plt.show()
74/85:
# Build the scatter plots for urban cities.
plt.scatter(urban_ride_count,
      urban_avg_fare,)
plt.show()
74/86:
# Build the scatter plots for urban cities.
plt.scatter(urban_ride_count,
      urban_avg_fare,
      s=urban_driver_count)
plt.show()
74/87:
# Build the scatter plots for urban cities.
plt.scatter(urban_ride_count,
      urban_avg_fare,
      s=10*urban_driver_count, c="coral",
      edgecolor="black", linewidths=1,
      alpha=0.8, label="Urban")
plt.title("PyBer Ride-Sharing Data (2019)")
plt.ylabel("Average Fare ($)")
plt.xlabel("Total Number of Rides (Per City)")
plt.grid(True)
# Add the legend.
plt.legend()
74/88:
# Build the scatter plots for urban cities.
plt.scatter(urban_ride_count,
      urban_avg_fare,
      s=10*urban_driver_count, c="coral",
     ,
      alpha=0.8, label="Urban")
plt.title("PyBer Ride-Sharing Data (2019)")
plt.ylabel("Average Fare ($)")
plt.xlabel("Total Number of Rides (Per City)")
plt.grid(True)
# Add the legend.
plt.legend()
74/89:
# Build the scatter plots for urban cities.
plt.scatter(urban_ride_count,
      urban_avg_fare,
      s=10*urban_driver_count, c="coral",
      alpha=0.8, label="Urban")
plt.title("PyBer Ride-Sharing Data (2019)")
plt.ylabel("Average Fare ($)")
plt.xlabel("Total Number of Rides (Per City)")
plt.grid(True)
# Add the legend.
plt.legend()
74/90:
# Build the scatter plots for urban cities.
plt.scatter(urban_ride_count,
      urban_avg_fare,
      s=10*urban_driver_count, c="coral",
      edgecolor="black", linewidths=1
      alpha=0.8, label="Urban")
plt.title("PyBer Ride-Sharing Data (2019)")
plt.ylabel("Average Fare ($)")
plt.xlabel("Total Number of Rides (Per City)")
plt.grid(True)
# Add the legend.
plt.legend()
74/91:
# Build the scatter plots for urban cities.
plt.scatter(urban_ride_count,
      urban_avg_fare,
      s=10*urban_driver_count, c="coral",
      edgecolor="black", linewidths=1,
      alpha=0.8, label="Urban")
plt.title("PyBer Ride-Sharing Data (2019)")
plt.ylabel("Average Fare ($)")
plt.xlabel("Total Number of Rides (Per City)")
plt.grid(True)
# Add the legend.
plt.legend()
74/92:
# Build the scatter plots for urban cities.
plt.scatter(urban_ride_count,
      urban_avg_fare,
      s=10*urban_driver_count, c="coral",
      edgecolor="black", linewidths=1,
      alpha=0.8, label="Urban")
plt.title("PyBer Ride-Sharing Data (2019)")
plt.ylabel("Average Fare ($)")
plt.xlabel("Total Number of Rides (Per City)")
plt.grid(True)
# Add the legend.
plt.legend()
74/93:
# Build the scatter plots for suburban cities.
plt.scatter(suburban_ride_count,
      suburban_avg_fare,
      s=10*suburban_driver_count, c="skyblue",
      edgecolor="black", linewidths=1,
      alpha=0.8, label="Suburban")
plt.title("PyBer Ride-Sharing Data (2019)")
plt.ylabel("Average Fare ($)")
plt.xlabel("Total Number of Rides (Per City)")
plt.grid(True)
# Add the legend.
plt.legend()
74/94:
#Add Matplotlib inline magic command
%matplotlib inline
# Dependencies and Set up
import matplotlib.pyplot as plt
import pandas as pd
74/95:
city_data_load = "Resources/city_data.csv"
ride_data_load = "Resources/ride_data.csv"
74/96:
# Read the city datafile and store it in a pandas DataFrame.
city_data_df = pd.read_csv(city_data_load)
city_data_df.head(10)
74/97:
# Read the ride datafile and store it in a pandas DataFrame.
ride_data_df = pd.read_csv(ride_data_load)
ride_data_df.head(10)
74/98:
# Get the columns and the rows that are not null
city_data_df.count()
74/99:
# Get the columns and the rows that are not null.
city_data_df.isnull().sum()
74/100:
# Get the data types of each column.
city_data_df.dtypes
74/101:
# Get the unique values of the type of city.
city_data_df["type"].unique()
74/102:
# Get the columns and the rows that are not null.
ride_data_df.count()
74/103:
# Get the columns and the rows that are not null.
ride_data_df.isnull().sum()
74/104:
# Get the data types of each column.
ride_data_df.dtypes
74/105:
# Combine the data into a single dataset
pyber_data_df = pd.merge(ride_data_df, city_data_df, on =["city","city"])
#Display the DataFrame 
pyber_data_df.head()
74/106:
# Create the Urban city DataFrame.
urban_cities_df = pyber_data_df[pyber_data_df["type"] == "Urban"]
urban_cities_df.head()
74/107:
# Create the Suburban and Rural city DataFrames.
suburban_cities_df = pyber_data_df[pyber_data_df["type"]== "Suburban"]
rural_cities_df = pyber_data_df[pyber_data_df["type"]=="Rural"]
74/108:
# get the number of rides for urban cities
urban_ride_count = urban_cities_df.groupby(["city"]).count() ["ride_id"]
urban_ride_count.head()
74/109:
# get the number of rides for suburban and rural cities
suburban_ride_count = suburban_cities_df.groupby(["city"]).count() ["ride_id"]
rural_ride_count= rural_cities_df.groupby(["city"]).count() ["ride_id"]
74/110:
#get the average fare for each city in the urban cities
urban_avg_fare = urban_cities_df.groupby(["city"]).mean()["fare"]
urban_avg_fare.head ()
74/111:
#get the average fare for each city in the suurban and rural cities
suburban_avg_fare = suburban_cities_df.groupby(["city"]).mean()["fare"]
rural_avg_fare = rural_cities_df.groupby(["city"]).mean()["fare"]
74/112:
urban_driver_count = urban_cities_df.groupby(["city"]).mean()["driver_count"]
urban_driver_count.head()
74/113:
sburban_driver_count = suburban_cities_df.groupby(["city"]).mean()["driver_count"]
rural_driver_count = rural_cities_df.groupby(["city"]).mean()["driver_count"]
74/114:
# Build the scatter plots for urban cities.
plt.scatter(urban_ride_count,
      urban_avg_fare,
      s=urban_driver_count)
plt.show()
74/115:
# Build the scatter plots for urban cities.
plt.scatter(urban_ride_count,
      urban_avg_fare,
      s=10*urban_driver_count, c="coral",
      edgecolor="black", linewidths=1,
      alpha=0.8, label="Urban")
plt.title("PyBer Ride-Sharing Data (2019)")
plt.ylabel("Average Fare ($)")
plt.xlabel("Total Number of Rides (Per City)")
plt.grid(True)
# Add the legend.
plt.legend()
74/116:
# Build the scatter plots for suburban cities.
plt.scatter(suburban_ride_count,
      suburban_avg_fare,
      s=10*suburban_driver_count, c="skyblue",
      edgecolor="black", linewidths=1,
      alpha=0.8, label="Suburban")
plt.title("PyBer Ride-Sharing Data (2019)")
plt.ylabel("Average Fare ($)")
plt.xlabel("Total Number of Rides (Per City)")
plt.grid(True)
# Add the legend.
plt.legend()
74/117:
# Build the scatter plots for suburban cities.
plt.scatter(suburban_ride_count,
      suburban_avg_fare,
      s=10*suburban_driver_count, c="blue",
      edgecolor="black", linewidths=1,
      alpha=0.8, label="Suburban")
plt.title("PyBer Ride-Sharing Data (2019)")
plt.ylabel("Average Fare ($)")
plt.xlabel("Total Number of Rides (Per City)")
plt.grid(True)
# Add the legend.
plt.legend()
74/118:
# Build the scatter plots for suburban cities.
plt.scatter(suburban_ride_count,suburban_avg_fare,s=10*suburban_driver_count, c="skyblue",edgecolor="black", linewidths=1,alpha=0.8, label="Suburban")
plt.title("PyBer Ride-Sharing Data (2019)")
plt.ylabel("Average Fare ($)")
plt.xlabel("Total Number of Rides (Per City)")
plt.grid(True)
# Add the legend.
plt.legend()
74/119:
# Build the scatter plots for suburban cities.
plt.scatter(suburban_ride_count,
      suburban_avg_fare,
      s=10*suburban_driver_count, c="skyblue",
      edgecolor="black", linewidths=1,
      alpha=0.8, label="Suburban")
plt.title("PyBer Ride-Sharing Data (2019)")
plt.ylabel("Average Fare ($)")
plt.xlabel("Total Number of Rides (Per City)")
plt.grid(True)
# Add the legend.
plt.legend()
74/120:
sburban_driver_count = suburban_cities_df.groupby(["city"]).mean()["driver_count"]
rural_driver_count = rural_cities_df.groupby(["city"]).mean()["driver_count"]
74/121:
# Build the scatter plots for urban cities.
plt.scatter(urban_ride_count,
      urban_avg_fare,
      s=urban_driver_count)
plt.show()
74/122:
plt.scatter(suburban_ride_count,
      suburban_avg_fare,
      s=suburban_driver_count)
plt.show()
74/123:
suburban_driver_count = suburban_cities_df.groupby(["city"]).mean()["driver_count"]
rural_driver_count = rural_cities_df.groupby(["city"]).mean()["driver_count"]
74/124:
# Build the scatter plots for urban cities.
plt.scatter(urban_ride_count,
      urban_avg_fare,
      s=urban_driver_count)
plt.show()
74/125:
# Build the scatter plots for urban cities.
plt.scatter(urban_ride_count,
      urban_avg_fare,
      s=10*urban_driver_count, c="coral",
      edgecolor="black", linewidths=1,
      alpha=0.8, label="Urban")
plt.title("PyBer Ride-Sharing Data (2019)")
plt.ylabel("Average Fare ($)")
plt.xlabel("Total Number of Rides (Per City)")
plt.grid(True)
# Add the legend.
plt.legend()
74/126:
# Build the scatter plots for suburban cities.
plt.scatter(suburban_ride_count,
      suburban_avg_fare,
      s=10*suburban_driver_count, c="skyblue",
      edgecolor="black", linewidths=1,
      alpha=0.8, label="Suburban")
plt.title("PyBer Ride-Sharing Data (2019)")
plt.ylabel("Average Fare ($)")
plt.xlabel("Total Number of Rides (Per City)")
plt.grid(True)
# Add the legend.
plt.legend()
74/127:
# Build the scatter plots for rural cities.
plt.scatter(rural_ride_count,
      rural_avg_fare,
      s=10*rural_driver_count, c="gold",
      edgecolor="black", linewidths=1,
      alpha=0.8, label="Rural")
plt.title("PyBer Ride-Sharing Data (2019)")
plt.ylabel("Average Fare ($)")
plt.xlabel("Total Number of Rides (Per City)")
plt.grid(True)
# Add the legend.
plt.legend()
74/128:
# Add the scatter charts for each type of city.
plt.scatter(urban_ride_count,
      urban_avg_fare,
      s=10*urban_driver_count, c="coral",
      edgecolor="black", linewidths=1,
      alpha=0.8, label="Urban")

plt.scatter(suburban_ride_count,
      suburban_avg_fare,
      s=10*suburban_driver_count, c="skyblue",
      edgecolor="black", linewidths=1,
      alpha=0.8, label="Suburban")

plt.scatter(rural_ride_count,
      rural_avg_fare,
      s=10*rural_driver_count, c="gold",
      edgecolor="black", linewidths=1,
      alpha=0.8, label="Rural")

# Show the plot
plt.show()
74/129:
# Build the scatter charts for each city type.
plt.subplots(figsize=(10, 6))
plt.scatter(urban_ride_count,
      urban_avg_fare,
      s=10*urban_driver_count, c="coral",
      edgecolor="black", linewidths=1,
      alpha=0.8, label="Urban")

plt.scatter(suburban_ride_count,
      suburban_avg_fare,
      s=10*suburban_driver_count, c="skyblue",
      edgecolor="black", linewidths=1,
      alpha=0.8, label="Suburban")

plt.scatter(rural_ride_count,
      rural_avg_fare,
      s=10*rural_driver_count, c="gold",
      edgecolor="black", linewidths=1,
      alpha=0.8, label="Rural")

# Incorporate the other graph properties
plt.title("PyBer Ride-Sharing Data (2019)", fontsize=20)
plt.ylabel("Average Fare ($)", fontsize=12)
plt.xlabel("Total Number of Rides (Per City)", fontsize=12)
plt.grid(True)
# Add the legend.
plt.legend()
# Show the plot
plt.show()
74/130:
# Build the scatter charts for each city type.
plt.subplots(figsize=(10, 6))
plt.scatter(urban_ride_count,
      urban_avg_fare,
      s=10*urban_driver_count, c="coral",
      edgecolor="black", linewidths=1,
      alpha=0.8, label="Urban")

plt.scatter(suburban_ride_count,
      suburban_avg_fare,
      s=10*suburban_driver_count, c="skyblue",
      edgecolor="black", linewidths=1,
      alpha=0.8, label="Suburban")

plt.scatter(rural_ride_count,
      rural_avg_fare,
      s=10*rural_driver_count, c="gold",
      edgecolor="black", linewidths=1,
      alpha=0.8, label="Rural")

# Incorporate the other graph properties
plt.title("PyBer Ride-Sharing Data (2019)", fontsize=20)
plt.ylabel("Average Fare ($)", fontsize=12)
plt.xlabel("Total Number of Rides (Per City)", fontsize=12)
plt.grid(True)
# Add the legend.
# Create a legend
lgnd = plt.legend(fontsize="12", mode="Expanded",
         scatterpoints=1, loc="best", title="City Types")
lgnd.legendHandles[0]._sizes = [75]
lgnd.legendHandles[1]._sizes = [75]
lgnd.legendHandles[2]._sizes = [75]
lgnd.get_title().set_fontsize(12)
# Show the plot
plt.show()
74/131:
# Build the scatter charts for each city type.
plt.subplots(figsize=(10, 6))
plt.scatter(urban_ride_count,
      urban_avg_fare,
      s=10*urban_driver_count, c="coral",
      edgecolor="black", linewidths=1,
      alpha=0.8, label="Urban")

plt.scatter(suburban_ride_count,
      suburban_avg_fare,
      s=10*suburban_driver_count, c="skyblue",
      edgecolor="black", linewidths=1,
      alpha=0.8, label="Suburban")

plt.scatter(rural_ride_count,
      rural_avg_fare,
      s=10*rural_driver_count, c="gold",
      edgecolor="black", linewidths=1,
      alpha=0.8, label="Rural")

# Incorporate the other graph properties
plt.title("PyBer Ride-Sharing Data (2019)", fontsize=20)
plt.ylabel("Average Fare ($)", fontsize=12)
plt.xlabel("Total Number of Rides (Per City)", fontsize=12)
plt.grid(True)
# Add the legend.
# Create a legend
lgnd = plt.legend(fontsize="12", mode="Expanded",
         scatterpoints=1, loc="best", title="City Types")
lgnd.legendHandles[0]._sizes = [75]
lgnd.legendHandles[1]._sizes = [75]
lgnd.legendHandles[2]._sizes = [75]
plt.text(42, 35, "Note: Circle size correlates with driver count per city.", fontsize="12")
lgnd.get_title().set_fontsize(12)
# Show the plot
plt.show()
74/132: plt.savefig("analysis/Fig1.png")
74/133:
#Add Matplotlib inline magic command
%matplotlib inline
# Dependencies and Set up
import matplotlib.pyplot as plt
import pandas as pd
74/134:
city_data_load = "Resources/city_data.csv"
ride_data_load = "Resources/ride_data.csv"
74/135:
# Read the city datafile and store it in a pandas DataFrame.
city_data_df = pd.read_csv(city_data_load)
city_data_df.head(10)
74/136:
# Read the ride datafile and store it in a pandas DataFrame.
ride_data_df = pd.read_csv(ride_data_load)
ride_data_df.head(10)
74/137:
# Get the columns and the rows that are not null
city_data_df.count()
74/138:
# Get the columns and the rows that are not null.
city_data_df.isnull().sum()
74/139:
# Get the data types of each column.
city_data_df.dtypes
74/140:
# Get the unique values of the type of city.
city_data_df["type"].unique()
74/141:
# Get the columns and the rows that are not null.
ride_data_df.count()
74/142:
# Get the columns and the rows that are not null.
ride_data_df.isnull().sum()
74/143:
# Get the data types of each column.
ride_data_df.dtypes
74/144:
# Combine the data into a single dataset
pyber_data_df = pd.merge(ride_data_df, city_data_df, on =["city","city"])
#Display the DataFrame 
pyber_data_df.head()
74/145:
# Create the Urban city DataFrame.
urban_cities_df = pyber_data_df[pyber_data_df["type"] == "Urban"]
urban_cities_df.head()
74/146:
# Create the Suburban and Rural city DataFrames.
suburban_cities_df = pyber_data_df[pyber_data_df["type"]== "Suburban"]
rural_cities_df = pyber_data_df[pyber_data_df["type"]=="Rural"]
74/147:
# get the number of rides for urban cities
urban_ride_count = urban_cities_df.groupby(["city"]).count() ["ride_id"]
urban_ride_count.head()
74/148:
# get the number of rides for suburban and rural cities
suburban_ride_count = suburban_cities_df.groupby(["city"]).count() ["ride_id"]
rural_ride_count= rural_cities_df.groupby(["city"]).count() ["ride_id"]
74/149:
#get the average fare for each city in the urban cities
urban_avg_fare = urban_cities_df.groupby(["city"]).mean()["fare"]
urban_avg_fare.head ()
74/150:
#get the average fare for each city in the suurban and rural cities
suburban_avg_fare = suburban_cities_df.groupby(["city"]).mean()["fare"]
rural_avg_fare = rural_cities_df.groupby(["city"]).mean()["fare"]
74/151:
urban_driver_count = urban_cities_df.groupby(["city"]).mean()["driver_count"]
urban_driver_count.head()
74/152:
suburban_driver_count = suburban_cities_df.groupby(["city"]).mean()["driver_count"]
rural_driver_count = rural_cities_df.groupby(["city"]).mean()["driver_count"]
74/153:
# Build the scatter plots for urban cities.
plt.scatter(urban_ride_count,
      urban_avg_fare,
      s=urban_driver_count)
plt.show()
74/154:
# Build the scatter plots for urban cities.
plt.scatter(urban_ride_count,
      urban_avg_fare,
      s=10*urban_driver_count, c="coral",
      edgecolor="black", linewidths=1,
      alpha=0.8, label="Urban")
plt.title("PyBer Ride-Sharing Data (2019)")
plt.ylabel("Average Fare ($)")
plt.xlabel("Total Number of Rides (Per City)")
plt.grid(True)
# Add the legend.
plt.legend()
74/155:
# Build the scatter plots for suburban cities.
plt.scatter(suburban_ride_count,
      suburban_avg_fare,
      s=10*suburban_driver_count, c="skyblue",
      edgecolor="black", linewidths=1,
      alpha=0.8, label="Suburban")
plt.title("PyBer Ride-Sharing Data (2019)")
plt.ylabel("Average Fare ($)")
plt.xlabel("Total Number of Rides (Per City)")
plt.grid(True)
# Add the legend.
plt.legend()
74/156:
# Build the scatter plots for rural cities.
plt.scatter(rural_ride_count,
      rural_avg_fare,
      s=10*rural_driver_count, c="gold",
      edgecolor="black", linewidths=1,
      alpha=0.8, label="Rural")
plt.title("PyBer Ride-Sharing Data (2019)")
plt.ylabel("Average Fare ($)")
plt.xlabel("Total Number of Rides (Per City)")
plt.grid(True)
# Add the legend.
plt.legend()
74/157:
# Add the scatter charts for each type of city.
plt.scatter(urban_ride_count,
      urban_avg_fare,
      s=10*urban_driver_count, c="coral",
      edgecolor="black", linewidths=1,
      alpha=0.8, label="Urban")

plt.scatter(suburban_ride_count,
      suburban_avg_fare,
      s=10*suburban_driver_count, c="skyblue",
      edgecolor="black", linewidths=1,
      alpha=0.8, label="Suburban")

plt.scatter(rural_ride_count,
      rural_avg_fare,
      s=10*rural_driver_count, c="gold",
      edgecolor="black", linewidths=1,
      alpha=0.8, label="Rural")

# Show the plot
plt.show()
74/158:
# Build the scatter charts for each city type.
plt.subplots(figsize=(10, 6))
plt.scatter(urban_ride_count,
      urban_avg_fare,
      s=10*urban_driver_count, c="coral",
      edgecolor="black", linewidths=1,
      alpha=0.8, label="Urban")

plt.scatter(suburban_ride_count,
      suburban_avg_fare,
      s=10*suburban_driver_count, c="skyblue",
      edgecolor="black", linewidths=1,
      alpha=0.8, label="Suburban")

plt.scatter(rural_ride_count,
      rural_avg_fare,
      s=10*rural_driver_count, c="gold",
      edgecolor="black", linewidths=1,
      alpha=0.8, label="Rural")

# Incorporate the other graph properties
plt.title("PyBer Ride-Sharing Data (2019)", fontsize=20)
plt.ylabel("Average Fare ($)", fontsize=12)
plt.xlabel("Total Number of Rides (Per City)", fontsize=12)
plt.grid(True)
# Add the legend.
# Create a legend
lgnd = plt.legend(fontsize="12", mode="Expanded",
         scatterpoints=1, loc="best", title="City Types")
lgnd.legendHandles[0]._sizes = [75]
lgnd.legendHandles[1]._sizes = [75]
lgnd.legendHandles[2]._sizes = [75]
plt.text(42, 35, "Note: Circle size correlates with driver count per city.", fontsize="12")
lgnd.get_title().set_fontsize(12)
# Show the plot
plt.show()
74/159: plt.savefig("analysis/Fig1.png")
74/160:
# Build the scatter charts for each city type.
plt.subplots(figsize=(10, 6))
plt.scatter(urban_ride_count,
      urban_avg_fare,
      s=10*urban_driver_count, c="coral",
      edgecolor="black", linewidths=1,
      alpha=0.8, label="Urban")

plt.scatter(suburban_ride_count,
      suburban_avg_fare,
      s=10*suburban_driver_count, c="skyblue",
      edgecolor="black", linewidths=1,
      alpha=0.8, label="Suburban")

plt.scatter(rural_ride_count,
      rural_avg_fare,
      s=10*rural_driver_count, c="gold",
      edgecolor="black", linewidths=1,
      alpha=0.8, label="Rural")

# Incorporate the other graph properties
plt.title("PyBer Ride-Sharing Data (2019)", fontsize=20)
plt.ylabel("Average Fare ($)", fontsize=12)
plt.xlabel("Total Number of Rides (Per City)", fontsize=12)
plt.grid(True)
# Add the legend.
# Create a legend
lgnd = plt.legend(fontsize="12", mode="Expanded",
         scatterpoints=1, loc="best", title="City Types")
lgnd.legendHandles[0]._sizes = [75]
lgnd.legendHandles[1]._sizes = [75]
lgnd.legendHandles[2]._sizes = [75]
plt.text(42, 35, "Note: Circle size correlates with driver count per city.", fontsize="12")
plt.savefig("analysis/Fig1.png")
lgnd.get_title().set_fontsize(12)
# Show the plot
plt.show()
74/161:
# Build the scatter charts for each city type.
plt.subplots(figsize=(10, 6))
plt.scatter(urban_ride_count,
      urban_avg_fare,
      s=10*urban_driver_count, c="coral",
      edgecolor="black", linewidths=1,
      alpha=0.8, label="Urban")

plt.scatter(suburban_ride_count,
      suburban_avg_fare,
      s=10*suburban_driver_count, c="skyblue",
      edgecolor="black", linewidths=1,
      alpha=0.8, label="Suburban")

plt.scatter(rural_ride_count,
      rural_avg_fare,
      s=10*rural_driver_count, c="gold",
      edgecolor="black", linewidths=1,
      alpha=0.8, label="Rural")

# Incorporate the other graph properties
plt.title("PyBer Ride-Sharing Data (2019)", fontsize=20)
plt.ylabel("Average Fare ($)", fontsize=12)
plt.xlabel("Total Number of Rides (Per City)", fontsize=12)
plt.grid(True)
# Add the legend.
# Create a legend
lgnd = plt.legend(fontsize="12", mode="Expanded",
         scatterpoints=1, loc="best", title="City Types")
lgnd.legendHandles[0]._sizes = [75]
lgnd.legendHandles[1]._sizes = [75]
lgnd.legendHandles[2]._sizes = [75]
plt.text(42, 35, "Note: Circle size correlates with driver count per city.", fontsize="12")
plt.savefig("analysis/Fig1.png")
lgnd.get_title().set_fontsize(12)
# Show the plot
plt.show()
74/162:
# Build the scatter charts for each city type.
plt.subplots(figsize=(10, 6))
plt.scatter(urban_ride_count,
      urban_avg_fare,
      s=10*urban_driver_count, c="coral",
      edgecolor="black", linewidths=1,
      alpha=0.8, label="Urban")

plt.scatter(suburban_ride_count,
      suburban_avg_fare,
      s=10*suburban_driver_count, c="skyblue",
      edgecolor="black", linewidths=1,
      alpha=0.8, label="Suburban")

plt.scatter(rural_ride_count,
      rural_avg_fare,
      s=10*rural_driver_count, c="gold",
      edgecolor="black", linewidths=1,
      alpha=0.8, label="Rural")

# Incorporate the other graph properties
plt.title("PyBer Ride-Sharing Data (2019)", fontsize=20)
plt.ylabel("Average Fare ($)", fontsize=12)
plt.xlabel("Total Number of Rides (Per City)", fontsize=12)
plt.grid(True)
# Add the legend.
# Create a legend
lgnd = plt.legend(fontsize="12", mode="Expanded",
         scatterpoints=1, loc="best", title="City Types")
lgnd.legendHandles[0]._sizes = [75]
lgnd.legendHandles[1]._sizes = [75]
lgnd.legendHandles[2]._sizes = [75]
lgnd.get_title().set_fontsize(12)
plt.text(42, 35, "Note: Circle size correlates with driver count per city.", fontsize="12")
plt.savefig("analysis/Fig1.png")
# Show the plot
plt.show()
74/163:
# Build the scatter charts for each city type.
plt.subplots(figsize=(10, 6))
plt.scatter(urban_ride_count,
      urban_avg_fare,
      s=10*urban_driver_count, c="coral",
      edgecolor="black", linewidths=1,
      alpha=0.8, label="Urban")

plt.scatter(suburban_ride_count,
      suburban_avg_fare,
      s=10*suburban_driver_count, c="skyblue",
      edgecolor="black", linewidths=1,
      alpha=0.8, label="Suburban")

plt.scatter(rural_ride_count,
      rural_avg_fare,
      s=10*rural_driver_count, c="gold",
      edgecolor="black", linewidths=1,
      alpha=0.8, label="Rural")

# Incorporate the other graph properties
plt.title("PyBer Ride-Sharing Data (2019)", fontsize=20)
plt.ylabel("Average Fare ($)", fontsize=12)
plt.xlabel("Total Number of Rides (Per City)", fontsize=12)
plt.grid(True)
# Add the legend.
# Create a legend
lgnd = plt.legend(fontsize="12", mode="Expanded",
         scatterpoints=1, loc="best", title="City Types")
lgnd.legendHandles[0]._sizes = [75]
lgnd.legendHandles[1]._sizes = [75]
lgnd.legendHandles[2]._sizes = [75]
lgnd.get_title().set_fontsize(12)
plt.text(42, 35, "Note: Circle size correlates with driver count per city.", fontsize="12")

# Show the plot
plt.show()
plt.savefig("analysis/Fig1.png")
74/164:
#Add Matplotlib inline magic command
%matplotlib inline
# Dependencies and Set up
import matplotlib.pyplot as plt
import pandas as pd
74/165:
city_data_load = "Resources/city_data.csv"
ride_data_load = "Resources/ride_data.csv"
74/166:
# Read the city datafile and store it in a pandas DataFrame.
city_data_df = pd.read_csv(city_data_load)
city_data_df.head(10)
74/167:
# Read the ride datafile and store it in a pandas DataFrame.
ride_data_df = pd.read_csv(ride_data_load)
ride_data_df.head(10)
74/168:
# Get the columns and the rows that are not null
city_data_df.count()
74/169:
# Get the columns and the rows that are not null.
city_data_df.isnull().sum()
74/170:
# Get the data types of each column.
city_data_df.dtypes
74/171:
# Get the unique values of the type of city.
city_data_df["type"].unique()
74/172:
# Get the columns and the rows that are not null.
ride_data_df.count()
74/173:
# Get the columns and the rows that are not null.
ride_data_df.isnull().sum()
74/174:
# Get the data types of each column.
ride_data_df.dtypes
74/175:
# Combine the data into a single dataset
pyber_data_df = pd.merge(ride_data_df, city_data_df, on =["city","city"])
#Display the DataFrame 
pyber_data_df.head()
74/176:
# Create the Urban city DataFrame.
urban_cities_df = pyber_data_df[pyber_data_df["type"] == "Urban"]
urban_cities_df.head()
74/177:
# Create the Suburban and Rural city DataFrames.
suburban_cities_df = pyber_data_df[pyber_data_df["type"]== "Suburban"]
rural_cities_df = pyber_data_df[pyber_data_df["type"]=="Rural"]
74/178:
# get the number of rides for urban cities
urban_ride_count = urban_cities_df.groupby(["city"]).count() ["ride_id"]
urban_ride_count.head()
74/179:
# get the number of rides for suburban and rural cities
suburban_ride_count = suburban_cities_df.groupby(["city"]).count() ["ride_id"]
rural_ride_count= rural_cities_df.groupby(["city"]).count() ["ride_id"]
74/180:
#get the average fare for each city in the urban cities
urban_avg_fare = urban_cities_df.groupby(["city"]).mean()["fare"]
urban_avg_fare.head ()
74/181:
#get the average fare for each city in the suurban and rural cities
suburban_avg_fare = suburban_cities_df.groupby(["city"]).mean()["fare"]
rural_avg_fare = rural_cities_df.groupby(["city"]).mean()["fare"]
74/182:
urban_driver_count = urban_cities_df.groupby(["city"]).mean()["driver_count"]
urban_driver_count.head()
74/183:
suburban_driver_count = suburban_cities_df.groupby(["city"]).mean()["driver_count"]
rural_driver_count = rural_cities_df.groupby(["city"]).mean()["driver_count"]
74/184:
# Build the scatter plots for urban cities.
plt.scatter(urban_ride_count,
      urban_avg_fare,
      s=urban_driver_count)
plt.show()
74/185:
# Build the scatter plots for urban cities.
plt.scatter(urban_ride_count,
      urban_avg_fare,
      s=10*urban_driver_count, c="coral",
      edgecolor="black", linewidths=1,
      alpha=0.8, label="Urban")
plt.title("PyBer Ride-Sharing Data (2019)")
plt.ylabel("Average Fare ($)")
plt.xlabel("Total Number of Rides (Per City)")
plt.grid(True)
# Add the legend.
plt.legend()
74/186:
# Build the scatter plots for suburban cities.
plt.scatter(suburban_ride_count,
      suburban_avg_fare,
      s=10*suburban_driver_count, c="skyblue",
      edgecolor="black", linewidths=1,
      alpha=0.8, label="Suburban")
plt.title("PyBer Ride-Sharing Data (2019)")
plt.ylabel("Average Fare ($)")
plt.xlabel("Total Number of Rides (Per City)")
plt.grid(True)
# Add the legend.
plt.legend()
74/187:
# Build the scatter plots for rural cities.
plt.scatter(rural_ride_count,
      rural_avg_fare,
      s=10*rural_driver_count, c="gold",
      edgecolor="black", linewidths=1,
      alpha=0.8, label="Rural")
plt.title("PyBer Ride-Sharing Data (2019)")
plt.ylabel("Average Fare ($)")
plt.xlabel("Total Number of Rides (Per City)")
plt.grid(True)
# Add the legend.
plt.legend()
74/188:
# Add the scatter charts for each type of city.
plt.scatter(urban_ride_count,
      urban_avg_fare,
      s=10*urban_driver_count, c="coral",
      edgecolor="black", linewidths=1,
      alpha=0.8, label="Urban")

plt.scatter(suburban_ride_count,
      suburban_avg_fare,
      s=10*suburban_driver_count, c="skyblue",
      edgecolor="black", linewidths=1,
      alpha=0.8, label="Suburban")

plt.scatter(rural_ride_count,
      rural_avg_fare,
      s=10*rural_driver_count, c="gold",
      edgecolor="black", linewidths=1,
      alpha=0.8, label="Rural")

# Show the plot
plt.show()
74/189:
# Build the scatter charts for each city type.
plt.subplots(figsize=(10, 6))
plt.scatter(urban_ride_count,
      urban_avg_fare,
      s=10*urban_driver_count, c="coral",
      edgecolor="black", linewidths=1,
      alpha=0.8, label="Urban")

plt.scatter(suburban_ride_count,
      suburban_avg_fare,
      s=10*suburban_driver_count, c="skyblue",
      edgecolor="black", linewidths=1,
      alpha=0.8, label="Suburban")

plt.scatter(rural_ride_count,
      rural_avg_fare,
      s=10*rural_driver_count, c="gold",
      edgecolor="black", linewidths=1,
      alpha=0.8, label="Rural")

# Incorporate the other graph properties
plt.title("PyBer Ride-Sharing Data (2019)", fontsize=20)
plt.ylabel("Average Fare ($)", fontsize=12)
plt.xlabel("Total Number of Rides (Per City)", fontsize=12)
plt.grid(True)
# Add the legend.
# Create a legend
lgnd = plt.legend(fontsize="12", mode="Expanded",
         scatterpoints=1, loc="best", title="City Types")
lgnd.legendHandles[0]._sizes = [75]
lgnd.legendHandles[1]._sizes = [75]
lgnd.legendHandles[2]._sizes = [75]
lgnd.get_title().set_fontsize(12)
plt.text(42, 35, "Note: Circle size correlates with driver count per city.", fontsize="12")

# Show the plot
plt.show()
plt.savefig("analysis/Fig1.png")
74/190:
# Build the scatter charts for each city type.
plt.subplots(figsize=(10, 6))
plt.scatter(urban_ride_count,
      urban_avg_fare,
      s=10*urban_driver_count, c="coral",
      edgecolor="black", linewidths=1,
      alpha=0.8, label="Urban")

plt.scatter(suburban_ride_count,
      suburban_avg_fare,
      s=10*suburban_driver_count, c="skyblue",
      edgecolor="black", linewidths=1,
      alpha=0.8, label="Suburban")

plt.scatter(rural_ride_count,
      rural_avg_fare,
      s=10*rural_driver_count, c="gold",
      edgecolor="black", linewidths=1,
      alpha=0.8, label="Rural")

# Incorporate the other graph properties
plt.title("PyBer Ride-Sharing Data (2019)", fontsize=20)
plt.ylabel("Average Fare ($)", fontsize=12)
plt.xlabel("Total Number of Rides (Per City)", fontsize=12)
plt.grid(True)
# Add the legend.
# Create a legend
lgnd = plt.legend(fontsize="12", mode="Expanded",
         scatterpoints=1, loc="best", title="City Types")
lgnd.legendHandles[0]._sizes = [75]
lgnd.legendHandles[1]._sizes = [75]
lgnd.legendHandles[2]._sizes = [75]
lgnd.get_title().set_fontsize(12)
plt.text(42, 35, "Note: Circle size correlates with driver count per city.", fontsize="12")

# Show the plot
plt.show()
plt.savefig("analysis/Fig1.png")
74/191:
# Build the scatter charts for each city type.
plt.subplots(figsize=(10, 6))
plt.scatter(urban_ride_count,
      urban_avg_fare,
      s=10*urban_driver_count, c="coral",
      edgecolor="black", linewidths=1,
      alpha=0.8, label="Urban")

plt.scatter(suburban_ride_count,
      suburban_avg_fare,
      s=10*suburban_driver_count, c="skyblue",
      edgecolor="black", linewidths=1,
      alpha=0.8, label="Suburban")

plt.scatter(rural_ride_count,
      rural_avg_fare,
      s=10*rural_driver_count, c="gold",
      edgecolor="black", linewidths=1,
      alpha=0.8, label="Rural")

# Incorporate the other graph properties
plt.title("PyBer Ride-Sharing Data (2019)", fontsize=20)
plt.ylabel("Average Fare ($)", fontsize=12)
plt.xlabel("Total Number of Rides (Per City)", fontsize=12)
plt.grid(True)
# Add the legend.
# Create a legend
lgnd = plt.legend(fontsize="12", mode="Expanded",
         scatterpoints=1, loc="best", title="City Types")
lgnd.legendHandles[0]._sizes = [75]
lgnd.legendHandles[1]._sizes = [75]
lgnd.legendHandles[2]._sizes = [75]
lgnd.get_title().set_fontsize(12)
plt.text(42, 35, "Note: Circle size correlates with driver count per city.", fontsize="12")
plt.savefig("analysis/Fig1.png")
# Show the plot
plt.show()
74/192:
#Get the summary statistics.
urban_cities_df.describe()
74/193: suburban_cities_df.describe()
74/194: rural_cities_df.describe()
74/195: urban_ride_describe()
74/196: urban_ride_count_describe()
74/197: urban_ride_count.describe()
74/198: suburban_ride_count.describe()
74/199: rural_ride_df.describe(
74/200: rural_ride_df.describe()
74/201: rural_ride_count.describe()
74/202:
# Calculate the mean of the ride count for each city type.
round(urban_ride_count.mean(),2), round(suburban_ride_count.mean(),2), round(rural_ride_count.mean(),2)
74/203: round(urban_ride_count.median(),2), round(suburban_ride_count.median(),2), round(rural_ride_count.median(),2)
74/204:
# Calculate the mode of the ride count for the urban cities.
urban_ride_count.mode()
74/205: suburban_ride_count.mode()
74/206:
# Import NumPy and the stats module from SciPy.
import numpy as np
import scipy.stats as sts
74/207:
# Calculate the measures of central tendency for the ride count for the urban cities.
mean_urban_ride_count = np.mean(urban_ride_count)
print(f"The mean for the ride counts for urban trips is {mean_urban_ride_count:.2f}.")

median_urban_ride_count = np.median(urban_ride_count)
print(f"The median for the ride counts for urban trips is {median_urban_ride_count}.")

mode_urban_ride_count = sts.mode(urban_ride_count)
print(f"The mode for the ride counts for urban trips is {mode_urban_ride_count}.")
74/208: rural_ride_count.mode()
74/209: ride_count.head()
74/210: rural_ride_count.head()
74/211: urban_ride_count.head()
74/212: suburban_ride.count()
74/213: suburban_ride_count()
74/214: suburban_ride_count.head()
74/215:
# Get the fares for the urban cities.
urban_fares = urban_cities_df["fare"]
urban_fares.head()
74/216:
# Get the fares for the urban cities.
urban_fares = urban_cities_df["fare"]
urban_fares()
74/217:
# Get the fares for the urban cities.
urban_fares = urban_cities_df["fare"]
urban_fares.head()
74/218:
# Calculate the measures of central tendency for the average fare for the urban cities.
mean_urban_fares = np.mean(urban_fares)
print(f"The mean fare price for urban trips is ${mean_urban_fares:.2f}.")

median_urban_fares = np.median(urban_fares)
print(f"The median fare price for urban trips is ${median_urban_fares:.2f}.")

mode_urban_fares = sts.mode(urban_fares)
print(f"The mode fare price for urban trips is {mode_urban_fares}.")
74/219:
# Calculate the measures of central tendency for the average fare for the urban cities.
mean_suburban_fares = np.mean(suburban_fares)
print(f"The mean fare price for urban trips is ${mean_suburban_fares:.2f}.")

median_suburban_fares = np.median(suburban_fares)
print(f"The median fare price for urban trips is ${median_suburban_fares:.2f}.")

mode_suburban_fares = sts.mode(suburban_fares)
print(f"The mode fare price for suburban trips is {mode_suburban_fares}.")
74/220:
# Calculate the measures of central tendency for the average fare for the urban cities.
mean_suburban_fares = np.mean(suburban_fares)
print(f"The mean fare price for suburban trips is ${mean_suburban_fares:.2f}.")

median_suburban_fares = np.median(suburban_fares)
print(f"The median fare price for suburban trips is ${median_suburban_fares:.2f}.")

mode_suburban_fares = sts.mode(suburban_fares)
print(f"The mode fare price for suburban trips is {mode_suburban_fares}.")
74/221:
# Get the fares for the urban cities.
suburban_fares.head()suburban_fares = suburban_cities_df["fare"]
suburban_fares.head()
74/222:
# Get the fares for the urban cities.
suburban_fares = suburban_cities_df["fare"]
suburban_fares.head()
74/223:
# Calculate the measures of central tendency for the average fare for the suburban cities.
mean_suburban_fares = np.mean(suburban_fares)
print(f"The mean fare price for suburban trips is ${mean_suburban_fares:.2f}.")

median_suburban_fares = np.median(suburban_fares)
print(f"The median fare price for suburban trips is ${median_suburban_fares:.2f}.")

mode_suburban_fares = sts.mode(suburban_fares)
print(f"The mode fare price for suburban trips is {mode_suburban_fares}.")
74/224:
 Get the fares for the rural cities.
rural_fares = rural_cities_df["fare"]
rural_fares.head()
74/225:
# Get the fares for the rural cities.
rural_fares = rural_cities_df["fare"]
rural_fares.head()
74/226:
# Calculate the measures of central tendency for the average fare for the rural cities.
mean_rural_fares = np.mean(rural_fares)
print(f"The mean fare price for rural trips is ${mean_rural_fares:.2f}.")

median_rural_fares = np.median(rural_fares)
print(f"The median fare price for rural trips is ${median_rural_fares:.2f}.")

mode_rural_fares = sts.mode(rural_fares)
print(f"The mode fare price for rural trips is {mode_rural_fares}.")
74/227:
# Get the driver count data from the urban cities.
urban_drivers = urban_cities_df['driver_count']
urban_drivers.head()
74/228:
# Get the driver count data from the urban cities.
suburban_drivers = suburban_cities_df['driver_count']
suburban_drivers.head()
74/229:
# Get the driver count data from the urban cities.
rural_drivers = rural_cities_df['driver_count']
rural_drivers.head()
74/230:
# Create a box-and-whisker plot for the urban cities ride count.
x_labels = ["Urban"]
fig, ax = plt.subplots()
ax.boxplot(urban_ride_count, labels=x_labels)
# Add the title, y-axis label and grid.
ax.set_title('Ride Count Data (2019)')
ax.set_ylabel('Number of Rides')
ax.set_yticks(np.arange(10, 41, step=2.0))
ax.grid()
plt.show()
74/231:
# Add all ride count box-and-whisker plots to the same graph.
x_labels = ["Urban", "Suburban","Rural"]
ride_count_data = [urban_ride_count, suburban_ride_count, rural_ride_count]
fig, ax = plt.subplots(figsize=(10, 6))
ax.set_title('Ride Count Data (2019)',fontsize=20)
ax.set_ylabel('Number of Rides',fontsize=14)
ax.set_xlabel("City Types",fontsize=14)
ax.boxplot(ride_count_data, labels=x_labels)
ax.set_yticks(np.arange(0, 45, step=3.0))
ax.grid()
# Save the figure.
plt.savefig("analysis/Fig2.png")
plt.show()
74/232:
#Add Matplotlib inline magic command
%matplotlib inline
# Dependencies and Set up
import matplotlib.pyplot as plt
import pandas as pd
74/233:
city_data_load = "Resources/city_data.csv"
ride_data_load = "Resources/ride_data.csv"
74/234:
# Read the city datafile and store it in a pandas DataFrame.
city_data_df = pd.read_csv(city_data_load)
city_data_df.head(10)
74/235:
# Read the ride datafile and store it in a pandas DataFrame.
ride_data_df = pd.read_csv(ride_data_load)
ride_data_df.head(10)
74/236:
# Get the columns and the rows that are not null
city_data_df.count()
74/237:
# Get the columns and the rows that are not null.
city_data_df.isnull().sum()
74/238:
# Get the data types of each column.
city_data_df.dtypes
74/239:
# Get the unique values of the type of city.
city_data_df["type"].unique()
74/240:
# Get the columns and the rows that are not null.
ride_data_df.count()
74/241:
# Get the columns and the rows that are not null.
ride_data_df.isnull().sum()
74/242:
# Get the data types of each column.
ride_data_df.dtypes
74/243:
# Combine the data into a single dataset
pyber_data_df = pd.merge(ride_data_df, city_data_df, on =["city","city"])
#Display the DataFrame 
pyber_data_df.head()
74/244:
# Create the Urban city DataFrame.
urban_cities_df = pyber_data_df[pyber_data_df["type"] == "Urban"]
urban_cities_df.head()
74/245:
# Create the Suburban and Rural city DataFrames.
suburban_cities_df = pyber_data_df[pyber_data_df["type"]== "Suburban"]
rural_cities_df = pyber_data_df[pyber_data_df["type"]=="Rural"]
74/246:
# get the number of rides for urban cities
urban_ride_count = urban_cities_df.groupby(["city"]).count() ["ride_id"]
urban_ride_count.head()
74/247:
# get the number of rides for suburban and rural cities
suburban_ride_count = suburban_cities_df.groupby(["city"]).count() ["ride_id"]
rural_ride_count= rural_cities_df.groupby(["city"]).count() ["ride_id"]
74/248:
#get the average fare for each city in the urban cities
urban_avg_fare = urban_cities_df.groupby(["city"]).mean()["fare"]
urban_avg_fare.head ()
74/249:
#get the average fare for each city in the suurban and rural cities
suburban_avg_fare = suburban_cities_df.groupby(["city"]).mean()["fare"]
rural_avg_fare = rural_cities_df.groupby(["city"]).mean()["fare"]
74/250:
urban_driver_count = urban_cities_df.groupby(["city"]).mean()["driver_count"]
urban_driver_count.head()
74/251:
suburban_driver_count = suburban_cities_df.groupby(["city"]).mean()["driver_count"]
rural_driver_count = rural_cities_df.groupby(["city"]).mean()["driver_count"]
74/252:
# Build the scatter plots for urban cities.
plt.scatter(urban_ride_count,
      urban_avg_fare,
      s=urban_driver_count)
plt.show()
74/253:
# Build the scatter plots for urban cities.
plt.scatter(urban_ride_count,
      urban_avg_fare,
      s=10*urban_driver_count, c="coral",
      edgecolor="black", linewidths=1,
      alpha=0.8, label="Urban")
plt.title("PyBer Ride-Sharing Data (2019)")
plt.ylabel("Average Fare ($)")
plt.xlabel("Total Number of Rides (Per City)")
plt.grid(True)
# Add the legend.
plt.legend()
74/254:
# Build the scatter plots for suburban cities.
plt.scatter(suburban_ride_count,
      suburban_avg_fare,
      s=10*suburban_driver_count, c="skyblue",
      edgecolor="black", linewidths=1,
      alpha=0.8, label="Suburban")
plt.title("PyBer Ride-Sharing Data (2019)")
plt.ylabel("Average Fare ($)")
plt.xlabel("Total Number of Rides (Per City)")
plt.grid(True)
# Add the legend.
plt.legend()
74/255:
# Build the scatter plots for rural cities.
plt.scatter(rural_ride_count,
      rural_avg_fare,
      s=10*rural_driver_count, c="gold",
      edgecolor="black", linewidths=1,
      alpha=0.8, label="Rural")
plt.title("PyBer Ride-Sharing Data (2019)")
plt.ylabel("Average Fare ($)")
plt.xlabel("Total Number of Rides (Per City)")
plt.grid(True)
# Add the legend.
plt.legend()
74/256:
# Add the scatter charts for each type of city.
plt.scatter(urban_ride_count,
      urban_avg_fare,
      s=10*urban_driver_count, c="coral",
      edgecolor="black", linewidths=1,
      alpha=0.8, label="Urban")

plt.scatter(suburban_ride_count,
      suburban_avg_fare,
      s=10*suburban_driver_count, c="skyblue",
      edgecolor="black", linewidths=1,
      alpha=0.8, label="Suburban")

plt.scatter(rural_ride_count,
      rural_avg_fare,
      s=10*rural_driver_count, c="gold",
      edgecolor="black", linewidths=1,
      alpha=0.8, label="Rural")

# Show the plot
plt.show()
74/257:
# Build the scatter charts for each city type.
plt.subplots(figsize=(10, 6))
plt.scatter(urban_ride_count,
      urban_avg_fare,
      s=10*urban_driver_count, c="coral",
      edgecolor="black", linewidths=1,
      alpha=0.8, label="Urban")

plt.scatter(suburban_ride_count,
      suburban_avg_fare,
      s=10*suburban_driver_count, c="skyblue",
      edgecolor="black", linewidths=1,
      alpha=0.8, label="Suburban")

plt.scatter(rural_ride_count,
      rural_avg_fare,
      s=10*rural_driver_count, c="gold",
      edgecolor="black", linewidths=1,
      alpha=0.8, label="Rural")

# Incorporate the other graph properties
plt.title("PyBer Ride-Sharing Data (2019)", fontsize=20)
plt.ylabel("Average Fare ($)", fontsize=12)
plt.xlabel("Total Number of Rides (Per City)", fontsize=12)
plt.grid(True)
# Add the legend.
# Create a legend
lgnd = plt.legend(fontsize="12", mode="Expanded",
         scatterpoints=1, loc="best", title="City Types")
lgnd.legendHandles[0]._sizes = [75]
lgnd.legendHandles[1]._sizes = [75]
lgnd.legendHandles[2]._sizes = [75]
lgnd.get_title().set_fontsize(12)
plt.text(42, 35, "Note: Circle size correlates with driver count per city.", fontsize="12")
plt.savefig("analysis/Fig1.png")
# Show the plot
plt.show()
74/258:
#Get the summary statistics.
urban_cities_df.describe()
74/259: suburban_cities_df.describe()
74/260: rural_cities_df.describe()
74/261: urban_ride_count.describe()
74/262: suburban_ride_count.describe()
74/263: rural_ride_count.describe()
74/264:
# Calculate the mean of the ride count for each city type.
round(urban_ride_count.mean(),2), round(suburban_ride_count.mean(),2), round(rural_ride_count.mean(),2)
74/265: round(urban_ride_count.median(),2), round(suburban_ride_count.median(),2), round(rural_ride_count.median(),2)
74/266:
# Calculate the mode of the ride count for the urban cities.
urban_ride_count.mode()
74/267: suburban_ride_count.mode()
74/268: rural_ride_count.mode()
74/269:
# Import NumPy and the stats module from SciPy.
import numpy as np
import scipy.stats as sts
74/270:
# Calculate the measures of central tendency for the ride count for the urban cities.
mean_urban_ride_count = np.mean(urban_ride_count)
print(f"The mean for the ride counts for urban trips is {mean_urban_ride_count:.2f}.")

median_urban_ride_count = np.median(urban_ride_count)
print(f"The median for the ride counts for urban trips is {median_urban_ride_count}.")

mode_urban_ride_count = sts.mode(urban_ride_count)
print(f"The mode for the ride counts for urban trips is {mode_urban_ride_count}.")
74/271: suburban_ride_count.head()
74/272:
# Get the fares for the urban cities.
urban_fares = urban_cities_df["fare"]
urban_fares.head()
74/273:
# Calculate the measures of central tendency for the average fare for the urban cities.
mean_urban_fares = np.mean(urban_fares)
print(f"The mean fare price for urban trips is ${mean_urban_fares:.2f}.")

median_urban_fares = np.median(urban_fares)
print(f"The median fare price for urban trips is ${median_urban_fares:.2f}.")

mode_urban_fares = sts.mode(urban_fares)
print(f"The mode fare price for urban trips is {mode_urban_fares}.")
74/274:
# Get the fares for the suburban cities.
suburban_fares = suburban_cities_df["fare"]
suburban_fares.head()
74/275:
# Calculate the measures of central tendency for the average fare for the suburban cities.
mean_suburban_fares = np.mean(suburban_fares)
print(f"The mean fare price for suburban trips is ${mean_suburban_fares:.2f}.")

median_suburban_fares = np.median(suburban_fares)
print(f"The median fare price for suburban trips is ${median_suburban_fares:.2f}.")

mode_suburban_fares = sts.mode(suburban_fares)
print(f"The mode fare price for suburban trips is {mode_suburban_fares}.")
74/276:
# Get the fares for the rural cities.
rural_fares = rural_cities_df["fare"]
rural_fares.head()
74/277:
# Calculate the measures of central tendency for the average fare for the rural cities.
mean_rural_fares = np.mean(rural_fares)
print(f"The mean fare price for rural trips is ${mean_rural_fares:.2f}.")

median_rural_fares = np.median(rural_fares)
print(f"The median fare price for rural trips is ${median_rural_fares:.2f}.")

mode_rural_fares = sts.mode(rural_fares)
print(f"The mode fare price for rural trips is {mode_rural_fares}.")
74/278:
# Get the driver count data from the urban cities.
urban_drivers = urban_cities_df['driver_count']
urban_drivers.head()
74/279:
# Get the driver count data from the urban cities.
suburban_drivers = suburban_cities_df['driver_count']
suburban_drivers.head()
74/280:
# Get the driver count data from the urban cities.
rural_drivers = rural_cities_df['driver_count']
rural_drivers.head()
74/281:
# Create a box-and-whisker plot for the urban cities ride count.
x_labels = ["Urban"]
fig, ax = plt.subplots()
ax.boxplot(urban_ride_count, labels=x_labels)
# Add the title, y-axis label and grid.
ax.set_title('Ride Count Data (2019)')
ax.set_ylabel('Number of Rides')
ax.set_yticks(np.arange(10, 41, step=2.0))
ax.grid()
plt.show()
74/282:
# Add all ride count box-and-whisker plots to the same graph.
x_labels = ["Urban", "Suburban","Rural"]
ride_count_data = [urban_ride_count, suburban_ride_count, rural_ride_count]
fig, ax = plt.subplots(figsize=(10, 6))
ax.set_title('Ride Count Data (2019)',fontsize=20)
ax.set_ylabel('Number of Rides',fontsize=14)
ax.set_xlabel("City Types",fontsize=14)
ax.boxplot(ride_count_data, labels=x_labels)
ax.set_yticks(np.arange(0, 45, step=3.0))
ax.grid()
# Save the figure.
plt.savefig("analysis/Fig2.png")
plt.show()
74/283:
#Get the city that matches 39.
urban_city_outlier = urban_ride_count[urban_ride_count==39].index[0]
print(f"{urban_city_outlier} has the highest rider count.")
74/284:
# Add all ride count box-and-whisker plots to the same graph.
x_labels = ["Urban", "Suburban","Rural"]
ride_count_data = [urban_ride_count, suburban_ride_count, rural_ride_count]
fig, ax = plt.subplots(figsize=(10, 6))
ax.set_title('Ride Count Data (2019)',fontsize=20)
ax.set_ylabel('Number of Rides',fontsize=14)
ax.set_xlabel("City Types",fontsize=14)
ax.boxplot(ride_count_data, labels=x_labels)
ax.set_yticks(np.arange(0, 45, step=2.0))
ax.grid()
# Save the figure.
plt.savefig("analysis/Fig2.png")
plt.show()
74/285:
# Add all ride count box-and-whisker plots to the same graph.
x_labels = ["Urban", "Suburban","Rural"]
ride_count_data = [urban_ride_count, suburban_ride_count, rural_ride_count]
fig, ax = plt.subplots(figsize=(10, 6))
ax.set_title('Ride Count Data (2019)',fontsize=20)
ax.set_ylabel('Number of Rides',fontsize=14)
ax.set_xlabel("City Types",fontsize=14)
ax.boxplot(ride_count_data, labels=x_labels)
ax.set_yticks(np.arange(0, 45, step=1.0))
ax.grid()
# Save the figure.
plt.savefig("analysis/Fig2.png")
plt.show()
74/286:
# Add all ride count box-and-whisker plots to the same graph.
x_labels = ["Urban", "Suburban","Rural"]
ride_count_data = [urban_ride_count, suburban_ride_count, rural_ride_count]
fig, ax = plt.subplots(figsize=(10, 6))
ax.set_title('Ride Count Data (2019)',fontsize=20)
ax.set_ylabel('Number of Rides',fontsize=14)
ax.set_xlabel("City Types",fontsize=14)
ax.boxplot(ride_count_data, labels=x_labels)
ax.set_yticks(np.arange(0, 45, step=3.0))
ax.grid()
# Save the figure.
plt.savefig("analysis/Fig2.png")
plt.show()
74/287:
# Create a box-and-whisker plot for the urban cities ride count.
x_labels = ["Urban"]
fig, ax = plt.subplots()
ax.boxplot(urban_ride_count, labels=x_labels)
# Add the title, y-axis label and grid.
ax.set_title('Ride Count Data (2019)')
ax.set_ylabel('Number of Rides')
ax.set_yticks(np.arange(10, 41, step=1.0))
ax.grid()
plt.show()
74/288:
# Create a box-and-whisker plot for the urban cities ride count.
x_labels = ["Urban"]
fig, ax = plt.subplots()
ax.boxplot(urban_ride_count, labels=x_labels)
# Add the title, y-axis label and grid.
ax.set_title('Ride Count Data (2019)')
ax.set_ylabel('Number of Rides')
ax.set_yticks(np.arange(10, 41, step=2.0))
ax.grid()
plt.show()
74/289:
# Add all ride count box-and-whisker plots to the same graph.
x_labels = ["Urban", "Suburban","Rural"]
ride_count_data = [urban_ride_count, suburban_ride_count, rural_ride_count]
fig, ax = plt.subplots(figsize=(10, 6))
ax.set_title('Ride Count Data (2019)',fontsize=20)
ax.set_ylabel('Number of Rides',fontsize=14)
ax.set_xlabel("City Types",fontsize=14)
ax.boxplot(ride_count_data, labels=x_labels)
ax.set_yticks(np.arange(0, 45, step=2.0))
ax.grid()
# Save the figure.
plt.savefig("analysis/Fig2.png")
plt.show()
74/290:
# Add all ride count box-and-whisker plots to the same graph.
x_labels = ["Urban", "Suburban","Rural"]
ride_count_data = [urban_ride_count, suburban_ride_count, rural_ride_count]
fig, ax = plt.subplots(figsize=(10, 6))
ax.set_title('Ride Count Data (2019)',fontsize=20)
ax.set_ylabel('Number of Rides',fontsize=14)
ax.set_xlabel("City Types",fontsize=14)
ax.boxplot(ride_count_data, labels=x_labels)
ax.set_yticks(np.arange(0, 45, step=3.0))
ax.grid()
# Save the figure.
plt.savefig("analysis/Fig2.png")
plt.show()
76/1: %matplotlib inline
76/2:
#Import dependencies
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
#Load in csv
pyber_ride_df = pd.read_csv("Resources/Pyber_ride_data.csv")
pyber_ride_df
76/3:
pyber_ride_df.plot(x="Month", y="Avg. Fare ($USD)")
plt.show()
77/1:
pyber_ride_df.plot(x="Month", y="Avg. Fare ($USD)")
plt.show()
77/2: %matplotlib inline
77/3:
#Import dependencies
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
#Load in csv
pyber_ride_df = pd.read_csv("Resources/Pyber_ride_data.csv")
pyber_ride_df
77/4:
pyber_ride_df.plot(x="Month", y="Avg. Fare ($USD)")
plt.show()
77/5:
#Set the axis and tick locations.
x_axis = np.arange(len(pyber_ride_df))
tick_locations = [value for value in x_axis]
#Plot the data.
pyber_ride_df.plot(x="Month",y="Avg. Fare ($USD)")
plt.xticks(tick_locations,pyber_ride_df["Month"])
plt.show()
   1: %matplotlib inline
   2:
#Import dependencies
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
#Load in csv
pyber_ride_df = pd.read_csv("Resources/Pyber_ride_data.csv")
pyber_ride_df
   3:
pyber_ride_df.plot(x="Month", y="Avg. Fare ($USD)")
plt.show()
   4:
#Set the axis and tick locations.
x_axis = np.arange(len(pyber_ride_df))
tick_locations = [value for value in x_axis]
#Plot the data.
pyber_ride_df.plot(x="Month",y="Avg. Fare ($USD)")
plt.xticks(tick_locations,pyber_ride_df["Month"])
plt.show()
   5: %history -g -f notebook_file.ipynb
